<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Kalyan的小书房</title>
  <icon>https://www.gravatar.com/avatar/26add54e467101c6779c59a0ed4ee504</icon>
  <subtitle>Kalyan is working hard</subtitle>
  <link href="https://kalyan-zitiu.github.io/atom.xml" rel="self"/>
  
  <link href="https://kalyan-zitiu.github.io/"/>
  <updated>2024-08-08T09:31:28.153Z</updated>
  <id>https://kalyan-zitiu.github.io/</id>
  
  <author>
    <name>Kalyan</name>
    <email>3148862192@qq.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>浅聊消息队列中间件-rocketmq</title>
    <link href="https://kalyan-zitiu.github.io/2024/08/08/%E6%B5%85%E8%81%8A%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%AD%E9%97%B4%E4%BB%B6-rocketmq/"/>
    <id>https://kalyan-zitiu.github.io/2024/08/08/%E6%B5%85%E8%81%8A%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%AD%E9%97%B4%E4%BB%B6-rocketmq/</id>
    <published>2024-08-08T08:40:52.000Z</published>
    <updated>2024-08-08T09:31:28.153Z</updated>
    
    <content type="html"><![CDATA[<h3 id="消息队列RocketMQ"><a href="#消息队列RocketMQ" class="headerlink" title="消息队列RocketMQ"></a>消息队列RocketMQ</h3><ul><li>为什么有了Kafka还是会有其他的的消息队列中间件呢，是因为KafKa不好用吗，并不是的，其实RocketMQ是有参考KafKa进行开发的，总的一句话说就是在<strong>架构上做减法，在功能上做加法</strong></li></ul><h3 id="减法"><a href="#减法" class="headerlink" title="减法"></a>减法</h3><ul><li>RcketMQ在KafKa的架构上除去了过重的Zookeeper分布式协调服务的组件，选择使用了更轻量级的nameserver。为什么要舍弃Zookeeper呢，主要是Zookeeper的功能多样而且强大，在KafKa中使用太过了。后续KafKa的新版本中也舍弃了Zookeeper选择使用了Raft一致性算法进行数据的统一协调。为什么新版本后还是有很多人选择使用RocketMQ呢，第一是新的东西总是有坑，第二就是RocketMQ还有不同KafKa的过人之处。</li></ul><h3 id="相似"><a href="#相似" class="headerlink" title="相似"></a>相似</h3><ul><li>RocketMQ还是和KafKa一样，在不同topic上分不同的Partition，接着就是Broker进行高可用和高扩展，只是不一样的是RocketMQ把partition改名成了Queue</li></ul><h3 id="不同"><a href="#不同" class="headerlink" title="不同"></a>不同</h3><h4 id="消息体的存储位置"><a href="#消息体的存储位置" class="headerlink" title="消息体的存储位置"></a>消息体的存储位置</h4><ul><li>和KafKa不同的是，KafKa在partition中存储的是完整的消息题，而RocketMQ则是在Queue中只存储简要的信息，用来堆消息进行导向，比如offset。而实际的消息体会放在一个commitLog上面进行存储，通过offset来堆消息体进行定位获取。</li></ul><p>@ 小白debug<br><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240808171332666.png" alt="image-20240808171332666"></p><h4 id="持久化磁盘的区别"><a href="#持久化磁盘的区别" class="headerlink" title="持久化磁盘的区别"></a>持久化磁盘的区别</h4><p>因为RocketMQ的消息体是放在一个commitLog里面，自然在写入磁盘时候也是顺序写入，非常通畅</p><h4 id="备份简化"><a href="#备份简化" class="headerlink" title="备份简化"></a>备份简化</h4><ul><li>RocketMQ为了不拆分commitLog干脆把主从副本升级成为了broker的级别，这样就不需要再多个Broker维护主从副本，直接改成了主从Broker。</li></ul><h3 id="加法"><a href="#加法" class="headerlink" title="加法"></a>加法</h3><h4 id="细分类"><a href="#细分类" class="headerlink" title="细分类"></a>细分类</h4><p>RocketMQ做的加法其实就是再Queue再进行细分类上打上tag的标签，比如，我在Queue中的索引某个消息打上vip的标签这样消费者就能够直接获取标签上的offset来获取vip标签。而KafKa则需要再一个partition里面进行筛选最终选出消息体给出消息。</p><h4 id="加入延时队列"><a href="#加入延时队列" class="headerlink" title="加入延时队列"></a>加入延时队列</h4><ul><li>RocketMQ能够使用延时队列，顾名思义就是能够延迟被消费者进行消费的队列消息。</li></ul><h4 id="加入死信队列"><a href="#加入死信队列" class="headerlink" title="加入死信队列"></a>加入死信队列</h4><ul><li>RockerMQ会对重复失败处理的消息放入，专门处理失败的独立Queue队列也就是死信队列。</li></ul><h3 id="附上总图-小白debug"><a href="#附上总图-小白debug" class="headerlink" title="附上总图 @ 小白debug"></a>附上总图 @ 小白debug</h3><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240808171926411.png" alt="image-20240808171926411"></p><h3 id="sum"><a href="#sum" class="headerlink" title="sum"></a>sum</h3><p>看似RocketMQ在KafKa的基础上做了如此多的优化，其实性能却远不及KafKa这又是为什么呢？？？</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;消息队列RocketMQ&quot;&gt;&lt;a href=&quot;#消息队列RocketMQ&quot; class=&quot;headerlink&quot; title=&quot;消息队列RocketMQ&quot;&gt;&lt;/a&gt;消息队列RocketMQ&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;为什么有了Kafka还是会有其他的的消息队列中间</summary>
      
    
    
    
    <category term="中间件" scheme="https://kalyan-zitiu.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="中间件" scheme="https://kalyan-zitiu.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>浅聊消息队列中间件-kafka</title>
    <link href="https://kalyan-zitiu.github.io/2024/08/08/%E6%B5%85%E8%81%8A%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%AD%E9%97%B4%E4%BB%B6-kafka/"/>
    <id>https://kalyan-zitiu.github.io/2024/08/08/%E6%B5%85%E8%81%8A%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%AD%E9%97%B4%E4%BB%B6-kafka/</id>
    <published>2024-08-08T06:02:57.000Z</published>
    <updated>2024-08-08T08:48:02.310Z</updated>
    
    <content type="html"><![CDATA[<h3 id="为什么需要中间件消息队列"><a href="#为什么需要中间件消息队列" class="headerlink" title="为什么需要中间件消息队列"></a>为什么需要中间件消息队列</h3><p>  假设你有两台服务器，服务器A不断地发送需要处理的消息给服务器B，但是处理的速度赶不上发送的速度，就会导致消息堆积以至于是服务器B负载升高。要是服务B宕机了存储在内存里面的需要处理的消息就消失了，服务A又不知道导致各种消息没有得到处理后的回应，于是就有了消息队列kafka的诞生，没有什么是不能增加一个中间件解决不了的。</p><h3 id="什么是KafKa"><a href="#什么是KafKa" class="headerlink" title="什么是KafKa"></a>什么是KafKa</h3><p>一种分布式流处理平台，主要用途是构建实时数据流应用和数据管道。</p><h3 id="KafKa的架构"><a href="#KafKa的架构" class="headerlink" title="KafKa的架构"></a>KafKa的架构</h3><ul><li>首先既然是一个中间件，它要是单独的跑一个消息队列进行消息的存储，当消息过多也会造成中间件的崩溃，所以需要一个高性能，高可用，有备份的中间件是必要的。</li></ul><h3 id="KafKa是怎么实现高性能的。"><a href="#KafKa是怎么实现高性能的。" class="headerlink" title="KafKa是怎么实现高性能的。"></a>KafKa是怎么实现高性能的。</h3><ul><li>我们把对参与消息的分为Producer和Consumer，意思就是生产者和消费者，更简单点就是发布消息者和订阅消息者。按自己理解来。</li><li>KafKa是通过消息的分类和分组的方式来区分不同类型的消息，我们管它叫<strong>Topic</strong></li><li>在每一个Topic它又会分为多个Partition，每个Partition能过够被Consumer独立消费</li></ul><p>ps：到以上能够解决了KafKa的性能问题，那么这多的partition在一节点上，要是节点炸了，那么消息一样全没了，所以又引导出高扩展的问题</p><h3 id="KafKa是怎么实现高扩展的"><a href="#KafKa是怎么实现高扩展的" class="headerlink" title="KafKa是怎么实现高扩展的"></a>KafKa是怎么实现高扩展的</h3><ul><li>大佬们是这么解决的，是通过服务器节点，我们把它叫<strong>Broker</strong>，Broker里面可以放不同数量的Partition，所以能够通过添加Broker节点来达到增加Partition，从何提高Topic的性能情况下，减少所有Partition放在同一个节点的方式的高负荷问题，那么要是就算某一个Broker还是因为高负荷坏了，该怎么解决，那么又能引发出高可用的问题</li></ul><h3 id="KafKa是怎么实现高可用"><a href="#KafKa是怎么实现高可用" class="headerlink" title="KafKa是怎么实现高可用"></a>KafKa是怎么实现高可用</h3><ul><li>KafKa是通过子不同的Borker里面存放副本进行高可用的实现，这些副本分为主从，若是主副本的Broker宕机了，那么从副本就会升级为主副本被Consumer消费。现在问题又来了，怎么保证他们每一个Broker之间的通信呢。</li></ul><h3 id="KafKa怎么解决组件之间通信的"><a href="#KafKa怎么解决组件之间通信的" class="headerlink" title="KafKa怎么解决组件之间通信的"></a>KafKa怎么解决组件之间通信的</h3><ul><li>KafKa最后处理组件一致性和通信问题是用了Zookeeper，Zookeeper有着服务发现的功能，能够很好的协调KafKa集群的分布式服务。通信问题解决了。要是在很极端的情况下，所有的高性能高可用以及高扩展出来的东西，还是因为负载过高而全部宕机呢。那么就需要考虑到持久化存储，既然放在内存里面的消息如此不稳定。那么我们就持久化到磁盘里面。</li></ul><h3 id="KafKa的底层存储"><a href="#KafKa的底层存储" class="headerlink" title="KafKa的底层存储"></a>KafKa的底层存储</h3><ul><li>KafKa是对每一个Partiton分区进行顺序写入的操作，Partiton分区下面是实际上是一堆堆segment，顺序写入Partition实际上是顺序把消息写入segment里面。然后再<strong>随机</strong>写入磁盘中，这里为什么要注意随机呢。</li></ul><h4 id="KafKa的持久化存储为什么最终是随机写入磁盘"><a href="#KafKa的持久化存储为什么最终是随机写入磁盘" class="headerlink" title="KafKa的持久化存储为什么最终是随机写入磁盘"></a>KafKa的持久化存储为什么最终是随机写入磁盘</h4><ul><li>众所周知顺序写入磁盘会比随机写入要快很多，那么为什么KafKa明明是对segment顺序写入的，最终还是成为随机呢。</li><li>因为每一堆segment是partition下面的，既然你那么多的partition，所以就会有很多份segment，对于sgement本身虽然是顺序写入，但是对于每一份segment确实随机写入。</li></ul><h3 id="最终附上up：小白debug的总图"><a href="#最终附上up：小白debug的总图" class="headerlink" title="最终附上up：小白debug的总图"></a>最终附上up：小白debug的总图</h3><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240808164328969.png" alt="image-20240808164328969"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;为什么需要中间件消息队列&quot;&gt;&lt;a href=&quot;#为什么需要中间件消息队列&quot; class=&quot;headerlink&quot; title=&quot;为什么需要中间件消息队列&quot;&gt;&lt;/a&gt;为什么需要中间件消息队列&lt;/h3&gt;&lt;p&gt;  假设你有两台服务器，服务器A不断地发送需要处理的消息给服</summary>
      
    
    
    
    <category term="中间件" scheme="https://kalyan-zitiu.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
    <category term="中间件" scheme="https://kalyan-zitiu.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>浅解析Containerd</title>
    <link href="https://kalyan-zitiu.github.io/2024/08/07/Containerd/"/>
    <id>https://kalyan-zitiu.github.io/2024/08/07/Containerd/</id>
    <published>2024-08-07T09:51:41.000Z</published>
    <updated>2024-08-08T04:31:40.930Z</updated>
    
    <content type="html"><![CDATA[<h3 id="导言"><a href="#导言" class="headerlink" title="导言"></a>导言</h3><p>最近在集群中遇到了很多containerd的问题，所以不禁思考我真的懂containerd吗？？?</p><h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><p>本文假设你熟悉了</p><ol><li>CRI的概念 &amp;&amp; gRPC &amp;&amp; socket 参考：<a href="https://blog.kalyan.life/2024/07/04/CRI/">https://blog.kalyan.life/2024/07/04/CRI/</a></li><li>shim垫片概念</li></ol><h3 id="containerd是什么就不说啦"><a href="#containerd是什么就不说啦" class="headerlink" title="containerd是什么就不说啦"></a>containerd是什么就不说啦</h3><h3 id="架构（理解就好，主要在于如何使用，想要研究可以去看源码）"><a href="#架构（理解就好，主要在于如何使用，想要研究可以去看源码）" class="headerlink" title="架构（理解就好，主要在于如何使用，想要研究可以去看源码）"></a>架构（理解就好，主要在于如何使用，想要研究可以去看源码）</h3><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240808100725408.png" alt="image-20240808100725408"></p><h4 id="1-API-层"><a href="#1-API-层" class="headerlink" title="1. API 层"></a>1. API 层</h4><ul><li><strong>gRPC API</strong>: 提供给客户端的 gRPC API，支持包括容器管理、镜像管理、存储管理等操作。</li><li><strong>CRI</strong>: 容器运行时接口，允许 Kubernetes 通过 gRPC API 与 containerd 交互。</li><li><strong>Prometheus</strong>: 用于监控的指标接口，收集和暴露 containerd 的运行时数据。</li></ul><h4 id="2-核心层-Core"><a href="#2-核心层-Core" class="headerlink" title="2. 核心层 (Core)"></a>2. 核心层 (Core)</h4><ul><li><p>Services</p><p>: 包含多种服务，每种服务负责不同的功能模块。</p><ul><li><strong>Containers Service</strong>: 管理容器的生命周期。</li><li><strong>Content Service</strong>: 负责内容管理，处理镜像层的数据。</li><li><strong>Diff Service</strong>: 负责镜像层之间的差异计算。</li><li><strong>Images Service</strong>: 负责镜像的管理。</li><li><strong>Leases Service</strong>: 管理临时资源。</li><li><strong>Namespaces Service</strong>: 提供命名空间支持，隔离不同的容器组。</li><li><strong>Snapshots Service</strong>: 管理快照。</li><li><strong>Tasks Service</strong>: 管理任务的运行。</li></ul></li><li><p>Metadata</p><p>: 提供命名空间支持和元数据管理。</p><ul><li><strong>Containers, Content, Images, Leases, Namespaces, Snapshots</strong>: 各种元数据的管理模块。</li></ul></li></ul><h4 id="3-后端层-Backend"><a href="#3-后端层-Backend" class="headerlink" title="3. 后端层 (Backend)"></a>3. 后端层 (Backend)</h4><ul><li><p><strong>Content Store</strong>: 负责存储内容，可以通过插件和本地存储实现。</p></li><li><p>Snapshotter</p><p>: 管理文件系统的快照。</p><ul><li><strong>overlay, btrfs, devmapper, native, windows, plugin</strong>: 支持多种文件系统和快照技术。</li></ul></li><li><p>Runtime</p><p>: 支持容器运行时。</p><ul><li><strong>runc, runhcs, kata, Firecracker, gVisor, shim</strong>: 支持多种运行时，包括 runc、runhcs、kata containers、Firecracker 和 gVisor。</li><li><strong>v2 shim client</strong>: 每个容器都有一个 shim 进程，隔离容器的生命周期管理，确保容器的独立运行。</li></ul></li></ul><h4 id="4-系统层-System"><a href="#4-系统层-System" class="headerlink" title="4. 系统层 (System)"></a>4. 系统层 (System)</h4><ul><li>支持多种硬件架构和操作系统，包括 ARM、Intel、Windows、Linux。</li></ul><h3 id="简化版"><a href="#简化版" class="headerlink" title="简化版"></a>简化版</h3><ul><li>分为三⼤块：Storage 管理镜像⽂件的存储；Metadata 管理镜像和容器的元数据；另外由 Task<br>触发运⾏时。对外提供 GRPC ⽅式的 API 以及 Metrics 接⼝。</li></ul><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240808102354598.png" alt="image-20240808102354598"></p><h3 id="然后我们讲一下重要的配置文件"><a href="#然后我们讲一下重要的配置文件" class="headerlink" title="然后我们讲一下重要的配置文件"></a>然后我们讲一下重要的配置文件</h3><h4 id="config-toml"><a href="#config-toml" class="headerlink" title="config.toml"></a>config.toml</h4><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240808103459459.png" alt="image-20240808103459459"></p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">version</span> <span class="string">=</span> <span class="number">2</span></span><br><span class="line"><span class="comment"># 配置文件版本</span></span><br><span class="line"></span><br><span class="line"><span class="string">root</span> <span class="string">=</span> <span class="string">&quot;/var/lib/containerd&quot;</span></span><br><span class="line"><span class="comment"># containerd 数据存储的根目录</span></span><br><span class="line"></span><br><span class="line"><span class="string">state</span> <span class="string">=</span> <span class="string">&quot;/run/containerd&quot;</span></span><br><span class="line"><span class="comment"># containerd 状态信息存储目录</span></span><br><span class="line"></span><br><span class="line"><span class="string">oom_score</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># OOM（Out of Memory）分数调整值，用于内存不足时的优先级</span></span><br><span class="line"></span><br><span class="line">[<span class="string">grpc</span>]</span><br><span class="line"><span class="comment"># gRPC 配置部分</span></span><br><span class="line"></span><br><span class="line">  <span class="string">max_recv_message_size</span> <span class="string">=</span> <span class="number">16777216</span></span><br><span class="line">  <span class="comment"># gRPC 最大接收消息大小</span></span><br><span class="line"></span><br><span class="line">  <span class="string">max_send_message_size</span> <span class="string">=</span> <span class="number">16777216</span></span><br><span class="line">  <span class="comment"># gRPC 最大发送消息大小</span></span><br><span class="line"></span><br><span class="line">[<span class="string">debug</span>]</span><br><span class="line"><span class="comment"># 调试配置部分</span></span><br><span class="line"></span><br><span class="line">  <span class="string">level</span> <span class="string">=</span> <span class="string">&quot;info&quot;</span></span><br><span class="line">  <span class="comment"># 日志级别，info 表示信息级别日志</span></span><br><span class="line"></span><br><span class="line">[<span class="string">metrics</span>]</span><br><span class="line"><span class="comment"># 指标配置部分</span></span><br><span class="line"></span><br><span class="line">  <span class="string">address</span> <span class="string">=</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="comment"># 指标服务监听地址，空表示不启用</span></span><br><span class="line"></span><br><span class="line">  <span class="string">grpc_histogram</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 是否启用 gRPC 直方图</span></span><br><span class="line"></span><br><span class="line">[<span class="string">plugins</span>]</span><br><span class="line"><span class="comment"># 插件配置部分</span></span><br><span class="line"></span><br><span class="line">  [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;</span>]</span><br><span class="line">  <span class="comment"># CRI 插件配置部分</span></span><br><span class="line"></span><br><span class="line">    <span class="string">sandbox_image</span> <span class="string">=</span> <span class="string">&quot;192.168.154.2/registry.k8s.io/pause:3.9&quot;</span></span><br><span class="line">    <span class="comment"># 沙箱镜像，用于 Pod 的基础镜像</span></span><br><span class="line"></span><br><span class="line">    <span class="string">max_container_log_line_size</span> <span class="string">=</span> <span class="number">-1</span></span><br><span class="line">    <span class="comment"># 容器日志行的最大长度，-1 表示不限制</span></span><br><span class="line"></span><br><span class="line">    <span class="string">enable_unprivileged_ports</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment"># 是否启用非特权端口</span></span><br><span class="line"></span><br><span class="line">    <span class="string">enable_unprivileged_icmp</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment"># 是否启用非特权 ICMP</span></span><br><span class="line"></span><br><span class="line">    [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd</span>]</span><br><span class="line">    <span class="comment"># containerd 相关配置</span></span><br><span class="line"></span><br><span class="line">      <span class="string">default_runtime_name</span> <span class="string">=</span> <span class="string">&quot;runc&quot;</span></span><br><span class="line">      <span class="comment"># 默认运行时名称</span></span><br><span class="line"></span><br><span class="line">      <span class="string">snapshotter</span> <span class="string">=</span> <span class="string">&quot;overlayfs&quot;</span></span><br><span class="line">      <span class="comment"># 默认使用的快照器类型</span></span><br><span class="line"></span><br><span class="line">      <span class="string">discard_unpacked_layers</span> <span class="string">=</span> <span class="literal">true</span></span><br><span class="line">      <span class="comment"># 是否丢弃解包的层</span></span><br><span class="line"></span><br><span class="line">    [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes</span>]</span><br><span class="line">    <span class="comment"># 容器运行时配置部分</span></span><br><span class="line"></span><br><span class="line">      [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc</span>]</span><br><span class="line">      <span class="comment"># runc 运行时配置部分</span></span><br><span class="line"></span><br><span class="line">        <span class="string">runtime_type</span> <span class="string">=</span> <span class="string">&quot;io.containerd.runc.v2&quot;</span></span><br><span class="line">        <span class="comment"># 运行时类型</span></span><br><span class="line"></span><br><span class="line">        <span class="string">runtime_engine</span> <span class="string">=</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 运行时引擎</span></span><br><span class="line"></span><br><span class="line">        <span class="string">runtime_root</span> <span class="string">=</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 运行时根目录</span></span><br><span class="line"></span><br><span class="line">        <span class="string">base_runtime_spec</span> <span class="string">=</span> <span class="string">&quot;/etc/containerd/cri-base.json&quot;</span></span><br><span class="line">        <span class="comment"># 基础运行时规格文件</span></span><br><span class="line"></span><br><span class="line">      [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options</span>]</span><br><span class="line">      <span class="comment"># runc 运行时选项配置部分</span></span><br><span class="line"></span><br><span class="line">        <span class="string">SystemdCgroup</span> <span class="string">=</span> <span class="literal">true</span></span><br><span class="line">        <span class="comment"># 是否启用 systemd cgroup</span></span><br><span class="line"></span><br><span class="line">        <span class="string">BinaryName</span> <span class="string">=</span> <span class="string">&quot;/usr/local/bin/runc&quot;</span></span><br><span class="line">        <span class="comment"># runc 二进制文件路径</span></span><br><span class="line"></span><br><span class="line">    [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry</span>]</span><br><span class="line">    <span class="comment"># 镜像仓库配置部分</span></span><br><span class="line"></span><br><span class="line">      [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors</span>]</span><br><span class="line">      <span class="comment"># 镜像仓库镜像配置部分</span></span><br><span class="line"></span><br><span class="line">        [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;192.168.154.2&quot;</span>]</span><br><span class="line">        <span class="comment"># 指定的镜像仓库</span></span><br><span class="line">          <span class="string">endpoint</span> <span class="string">=</span> [<span class="string">&quot;https://192.168.154.2&quot;</span>]</span><br><span class="line">          <span class="comment"># 镜像仓库的端点 URL</span></span><br><span class="line"></span><br><span class="line">      [<span class="string">plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.configs.&quot;192.168.154.2&quot;.tls</span>]</span><br><span class="line">      <span class="comment"># 镜像仓库 TLS 配置部分</span></span><br><span class="line"></span><br><span class="line">        <span class="string">insecure_skip_verify</span> <span class="string">=</span> <span class="literal">true</span></span><br><span class="line">        <span class="comment"># 是否跳过 TLS 证书验证</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="值得注意的是这里的镜像仓库有两种加载方式-到了2-0版本就可以用"><a href="#值得注意的是这里的镜像仓库有两种加载方式-到了2-0版本就可以用" class="headerlink" title="值得注意的是这里的镜像仓库有两种加载方式,到了2.0版本就可以用"></a>值得注意的是这里的镜像仓库有两种加载方式,到了2.0版本就可以用</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[plugins.<span class="string">&quot;io.containerd.grpc.v1.cri&quot;</span>.registry]</span><br><span class="line">config_path= <span class="string">&quot;/etc/containerd/certs.d&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后再certs.d目录下面添加你的镜像仓库就好了.</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="run-containerd-里面的是什么"><a href="#run-containerd-里面的是什么" class="headerlink" title="/run/containerd/里面的是什么"></a>/run/containerd/里面的是什么</h3><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240808111628400.png" alt="image-20240808111628400"></p><ol><li><strong>containerd.sock</strong>:</li></ol><ul><li>这是 containerd 的主 Unix socket 文件，用于与 containerd 守护进程进行通信。客户端（例如 Docker 或 Kubernetes）通过这个 socket 文件发送管理指令。</li></ul><ol start="2"><li><strong>containerd.sock.ttrpc</strong>:</li></ol><ul><li>这是 containerd 用于 ttrpc（Tiny Transport RPC）通信的 socket 文件。ttrpc 是一种轻量级的 RPC 框架，用于在性能敏感的环境中提供高效的进程间通信。</li></ul><ol start="3"><li><strong>io.containerd.grpc.v1.cri</strong>:</li></ol><ul><li>这个目录包含与 Kubernetes CRI（Container Runtime Interface）集成相关的 socket 文件和配置。containerd 支持 CRI，使得 Kubernetes 可以直接通过 containerd 来管理容器。</li></ul><ol start="4"><li><strong>io.containerd.runtime.v1.linux</strong>:</li></ol><ul><li>这个目录包含与 v1 版本的 containerd 运行时相关的文件和配置，主要用于 Linux 系统上的容器管理。</li></ul><ol start="5"><li><strong>io.containerd.runtime.v2.task</strong>:</li></ol><ul><li>这个目录包含与 v2 版本的 containerd 任务管理相关的文件和配置。v2 版本引入了一些新的特性和改进，用于更高效地管理容器任务。</li></ul><ol start="6"><li><strong>runc</strong>:</li></ol><ul><li>这是 runc 运行时的目录。runc 是一个 CLI 工具，用于根据 OCI（Open Container Initiative）规范创建和运行容器。containerd 使用 runc 作为默认的容器运行时。</li></ul><ol start="7"><li><strong>s</strong>:</li></ol><ul><li>这个目录的具体用途可能需要根据系统的实际配置来确定。它可能是用于存储临时文件、状态文件或特定插件的目录。</li></ul><h3 id="var-lib-containerd-里面的是什么"><a href="#var-lib-containerd-里面的是什么" class="headerlink" title="/var/lib/containerd 里面的是什么"></a>/var/lib/containerd 里面的是什么</h3><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240808113725285.png" alt="image-20240808113725285"></p><ol><li><strong>io.containerd.content.v1.content:</strong></li></ol><ul><li>存储镜像和容器层的内容，包括所有下载的镜像数据。这里的文件通常以内容地址（例如 SHA256 哈希）进行命名和存储。</li></ul><ol start="2"><li><strong>io.containerd.snapshotter.v1.overlayfs:</strong></li></ol><ul><li>这是一个与文件系统快照相关的目录，特别是使用 OverlayFS 作为存储后端时。这个目录包含快照和层的数据，用于构建和管理容器的文件系统层。</li></ul><ol start="3"><li><strong>io.containerd.snapshotter.v1.btrfs:</strong></li></ol><ul><li>类似于 overlayfs 目录，但用于 Btrfs 文件系统。它存储使用 Btrfs 作为存储后端时的快照和层的数据。</li></ul><ol start="4"><li><strong>io.containerd.snapshotter.v1.devmapper:</strong> </li></ol><ul><li>用于 Device Mapper 存储后端的快照数据，存储容器层的信息。</li></ul><ol start="5"><li><strong>io.containerd.grpc.v1.cri:</strong></li></ol><ul><li>包含与 Kubernetes CRI 集成相关的数据和配置。Kubernetes 通过这个目录与 containerd 进行通信和数据交换。</li></ul><ol start="6"><li><strong>tmpmounts:</strong></li></ol><ul><li>临时挂载点目录，用于存储容器运行时的临时文件和挂载点信息。</li></ul><h3 id="命令工具"><a href="#命令工具" class="headerlink" title="命令工具"></a>命令工具</h3><h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><table><thead><tr><th>命令</th><th>描述</th><th>docker</th><th>ctr</th><th>crictl</th><th>nerdctl</th></tr></thead><tbody><tr><td>显示镜像列表</td><td>显示本地主机上的镜像列表</td><td>docker images</td><td>ctr images list</td><td>crictl images</td><td>nerdctl images list</td></tr><tr><td>下载镜像</td><td>从 registry 中下载指定的镜像</td><td>docker pull</td><td>ctr images pull</td><td>crictl pull</td><td>nerdctl pull</td></tr><tr><td>上传镜像</td><td>将本地的镜像上传到 registry</td><td>docker push</td><td>ctr images push</td><td>不支持</td><td>nerdctl images push</td></tr></tbody></table><h4 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h4><table><thead><tr><th>命令</th><th>描述</th><th>docker</th><th>ctr</th><th>crictl</th><th>nerdctl</th></tr></thead><tbody><tr><td>删除镜像</td><td>删除指定的镜像</td><td>docker rmi</td><td>ctr images remove/delete</td><td>crictl rmi</td><td>nerdctl rmi</td></tr><tr><td>启动容器</td><td>创建并启动容器</td><td>docker run</td><td>ctr run</td><td>crictl run</td><td>nerdctl run</td></tr><tr><td>显示容器列表</td><td>显示本地主机上的容器列表</td><td>docker ps</td><td>ctr tasks ls</td><td>crictl ps</td><td>nerdctl ps</td></tr><tr><td>显示容器详情</td><td>显示容器的详细信息</td><td>docker inspect</td><td>ctr task info</td><td>crictl inspect</td><td>nerdctl inspect</td></tr><tr><td>停止容器</td><td>停止容器的运行</td><td>docker stop</td><td>ctr task kill</td><td>crictl stop</td><td>nerdctl stop</td></tr><tr><td>删除容器</td><td>删除指定的容器</td><td>docker rm</td><td>ctr task delete</td><td>crictl rm</td><td>nerdctl delete</td></tr><tr><td>进入容器</td><td>进入正在运行的容器</td><td>docker exec</td><td>ctr task exec</td><td>crictl exec</td><td>nerdctl exec</td></tr><tr><td>查看容器日志</td><td>显示容器的日志输出</td><td>docker logs</td><td>ctr task logs</td><td>crictl logs</td><td>nerdctl logs</td></tr><tr><td>导出容器</td><td>导出容器文件系统为 tar 包</td><td>docker export</td><td>ctr task export</td><td>不支持</td><td>nerdctl export</td></tr><tr><td>导入容器</td><td>从导出的 tar 包创建一个新的容器</td><td>docker import</td><td>ctr image import</td><td>不支持</td><td>nerdctl import</td></tr><tr><td>构建镜像</td><td>从 Dockerfile 构建镜像</td><td>docker build</td><td>不支持</td><td>不支持</td><td>nerdctl build</td></tr><tr><td>显示网络列表</td><td>显示本地主机上的网络列表</td><td>docker network ls</td><td>ctr network list</td><td>不支持</td><td>nerdctl network ls</td></tr><tr><td>创建网络</td><td>创建一个新的网络</td><td>docker network create</td><td>ctr network create</td><td>不支持</td><td>nerdctl network create</td></tr><tr><td>删除网络</td><td>删除指定的网络</td><td>docker network rm</td><td>ctr network remove</td><td>不支持</td><td>nerdctl network rm</td></tr></tbody></table><h4 id="Containerd-如何存储镜像和容器。⽬录结构是什么样的。是否⽀持-容量限制"><a href="#Containerd-如何存储镜像和容器。⽬录结构是什么样的。是否⽀持-容量限制" class="headerlink" title="Containerd 如何存储镜像和容器。⽬录结构是什么样的。是否⽀持 容量限制"></a>Containerd 如何存储镜像和容器。⽬录结构是什么样的。是否⽀持 容量限制</h4><p>  Containerd 是⼀个容器运⾏时管理程序，它使⽤ OCI（Open Container Initiative）标准来定义容器和镜像。镜像通常被存储在⼀个容器镜像存储库（Container Image Store）中，例如 Docker Hub，或者本地的 OCI 镜像存储库。Containerd 会从存储库中下载镜像，并在本地存储。容器则是使⽤镜像创建的运⾏实例。Containerd 将容器的元数据存储在称为 “snapshots” 的⽬录中。每个容器都有⼀个独⽴的快照⽬录，其中包含容器的根⽂件系统和元数据。Containerd 还⽀持将容器存储在可移动的磁盘上，这种⽅式称为 “offline snapshots”。Containerd ⽀持容器资源限制，可以设置 CPU 和内存的限制，也可以设置 I/O 和⽹络带宽等限制。这些限制是通过使⽤ Linux 内核的 cgroup 和 namespace 功能来实现的。</p><h4 id="Containerd-如何处理⽇志，是否⽀持轮滚"><a href="#Containerd-如何处理⽇志，是否⽀持轮滚" class="headerlink" title="Containerd 如何处理⽇志，是否⽀持轮滚"></a>Containerd 如何处理⽇志，是否⽀持轮滚</h4><p>  Containerd 本身并不负责处理容器的⽇志，⽽是将⽇志处理交给容器运⾏时，如 runc 或 CRI- O。这些容器运⾏时⽀持使⽤各种不同的⽅式来处理容器的⽇志，如直接输出到控制台、将⽇志写⼊⽂件或使⽤⽇志聚合⼯具，如 Fluentd 或ELK Stack。对于容器的⽇志轮滚，⼀般是由容器运⾏时负责实现。例如，runc 可以通过指定 –log-opt max-size 和 –log-opt max-file 参数来控制容器⽇志的⼤⼩和轮滚。当容器⽇志⽂件⼤⼩达到指定的⼤⼩时，runc 会⾃动创建⼀个新的⽇志⽂件，并将旧的⽇志⽂件压缩和删除。类似地，CRI- O 也⽀持使⽤ –log-max-file 和 –log-max-size 参数来控制容器⽇志的轮滚。</p><h4 id="Containerd-重启，是否会导致容器重启"><a href="#Containerd-重启，是否会导致容器重启" class="headerlink" title="Containerd 重启，是否会导致容器重启"></a>Containerd 重启，是否会导致容器重启</h4><p>  当 Containerd 重启时，已经在运⾏的容器不会⽴即停⽌或重启。这是因为容器本身是由容器运⾏时（例如 runc 或CRI- O）管理的，⽽不是由 Containerd 直接控制。因此，Containerd 重启不会直接影响容器的运⾏状态。当 Containerd 重启后，容器运⾏时会重新连接到新的 Containerd 进程，以便继续管理容器。在此过程中，容器运⾏时可能会暂停⼀段时间，导致容器内的应⽤程序暂时⽆法访问，但通常这个时间⾮常短暂，只会影响到容器内正在进⾏的临时操作。需要注意的是，如果 Containerd 重启导致容器存储被破坏或不可⽤，那么容器本身可能会受到影响，因为容器的根⽂<br>件系统和元数据存储在 Containerd 的快照⽬录中。在这种情况下，容器运⾏时可能会⽆法连接到 Containerd，导致容器⽆法正常运⾏。因此，在重启 Containerd 之前，需要确保容器存储的完整性和可⽤性。</p><h4 id="Containerd-的⽹络命名空间是什么样的，⽆-CNI-下的容器，是否⽀持⽹络"><a href="#Containerd-的⽹络命名空间是什么样的，⽆-CNI-下的容器，是否⽀持⽹络" class="headerlink" title="Containerd 的⽹络命名空间是什么样的，⽆ CNI 下的容器，是否⽀持⽹络"></a>Containerd 的⽹络命名空间是什么样的，⽆ CNI 下的容器，是否⽀持⽹络</h4><p>  Containerd 使⽤ Linux 内核的⽹络命名空间（network namespace）来隔离容器的⽹络栈和⽹络配置，以便容器可以拥有⾃⼰独⽴的⽹络栈和⽹络环境。每个容器都有⾃⼰的⽹络命名空间，并且容器之间默认是隔离的，不能相互访问。在没有 CNI（Container Networking Interface）插件的情况下，Containerd 本身并不提供⽹络功能，需要⼿动配置容器的⽹络。可以使⽤ Linux 的⽹络⼯具，如 ip 和 iptables，来⼿动配置容器的⽹络，例如分配 IP 地址、设置路由和防⽕墙规则等。这种⽅式需要⼿动配置和管理，⽐较繁琐。不过，Containerd 可以与 CNI 插件配合使⽤，以便⾃动化配置容器的⽹络。CNI 插件可以在容器创建时⾃动配置⽹络，例如分配 IP 地址、设置⽹络接⼝和路由等。常⻅的 CNI 插件包括 Flannel、Calico、Weave Net 等，它们可以与Containerd 集成，以提供⾃动化的⽹络配置和管理。</p><h4 id="Containerd-有没有-KMEM-泄露-的问题"><a href="#Containerd-有没有-KMEM-泄露-的问题" class="headerlink" title="Containerd 有没有 KMEM 泄露 的问题"></a>Containerd 有没有 KMEM 泄露 的问题</h4><p>  在早期版本的 Containerd 中曾经存在⼀些 KMEM 泄漏的问题。具体来说，这些问题通常与 Containerd 在处理⾼负载情况下使⽤了⼤量的内核内存（KMEM），导致内存泄漏和系统不稳定。不过，Containerd 的开发团队已经在后续版本中修复了这些问题，并采取了⼀些措施来避免 KMEM 泄漏。例如，Containerd 1.4.0 版本中引⼊了 KMEM 限制和监控功能，以便在 Containerd 使⽤⼤量 KMEM 时⾃动降低容器的资源配额，从⽽避免 KMEM 泄漏和系统不稳定。总的来说，如果您使⽤的是较新版本的 Containerd，并且在运⾏期间遇到了 KMEM 泄漏的问题，建议升级到最新版本并检查您的系统配置，以确保已经正确配置了 KMEM 限制和监控。同时，如果您的系统遇到了 KMEM 泄漏等其他问题，也可以向 Containerd 的开发团队报告问题并寻求技术⽀持。</p><h4 id="Containerd-shim-runc-v1与v2的区别"><a href="#Containerd-shim-runc-v1与v2的区别" class="headerlink" title="Containerd-shim-runc-v1与v2的区别"></a>Containerd-shim-runc-v1与v2的区别</h4><p>  containerd-shim-runc-v1 和 containerd-shim-runc-v2 是 containerd 中使⽤的两个 shim 实现。这两个 shim 实现都是使⽤ runc 来启动和管理容器的。containerd-shim-runc-v1 是 containerd 中旧的 shim 实现，它使⽤进程间通信 (IPC) 来与 containerd 守护进程进⾏通信，通常会使⽤ UNIX 域套接字或 FIFO 进⾏通信。它是在 containerd 1.0 中引⼊的，主要⽤于运⾏ Docker 容器，但现在已经被 containerd-shim-runc-v2 替代。containerd-shim-runc-v2 是 containerd 中新的 shim 实现，它使⽤ gRPC 来与 containerd 守护进程进⾏通信。它是在 containerd 1.1 中引⼊的，其⽬标是提供更好的性能和可靠性，并为后续的扩展提供更好的基础设施。与containerd-shim-runc-v1 相⽐，它更加轻量级，并且可以通过 API 配置各种容器和执⾏参数。总的来说，containerd-shim-runc-v2 是 containerd 中更加现代和⾼效的 shim 实现，它⽐ containerd-shimrunc-v1 更具扩展性和可维护性，因此在使⽤ containerd 时应该尽可能地使⽤ containerd-shim-runc-v2。</p><h4 id="Containerd的grpc⽅法是如何注册的？"><a href="#Containerd的grpc⽅法是如何注册的？" class="headerlink" title="Containerd的grpc⽅法是如何注册的？"></a>Containerd的grpc⽅法是如何注册的？</h4><p>   containerd 的 gRPC ⽅法是通过⽣成的 protobuf ⽂件和相应的代码实现的。protobuf ⽂件描述了 containerd ⽀持的API ⽅法和数据结构，然后使⽤这个⽂件⽣成对应的代码（包括客户端和服务器端代码）。这些⾃动⽣成的代码提供了实现⽅法的框架，开发⼈员可以在其中添加⾃⼰的代码以实现具体功能。在 containerd 中，服务器端的 gRPC ⽅法是在 services ⽬录下实现的。每个服务都实现了⼀个接⼝（在 protobuf⽂件中定义），并提供了⼀些⽅法来处理请求。这些⽅法通常采⽤ context 参数来获取请求上下⽂和取消信号，然后使⽤⾃动⽣成的代码处理 protobuf 消息。在这些⽅法中，使⽤的核⼼实现代码通常在 containers、images 或content 等核⼼ package 中实现。服务注册是通过 init 函数实现的，每个服务都在其对应的包中实现了⼀个名为 Register 的函数，该函数在包被导⼊时⾃动运⾏，将⾃⼰注册到 containerd 的 gRPC 服务器上。在 Register 函数中，使⽤<br>server.RegisterService 函数将⾃⼰的服务实现注册到 containerd 的 gRPC 服务器上，以便客户端可以调⽤。</p><h4 id="Containerd与containerd-shim是如何交互的？"><a href="#Containerd与containerd-shim是如何交互的？" class="headerlink" title="Containerd与containerd-shim是如何交互的？"></a>Containerd与containerd-shim是如何交互的？</h4><p>  在 Containerd 中，containerd-shim 是负责启动容器进程并与 Containerd API 通信的组件。Containerd 通过 gRPC接⼝与 containerd-shim 通信，以便进⾏容器的创建、启动、停⽌、删除等操作。具体⽽⾔，Containerd 与containerd-shim 之间的交互过程如下：</p><ol><li>Containerd 使⽤ gRPC 接⼝向 containerd-shim 发送创建容器的请求，包括容器的 ID、镜像、⽂件系统等参数。</li><li>containerd-shim 接收到创建容器的请求后，会根据请求中的参数启动⼀个新的容器进程，并创建⼀个对应的Linux namespace。</li><li>containerd-shim 将容器的 PID、Stdin、Stdout 和 Stderr 等信息发送回给 Containerd，以便后者能够管理和监控容器的运⾏状态。</li><li>在容器运⾏过程中，Containerd 可以通过 gRPC 接⼝向 containerd-shim 发送信号以启动、停⽌、暂停或恢复容器的运⾏。</li><li>当容器进程退出后，containerd-shim 会向 Containerd 发送容器的退出状态和退出码，Containerd 在接收到这些信息后，会更新容器的状态并删除对应的容器对象。需要注意的是，Containerd 和 containerd-shim 都是独⽴的进程，它们之间通过 gRPC 接⼝通信，因此 Containerd和 containerd-shim 可以在不同的计算机上运⾏，这也为 Containerd 的分布式部署提供了便利。</li></ol><h4 id="Containerd-shim与runc是如何交互的？"><a href="#Containerd-shim与runc是如何交互的？" class="headerlink" title="Containerd-shim与runc是如何交互的？"></a>Containerd-shim与runc是如何交互的？</h4><p>  在容器技术中，runc 是⼀个⽤于启动和管理容器的轻量级⼯具，⽽ containerd-shim 是 containerd ⽤于管理容器⽣命周期的代理。在容器启动的过程中，runc 和 containerd-shim 之间会进⾏以下交互：</p><ol><li>Containerd-shim 通过 Containerd API 向 Containerd 发送创建容器的请求。</li><li>Containerd 接收到请求后，将请求转发给 runc 来创建容器。runc 将通过 system call 创建新的容器进程，并设置容器的隔离环境（⽐如 namespace、cgroups、rootfs）等参数。</li><li>runc 启动新的容器进程并返回 PID 给 Containerd-shim。</li><li>Containerd-shim 接收到容器进程的 PID 后，会将 PID 发送回给 Containerd。Containerd 会继续管理和监控容器的⽣命周期。</li><li>在容器运⾏期间，Containerd 可以通过 Containerd API 向 Containerd-shim 发送命令，⽐如停⽌、暂停、恢复、删除容器等操作。</li><li>当容器进程退出后，runc 将容器的退出状态和退出码发送给 Containerd-shim。Containerd-shim 将这些信息发送回给 Containerd，Containerd 将更新容器的状态并删除对应的容器对象。需要注意的是，runc 是⼀个独⽴的⼯具，它与 containerd-shim 的交互是在容器启动时发⽣的。在容器启动成功后，runc 将直接与容器进程交互，⽽ containerd-shim 的作⽤将逐渐变⼩。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;导言&quot;&gt;&lt;a href=&quot;#导言&quot; class=&quot;headerlink&quot; title=&quot;导言&quot;&gt;&lt;/a&gt;导言&lt;/h3&gt;&lt;p&gt;最近在集群中遇到了很多containerd的问题，所以不禁思考我真的懂containerd吗？？?&lt;/p&gt;
&lt;h3 id=&quot;前提&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/categories/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes-StorageClass实践2</title>
    <link href="https://kalyan-zitiu.github.io/2024/08/05/Kubernetes-StorageClass%E5%AE%9E%E8%B7%B52/"/>
    <id>https://kalyan-zitiu.github.io/2024/08/05/Kubernetes-StorageClass%E5%AE%9E%E8%B7%B52/</id>
    <published>2024-08-05T02:16:48.000Z</published>
    <updated>2024-08-08T06:04:57.432Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>你需要提前了解，hwameistor的组件生命周期管理：</p><h3 id="1-LocalDiskManager"><a href="#1-LocalDiskManager" class="headerlink" title="1. LocalDiskManager"></a>1. LocalDiskManager</h3><p><strong>作用</strong>: <code>LocalDiskManager</code> 负责管理节点上的物理磁盘资源。它发现、监控和维护节点的本地磁盘信息，确保系统对可用磁盘资源的了解是最新的。</p><p><strong>生命周期管理</strong>:</p><ul><li><strong>启动</strong>: 当 <code>LocalDiskManager</code> 启动时，它扫描节点上的所有可用磁盘，收集磁盘的元数据（例如大小、型号、状态等）。</li><li><strong>运行中</strong>: 持续监控磁盘状态变化，更新磁盘元数据信息，并根据需要调整磁盘的可用性状态。</li><li><strong>停止</strong>: 在组件停止时，需要确保停止对磁盘的监控，并正确释放资源。</li></ul><h3 id="2-LocalStorage"><a href="#2-LocalStorage" class="headerlink" title="2. LocalStorage"></a>2. LocalStorage</h3><p><strong>作用</strong>: <code>LocalStorage</code> 提供节点级别的存储资源管理。它负责将物理磁盘抽象为可用的存储卷，并执行卷的创建、删除、扩展等操作。</p><p><strong>生命周期管理</strong>:</p><ul><li><strong>启动</strong>: 初始化本地存储卷的管理逻辑，确保节点上的物理磁盘可以被正确识别和使用。</li><li><strong>运行中</strong>: 管理存储卷的生命周期，包括创建、删除、扩展、快照等操作，监控卷的健康状态。</li><li><strong>停止</strong>: 停止管理存储卷，确保所有资源被安全释放。</li></ul><h3 id="3-Scheduler"><a href="#3-Scheduler" class="headerlink" title="3. Scheduler"></a>3. Scheduler</h3><p><strong>作用</strong>: <code>Scheduler</code> 是一个自定义调度器插件，用于优化工作负载调度到具有特定存储要求的节点上。</p><p><strong>生命周期管理</strong>:</p><ul><li><strong>启动</strong>: 注册自定义调度逻辑，将其集成到 Kubernetes 调度流程中。</li><li><strong>运行中</strong>: 根据工作负载的存储需求和节点的存储资源情况，执行优化调度。</li><li><strong>停止</strong>: 取消注册自定义调度逻辑，从 Kubernetes 调度器中安全移除。</li></ul><h3 id="4-AdmissionController"><a href="#4-AdmissionController" class="headerlink" title="4. AdmissionController"></a>4. AdmissionController</h3><p><strong>作用</strong>: <code>AdmissionController</code> 在工作负载被提交到 Kubernetes 集群时，对其进行预处理，确保其符合存储策略和要求。</p><p><strong>生命周期管理</strong>:</p><ul><li><strong>启动</strong>: 注册到 Kubernetes 的准入控制器链中，准备对即将创建的资源进行预处理。</li><li><strong>运行中</strong>: 拦截工作负载请求，根据存储策略进行验证和调整。</li><li><strong>停止</strong>: 从准入控制器链中移除，停止对新请求的拦截和处理。</li></ul><h3 id="5-VolumeEvictor"><a href="#5-VolumeEvictor" class="headerlink" title="5. VolumeEvictor"></a>5. VolumeEvictor</h3><p><strong>作用</strong>: <code>VolumeEvictor</code> 负责在节点维护或失败时，将存储卷从受影响的节点上安全地迁移到其他节点。</p><p><strong>生命周期管理</strong>:</p><ul><li><strong>启动</strong>: 初始化卷迁移逻辑，确保在节点发生问题时，卷可以被安全转移。</li><li><strong>运行中</strong>: 持续监控节点状态和卷的健康状况，执行必要的迁移操作。</li><li><strong>停止</strong>: 停止监控和迁移操作，确保当前迁移过程安全完成。</li></ul><h3 id="6-Exporter"><a href="#6-Exporter" class="headerlink" title="6. Exporter"></a>6. Exporter</h3><p><strong>作用</strong>: <code>Exporter</code> 收集和导出存储系统的监控指标，供外部监控系统（如 Prometheus）使用。</p><p><strong>生命周期管理</strong>:</p><ul><li><strong>启动</strong>: 初始化监控指标的收集和导出逻辑。</li><li><strong>运行中</strong>: 持续收集系统指标，提供给监控系统进行实时监控和分析。</li><li><strong>停止</strong>: 停止指标的收集和导出，释放相关资源。</li></ul><h3 id="7-Apiserver"><a href="#7-Apiserver" class="headerlink" title="7. Apiserver"></a>7. Apiserver</h3><p><strong>作用</strong>: <code>Apiserver</code> 提供对 HwameiStor 的管理接口，使用户能够通过 RESTful API 进行操作。</p><p><strong>生命周期管理</strong>:</p><ul><li><strong>启动</strong>: 初始化 API 服务，注册可用的接口端点。</li><li><strong>运行中</strong>: 处理用户请求，执行存储管理操作。</li><li><strong>停止</strong>: 停止 API 服务，确保当前请求被正确处理完成。</li></ul><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>手速StorageClass用hwameistor的方式进行pvc申领动态制备PV</p><h2 id="简要步骤"><a href="#简要步骤" class="headerlink" title="简要步骤"></a>简要步骤</h2><ol><li>保证helm存在</li><li>添加 hwameistor-operator Helm Repo</li><li>通过hwameistor-operator部署HwameiStor</li></ol><h2 id="amp-amp-实战开始"><a href="#amp-amp-实战开始" class="headerlink" title="@&amp;^%!*&amp;@$实战开始"></a>@&amp;^%!*&amp;@$实战开始</h2><h3 id="检查是否有空盘，至于hwameistor是否能再无空盘情况下中断安装后续再尝试"><a href="#检查是否有空盘，至于hwameistor是否能再无空盘情况下中断安装后续再尝试" class="headerlink" title="检查是否有空盘，至于hwameistor是否能再无空盘情况下中断安装后续再尝试"></a>检查是否有空盘，至于hwameistor是否能再无空盘情况下中断安装后续再尝试</h3><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240805105748731.png" alt="image-20240805105748731"></p><h3 id="添加源"><a href="#添加源" class="headerlink" title="添加源"></a>添加源</h3><p>其实这个步骤是挺简单的，全都是自动创建，所以建议就是最后需要了解一下改csi驱动的特点。比如分布式以及自动搜盘。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm repo add hwameistor-operator https://hwameistor.io/hwameistor-operator</span><br><span class="line">helm repo update hwameistor-operator</span><br></pre></td></tr></table></figure><h3 id="通过hwameistor-operator进行部署HwameiStor"><a href="#通过hwameistor-operator进行部署HwameiStor" class="headerlink" title="通过hwameistor-operator进行部署HwameiStor"></a>通过hwameistor-operator进行部署HwameiStor</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install hwameistor-operator hwameistor-operator/hwameistor-operator -n hwameistor --create-namespace</span><br></pre></td></tr></table></figure><p>ps:HwameiStor默认会把所有干净的磁盘纳入到LSD的存储池里面，但是也可以预留，通过helm的values来设置</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">--<span class="built_in">set</span> diskReserve\[0\].nodeName=node1 \</span><br><span class="line">--<span class="built_in">set</span> diskReserve\[0\].devices=&#123;/dev/sdc\,/dev/sdd&#125; \</span><br><span class="line">--<span class="built_in">set</span> diskReserve\[1\].nodeName=node2 \</span><br><span class="line">--<span class="built_in">set</span> diskReserve\[1\].devices=&#123;/dev/sdc\,/dev/sde&#125;</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -f diskReserve.yaml</span></span><br><span class="line"><span class="comment"># diskReserve.yaml 如下</span></span><br><span class="line"><span class="attr">diskReserve:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">nodeName:</span> <span class="string">node1</span></span><br><span class="line">  <span class="attr">devices:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/dev/sdc</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/dev/sdd</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">nodeName:</span> <span class="string">node2</span></span><br><span class="line">  <span class="attr">devices:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/dev/sdc</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">/dev/sde</span></span><br></pre></td></tr></table></figure><h3 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h3><p>理论来说，镜像拉取没有问题的话，就基本都可以了，HwameiStor就是这么的nb，可以自己做完所有事情。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前提&quot;&gt;&lt;a href=&quot;#前提&quot; class=&quot;headerlink&quot; title=&quot;前提&quot;&gt;&lt;/a&gt;前提&lt;/h2&gt;&lt;p&gt;你需要提前了解，hwameistor的组件生命周期管理：&lt;/p&gt;
&lt;h3 id=&quot;1-LocalDiskManager&quot;&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/categories/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes-StorageClass实践1</title>
    <link href="https://kalyan-zitiu.github.io/2024/08/01/Kubernetes%E5%AD%98%E5%82%A8%E5%AE%9E%E6%88%98/"/>
    <id>https://kalyan-zitiu.github.io/2024/08/01/Kubernetes%E5%AD%98%E5%82%A8%E5%AE%9E%E6%88%98/</id>
    <published>2024-08-01T02:16:47.000Z</published>
    <updated>2024-08-01T07:52:21.171Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h3><p>该实战基于假设了解并清楚，<strong>ServiceAccount</strong>，<strong>ClusterRole</strong>，<strong>ClusterRoleBinding</strong>等<br>以下是简要介绍：</p><ol><li>ServiceAccount：为Pod提供了一个身份，允许Pod与Kubernetes API进行安全交互。Local Path Provisioner需要访问和管理PV、PVC、Nodes等资源</li><li>ClusterRole：定义了一组权限，允许某个身份（如ServiceAccount）对Kubernetes集群中的资源执行特定操作。</li><li>ClusterRoleBinding：ClusterRoleBinding将ClusterRole与一个或多个主体（如ServiceAccount）绑定，以便这些主体获得ClusterRole定义的权限<h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3>手撕StorageClass用rancher的local-path的方式进行PVC申领动态制备PV</li></ol><h3 id="简要步骤"><a href="#简要步骤" class="headerlink" title="简要步骤"></a>简要步骤</h3><ol><li>建立命名空间进行资源隔离</li><li>创建ServiceAccount、ClusterRole和ClusterRoleBinding（前提解释）</li><li>创建deploy，控制pod副本数量</li><li>创建configMap，存储不含机密信息的配置数据。（参考：存储基础）</li><li>创建StorageClass（参考第4条）</li></ol><h3 id="废话不多说-￥-……-amp-实战开始"><a href="#废话不多说-￥-……-amp-实战开始" class="headerlink" title="废话不多说@#￥%……&amp;*实战开始"></a>废话不多说@#￥%……&amp;*实战开始</h3><h4 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a>namespace</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 好的，已经成功一半了</span></span><br><span class="line">kubectl create namespace(ns) local-path-storage</span><br></pre></td></tr></table></figure><h4 id="ServiceAccount"><a href="#ServiceAccount" class="headerlink" title="ServiceAccount"></a>ServiceAccount</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner-service-account</span><br><span class="line">  namespace: local-path-storage </span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240801104527213.png" alt="image-20240801104527213"></p><h4 id="ClusterRole，直接拿官方的"><a href="#ClusterRole，直接拿官方的" class="headerlink" title="ClusterRole，直接拿官方的"></a>ClusterRole，直接拿官方的</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1 <span class="comment"># 指定API版本，这里是rbac.authorization.k8s.io/v1</span></span><br><span class="line">kind: ClusterRole <span class="comment"># 资源类型，这里是ClusterRole，表示集群级别的权限定义</span></span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner-role <span class="comment"># ClusterRole的名称，这里是local-path-provisioner-role</span></span><br><span class="line">rules: <span class="comment"># 定义该角色的权限规则列表</span></span><br><span class="line">- apiGroups: [<span class="string">&quot;&quot;</span>] <span class="comment"># 指定API组，空字符串表示核心API组</span></span><br><span class="line">  resources: [<span class="string">&quot;nodes&quot;</span>, <span class="string">&quot;persistentvolumeclaims&quot;</span>, <span class="string">&quot;persistentvolumes&quot;</span>] <span class="comment"># 资源类型列表，包括nodes、persistentvolumeclaims和persistentvolumes</span></span><br><span class="line">  verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>] <span class="comment"># 允许的操作，包括获取、列出、监视、创建和删除</span></span><br><span class="line">- apiGroups: [<span class="string">&quot;&quot;</span>] <span class="comment"># 再次指定核心API组</span></span><br><span class="line">  resources: [<span class="string">&quot;pods&quot;</span>] <span class="comment"># 资源类型是pods</span></span><br><span class="line">  verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>] <span class="comment"># 允许的操作，包括获取、列出和监视</span></span><br><span class="line">- apiGroups: [<span class="string">&quot;storage.k8s.io&quot;</span>] <span class="comment"># 指定API组storage.k8s.io</span></span><br><span class="line">  resources: [<span class="string">&quot;storageclasses&quot;</span>] <span class="comment"># 资源类型是storageclasses</span></span><br><span class="line">  verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>] <span class="comment"># 允许的操作，包括获取、列出和监视</span></span><br><span class="line">- apiGroups: [<span class="string">&quot;batch&quot;</span>, <span class="string">&quot;extensions&quot;</span>] <span class="comment"># 指定API组batch和extensions</span></span><br><span class="line">  resources: [<span class="string">&quot;jobs&quot;</span>] <span class="comment"># 资源类型是jobs</span></span><br><span class="line">  verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;delete&quot;</span>] <span class="comment"># 允许的操作，包括获取、列出、监视、创建和删除</span></span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240801105301424.png" alt="image-20240801105301424"></p><h4 id="ClusterRoleBinding"><a href="#ClusterRoleBinding" class="headerlink" title="ClusterRoleBinding"></a>ClusterRoleBinding</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1 <span class="comment"># 指定API版本，这里是rbac.authorization.k8s.io/v1</span></span><br><span class="line">kind: ClusterRoleBinding <span class="comment"># 资源类型，这里是ClusterRoleBinding，表示集群级别的角色绑定</span></span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner-bindings <span class="comment"># ClusterRoleBinding的名称，这里是local-path-provisioner-bindings</span></span><br><span class="line">roleRef: <span class="comment"># 指定要绑定的角色</span></span><br><span class="line">  apiGroup: rbac.authorization.k8s.io <span class="comment"># 角色所属的API组，这里是rbac.authorization.k8s.io</span></span><br><span class="line">  kind: ClusterRole <span class="comment"># 角色类型，这里是ClusterRole</span></span><br><span class="line">  name: local-path-provisioner-role <span class="comment"># 角色名称，这里是local-path-provisioner-role</span></span><br><span class="line">subjects: <span class="comment"># 定义该角色绑定的主体列表</span></span><br><span class="line">- kind: ServiceAccount <span class="comment"># 主体类型，这里是ServiceAccount（服务账户）</span></span><br><span class="line">  name: local-path-provisioner-service-account <span class="comment"># 服务账户的名称，这里是local-path-provisioner-service-account</span></span><br><span class="line">  namespace: local-path-storage <span class="comment"># 服务账户所属的命名空间，这里是local-path-storage</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240801105734783.png" alt="image-20240801105734783"></p><h4 id="Deploy"><a href="#Deploy" class="headerlink" title="Deploy"></a>Deploy</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: apps/v1 <span class="comment"># 指定API版本，这里是apps/v1</span></span><br><span class="line">kind: Deployment <span class="comment"># 资源类型，这里是Deployment，表示部署一个应用</span></span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner <span class="comment"># Deployment的名称，这里是local-path-provisioner</span></span><br><span class="line">  namespace: local-path-storage <span class="comment"># Deployment所属的命名空间，这里是local-path-storage</span></span><br><span class="line">spec: <span class="comment"># Deployment的规格定义</span></span><br><span class="line">  replicas: 1 <span class="comment"># 副本数，这里是1，表示只部署一个副本</span></span><br><span class="line">  selector: <span class="comment"># 用于选择要部署的Pod</span></span><br><span class="line">    matchLabels:</span><br><span class="line">    <span class="comment"># 标签选择器，选择标签为app: local-path-provisioner的Pod</span></span><br><span class="line">      app: local-path-provisioner </span><br><span class="line">  template: <span class="comment"># Pod模板定义</span></span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: local-path-provisioner <span class="comment"># 为Pod设置的标签，这里是app: local-path-provisioner</span></span><br><span class="line">    spec: <span class="comment"># Pod的规格定义</span></span><br><span class="line">    <span class="comment"># 使用的服务账户名称，这里是local-path-provisioner-service-account</span></span><br><span class="line">      serviceAccountName: local-path-provisioner-service-account </span><br><span class="line">      containers: <span class="comment"># 容器列表</span></span><br><span class="line">      - name: provisioner <span class="comment"># 容器名称，这里是provisioner</span></span><br><span class="line">      <span class="comment"># 容器镜像，这里是rancher/local-path-provisioner:latest</span></span><br><span class="line">        image: rancher/local-path-provisioner:master-head <span class="comment"># 换加速啊啊啊啊啊啊啊啊叼毛</span></span><br><span class="line">        imagePullPolicy: Always <span class="comment"># 镜像拉取策略，总是拉取最新的镜像</span></span><br><span class="line">        volumeMounts: <span class="comment"># 挂载的卷列表</span></span><br><span class="line">        - name: config-volume <span class="comment"># 卷名称，这里是config-volume</span></span><br><span class="line">          mountPath: /etc/config <span class="comment"># 挂载路径，这里是/etc/config</span></span><br><span class="line">        - name: local-path-storage <span class="comment"># 卷名称，这里是local-path-storage</span></span><br><span class="line">          mountPath: /opt/local-path-storage <span class="comment"># 挂载路径，这里是/opt/local-path-storage</span></span><br><span class="line">      volumes: <span class="comment"># 定义Pod中使用的卷</span></span><br><span class="line">      - name: config-volume <span class="comment"># 卷名称，这里是config-volume</span></span><br><span class="line">        configMap: <span class="comment"># 使用ConfigMap作为卷</span></span><br><span class="line">          name: local-path-config <span class="comment"># ConfigMap的名称，这里是local-path-config</span></span><br><span class="line">      - name: local-path-storage <span class="comment"># 卷名称，这里是local-path-storage</span></span><br><span class="line">        hostPath: <span class="comment"># 使用主机路径作为卷</span></span><br><span class="line">          path: /opt/local-path-storage <span class="comment"># 主机路径，这里是/opt/local-path-storage</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240801110044796.png" alt="image-20240801110044796"></p><h4 id="config"><a href="#config" class="headerlink" title="config"></a>config</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1 <span class="comment"># 指定API版本，这里是v1</span></span><br><span class="line">kind: ConfigMap <span class="comment"># 资源类型，这里是ConfigMap，用于存储配置信息</span></span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-config <span class="comment"># ConfigMap的名称，这里是local-path-config</span></span><br><span class="line">  namespace: local-path-storage <span class="comment"># ConfigMap所属的命名空间，这里是local-path-storage</span></span><br><span class="line">data: <span class="comment"># 配置数据</span></span><br><span class="line">  config.json: | <span class="comment"># 配置文件的名称，这里是config.json，使用多行字符串格式</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;nodePathMap&quot;</span>:[</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">&quot;node&quot;</span>:<span class="string">&quot;DEFAULT_PATH_FOR_NON_LISTED_NODES&quot;</span>, <span class="comment"># 节点名称，表示未列出的节点的默认路径</span></span><br><span class="line">          <span class="string">&quot;paths&quot;</span>:[<span class="string">&quot;/opt/local-path-storage&quot;</span>] <span class="comment"># 路径列表，这里是/opt/local-path-storage</span></span><br><span class="line">        &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240801110611178.png" alt="image-20240801110611178"></p><h4 id="StorageClass"><a href="#StorageClass" class="headerlink" title="StorageClass"></a>StorageClass</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: storage.k8s.io/v1 <span class="comment"># 指定API版本，这里是storage.k8s.io/v1</span></span><br><span class="line">kind: StorageClass <span class="comment"># 资源类型，这里是StorageClass，表示存储类</span></span><br><span class="line">metadata:</span><br><span class="line">  name: local-path <span class="comment"># StorageClass的名称，这里是local-path</span></span><br><span class="line">provisioner: rancher.io/local-path <span class="comment"># 指定的provisioner，这里是rancher.io/local-path</span></span><br><span class="line">reclaimPolicy: Delete <span class="comment"># 回收策略，这里是Delete，表示当持久卷被释放时删除它</span></span><br><span class="line"><span class="comment"># 卷绑定模式，这里是WaitForFirstConsumer，表示延迟绑定，直到Pod被调度到节点上</span></span><br><span class="line">volumeBindingMode: WaitForFirstConsumer </span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240801110811688.png" alt="image-20240801110811688"></p><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><h5 id="创建pvc-yaml"><a href="#创建pvc-yaml" class="headerlink" title="创建pvc yaml"></a>创建pvc yaml</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: my-local-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 1Gi</span><br><span class="line">  storageClassName: local-path</span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240801142550578.png" alt="image-20240801142550578"></p><p>因为设计的是WaitForFirstConsumer，所以需要设计一个pod</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: myapp-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: myapp-container</span><br><span class="line">    image: m.daocloud.io/docker.io/library/nginx</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: <span class="string">&quot;/usr/share/nginx/html&quot;</span></span><br><span class="line">      name: my-local-storage</span><br><span class="line">  volumes:</span><br><span class="line">  - name: my-local-storage</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: my-local-pvc</span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240801145710135.png" alt="image-20240801145710135"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>以上的配置文件只是一个参考，实际的可以用官方的配置文件,需要注意的是换加速镜像地址时候要换全哦，带image的都换。配置不正确多半进入cashloopbackoff的问题。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-storage</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner-service-account</span><br><span class="line">  namespace: local-path-storage</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner-role</span><br><span class="line">  namespace: local-path-storage</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;patch&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;delete&quot;</span>]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner-role</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;nodes&quot;</span>, <span class="string">&quot;persistentvolumeclaims&quot;</span>, <span class="string">&quot;configmaps&quot;</span>, <span class="string">&quot;pods&quot;</span>, <span class="string">&quot;pods/log&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line">  - apiGroups: [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;persistentvolumes&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>, <span class="string">&quot;create&quot;</span>, <span class="string">&quot;patch&quot;</span>, <span class="string">&quot;update&quot;</span>, <span class="string">&quot;delete&quot;</span>]</span><br><span class="line">  - apiGroups: [<span class="string">&quot;&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;events&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;create&quot;</span>, <span class="string">&quot;patch&quot;</span>]</span><br><span class="line">  - apiGroups: [<span class="string">&quot;storage.k8s.io&quot;</span>]</span><br><span class="line">    resources: [<span class="string">&quot;storageclasses&quot;</span>]</span><br><span class="line">    verbs: [<span class="string">&quot;get&quot;</span>, <span class="string">&quot;list&quot;</span>, <span class="string">&quot;watch&quot;</span>]</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner-bind</span><br><span class="line">  namespace: local-path-storage</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name: local-path-provisioner-role</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: local-path-provisioner-service-account</span><br><span class="line">    namespace: local-path-storage</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner-bind</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: local-path-provisioner-role</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: local-path-provisioner-service-account</span><br><span class="line">    namespace: local-path-storage</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-provisioner</span><br><span class="line">  namespace: local-path-storage</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">app: local-path-provisioner</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: local-path-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: local-path-provisioner-service-account</span><br><span class="line">      containers:</span><br><span class="line">        - name: local-path-provisioner</span><br><span class="line">          image: docker.m.daocloud.io/rancher/local-path-provisioner:master-head  <span class="comment"># ps：换</span></span><br><span class="line">          imagePullPolicy: IfNotPresent</span><br><span class="line">          <span class="built_in">command</span>:</span><br><span class="line">            - local-path-provisioner</span><br><span class="line">            - --debug</span><br><span class="line">            - start</span><br><span class="line">            - --config</span><br><span class="line">            - /etc/config/config.json</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: config-volume</span><br><span class="line">              mountPath: /etc/config/</span><br><span class="line">          <span class="built_in">env</span>:</span><br><span class="line">            - name: POD_NAMESPACE</span><br><span class="line">              valueFrom:</span><br><span class="line">                fieldRef:</span><br><span class="line">                  fieldPath: metadata.namespace</span><br><span class="line">            - name: CONFIG_MOUNT_PATH</span><br><span class="line">              value: /etc/config/</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: local-path-config</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path</span><br><span class="line">provisioner: rancher.io/local-path</span><br><span class="line">volumeBindingMode: Immediate</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: local-path-config</span><br><span class="line">  namespace: local-path-storage</span><br><span class="line">data:</span><br><span class="line">  config.json: |-</span><br><span class="line">    &#123;</span><br><span class="line">            <span class="string">&quot;nodePathMap&quot;</span>:[</span><br><span class="line">            &#123;</span><br><span class="line">                    <span class="string">&quot;node&quot;</span>:<span class="string">&quot;DEFAULT_PATH_FOR_NON_LISTED_NODES&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;paths&quot;</span>:[<span class="string">&quot;/opt/local-path-provisioner&quot;</span>]</span><br><span class="line">            &#125;</span><br><span class="line">            ]</span><br><span class="line">    &#125;</span><br><span class="line">  setup: |-</span><br><span class="line">    <span class="comment">#!/bin/sh</span></span><br><span class="line">    <span class="built_in">set</span> -eu</span><br><span class="line">    <span class="built_in">mkdir</span> -m 0777 -p <span class="string">&quot;<span class="variable">$VOL_DIR</span>&quot;</span></span><br><span class="line">  teardown: |-</span><br><span class="line">    <span class="comment">#!/bin/sh</span></span><br><span class="line">    <span class="built_in">set</span> -eu</span><br><span class="line">    <span class="built_in">rm</span> -rf <span class="string">&quot;<span class="variable">$VOL_DIR</span>&quot;</span></span><br><span class="line">  helperPod.yaml: |-</span><br><span class="line">    apiVersion: v1</span><br><span class="line">    kind: Pod</span><br><span class="line">    metadata:</span><br><span class="line">      name: helper-pod</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-node-critical</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: node.kubernetes.io/disk-pressure</span><br><span class="line">          operator: Exists</span><br><span class="line">          effect: NoSchedule</span><br><span class="line">      containers:</span><br><span class="line">      - name: helper-pod</span><br><span class="line">        image: m.daocloud.io/docker.io/library/busybox <span class="comment"># ps：换</span></span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">手撕StorageClass用local-path的方式进行PVC申领动态制备PV</summary>
    
    
    
    <category term="Kubernentes" scheme="https://kalyan-zitiu.github.io/categories/Kubernentes/"/>
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 证书</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/31/Kubernetes_pki/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/31/Kubernetes_pki/</id>
    <published>2024-07-31T06:58:28.000Z</published>
    <updated>2024-08-01T08:07:45.606Z</updated>
    
    <content type="html"><![CDATA[<h3 id="PKI证书"><a href="#PKI证书" class="headerlink" title="PKI证书"></a>PKI证书</h3><p>kubernetes是需要PKI才能执行多数操作:</p><ol><li>kubelet的客户端证书:用于API服务器身份验证</li><li>kubelet服务证书:用于API服务器与Kubelet的会话</li><li>API服务器端点证书:用于HTTPS加密，确保通信加密</li><li>集群管理员的客户端证书：管理员（我）的工作证明</li><li>API 服务器的客户端证书：用于和 Kubelet 的会话</li><li>API 服务器的客户端证书：用于和 etcd 的会话</li><li>控制器管理器的客户端证书或 kubeconfig：用于和 API 服务器的会话</li><li>调度器的客户端证书或 kubeconfig：用于和 API 服务器的会话</li><li>前端代理的客户端及服务端证书</li></ol><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240731153548422.png" alt="image-20240731153548422"></p><h3 id="自定义证书"><a href="#自定义证书" class="headerlink" title="自定义证书"></a>自定义证书</h3><ul><li>首先用kubeadm创建的kubernetes会生成集群所需地全部证书。</li><li>其次你可以自定义，通过<code>--cert-dir</code>来指定不同的目录</li><li>默认位置/etc/kubernetes/pki里面</li><li><code>kubeadm init --cert-dir /自定义目录/</code>或者在kubeadm自定义的config的<code>certificatesDir</code>字段进行目录指定</li></ul><h3 id="外部CA"><a href="#外部CA" class="headerlink" title="外部CA"></a>外部CA</h3><p>指在 Kubernetes 集群中使用由外部证书颁发机构（CA）签发的证书，而不是由 kubeadm 自行生成和管理 CA 证书。这种模式下，所有的证书和密钥都是由外部的 CA 签发的，提供更高的安全性和信任度，尤其在有严格合规性要求的环境中。</p><h4 id="使用外部-CA-模式配置-Kubernetes-集群"><a href="#使用外部-CA-模式配置-Kubernetes-集群" class="headerlink" title="使用外部 CA 模式配置 Kubernetes 集群"></a>使用外部 CA 模式配置 Kubernetes 集群</h4><ol><li><p><strong>准备外部 CA 签发的证书和密钥</strong></p><ul><li>你需要从外部 CA 获取以下证书和密钥：<ul><li>CA 证书 (<code>ca.crt</code>)</li><li>kube-apiserver 证书及其密钥 (<code>apiserver.crt</code> 和 <code>apiserver.key</code>)</li><li>kube-controller-manager 证书及其密钥（可选，如果需要）</li><li>kube-scheduler 证书及其密钥（可选，如果需要）</li><li>其他组件所需的证书及其密钥（如 etcd 等）</li></ul></li></ul></li><li><p><strong>创建并配置 Kubernetes 配置文件</strong></p><ul><li>创建一个 kubeadm 配置文件，如 <code>kubeadm-config.yaml</code>，并在其中指定 <code>certificatesDir</code> 和 <code>ClusterConfiguration</code>。示例如下：<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">stable-1.21</span></span><br><span class="line"><span class="attr">certificatesDir:</span> <span class="string">/etc/kubernetes/pki</span></span><br><span class="line"><span class="attr">apiServer:</span></span><br><span class="line">  <span class="attr">certSANs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;your.domain.com&quot;</span></span><br><span class="line">   <span class="attr">extraArgs:</span></span><br><span class="line">      <span class="attr">&quot;tls-cert-file&quot;:</span> <span class="string">&quot;/etc/kubernetes/pki/apiserver.crt&quot;</span></span><br><span class="line">      <span class="attr">&quot;tls-private-key-file&quot;:</span> <span class="string">&quot;/etc/kubernetes/pki/apiserver.key&quot;</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>将外部 CA 签发的证书和密钥放置在指定目录</strong></p><ul><li>复制外部 CA 签发的证书和密钥到 <code>/etc/kubernetes/pki</code> 目录或你在配置文件中指定</li></ul></li></ol><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">cp</span> /path/to/ca.crt /etc/kubernetes/pki/ca.crt</span><br><span class="line">sudo <span class="built_in">cp</span> /path/to/apiserver.crt /etc/kubernetes/pki/apiserver.crt</span><br><span class="line">sudo <span class="built_in">cp</span> /path/to/apiserver.key /etc/kubernetes/pki/apiserver.key</span><br></pre></td></tr></table></figure><ol start="4"><li><strong>运行 kubeadm 初始化命令</strong></li></ol><ul><li>使用 kubeadm 初始化命令并指定配置文件来初始化 Kubernetes 集群：<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo kubeadm init --config kubeadm-config.yaml</span><br></pre></td></tr></table></figure></li></ul><h3 id="检查证书"><a href="#检查证书" class="headerlink" title="检查证书"></a>检查证书</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubeadm certs check-expiration</span><br></pre></td></tr></table></figure><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240731161509499.png" alt="image-20240731161509499"></p><p>ps:</p><ol><li><p>kubeadm不能管理外部ca</p></li><li><p>没有kubelet.conf的原因是kubeadm会将kubelet配置为自动更新证书，轮换在<code>/var/lib/kubelet/pki</code></p></li></ol><ul><li>轮询失败暂时参考：<a href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#kubelet-client-cert">https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/#kubelet-client-cert</a></li></ul><h3 id="自动更新证书"><a href="#自动更新证书" class="headerlink" title="自动更新证书"></a>自动更新证书</h3><p><code>kubeadm</code> 提供了一种机制，在集群控制面（control plane）升级时自动更新所有证书。这种方式简化了证书管理，并确保在定期升级 Kubernetes 版本时保持集群的安全性。下面是详细的操作步骤和相关说明。</p><h4 id="自动更新证书的机制"><a href="#自动更新证书的机制" class="headerlink" title="自动更新证书的机制"></a>自动更新证书的机制</h4><p>当你使用 <code>kubeadm upgrade apply</code> 命令升级控制面节点时，<code>kubeadm</code> 会自动更新所有的证书。</p><p>进。</p><h4 id="禁用自动证书更新"><a href="#禁用自动证书更新" class="headerlink" title="禁用自动证书更新"></a>禁用自动证书更新</h4><p>如果你有更复杂的证书管理需求，可以选择在升级时禁用自动证书更新。可以通过传递 <code>--certificate-renewal=false</code> 参数来实现。</p><ol><li><p><strong>升级控制面节点时禁用证书更新</strong>：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo kubeadm upgrade apply v1.xx.x --certificate-renewal=<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>其中 <code>v1.xx.x</code> 为目标 Kubernetes 版本。</p></li><li><p><strong>升级 worker 节点时禁用证书更新</strong>：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo kubeadm upgrade node --certificate-renewal=<span class="literal">false</span></span><br></pre></td></tr></table></figure></li></ol><h4 id="手动启用证书更新"><a href="#手动启用证书更新" class="headerlink" title="手动启用证书更新"></a>手动启用证书更新</h4><p>在 Kubernetes 1.17 版本之前，<code>kubeadm upgrade node</code> 命令的 <code>--certificate-renewal</code> 参数默认值为 <code>false</code>，需要显式地设置为 <code>true</code>。</p><h5 id="显式启用证书更新的操作步骤"><a href="#显式启用证书更新的操作步骤" class="headerlink" title="显式启用证书更新的操作步骤"></a>显式启用证书更新的操作步骤</h5><ol><li><p><strong>升级控制面节点时显式启用证书更新</strong>：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo kubeadm upgrade apply v1.xx.x --certificate-renewal=<span class="literal">true</span></span><br></pre></td></tr></table></figure></li><li><p><strong>升级 worker 节点时显式启用证书更新</strong>：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo kubeadm upgrade node --certificate-renewal=<span class="literal">true</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="手动更新证书"><a href="#手动更新证书" class="headerlink" title="手动更新证书"></a>手动更新证书</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 执行完此命令之后你需要重启控制面 Pod,运行了一个 HA 集群，这个命令需要在所有控制面板节点上执行。</span></span><br><span class="line">kubeadm certs renew (all)</span><br></pre></td></tr></table></figure><p>ps:kubeadm通常会把<code>admin.conf</code> 证书复制到 <code>$HOME/.kube/config</code> 中，在这样的系统中，为了在更新 <code>admin.conf</code> 后更新 <code>$HOME/.kube/config</code> 的内容， 你必须运行以下命令：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;PKI证书&quot;&gt;&lt;a href=&quot;#PKI证书&quot; class=&quot;headerlink&quot; title=&quot;PKI证书&quot;&gt;&lt;/a&gt;PKI证书&lt;/h3&gt;&lt;p&gt;kubernetes是需要PKI才能执行多数操作:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;kubelet的客户端证书:用于API</summary>
      
    
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/categories/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes存储基础</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/30/Kubernetes%E5%AD%98%E5%82%A8/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/30/Kubernetes%E5%AD%98%E5%82%A8/</id>
    <published>2024-07-30T07:42:49.000Z</published>
    <updated>2024-08-01T07:53:40.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="卷"><a href="#卷" class="headerlink" title="卷"></a>卷</h2><h3 id="PVC"><a href="#PVC" class="headerlink" title="PVC"></a>PVC</h3><ul><li>用于请求和绑定持久化存储卷pv,PVC 独立于具体的存储实现，可以通过存储类（StorageClass）来动态配置和管理存储资源。</li></ul><h4 id="yaml参考"><a href="#yaml参考" class="headerlink" title="yaml参考"></a>yaml参考</h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">10Gih</span> </span><br></pre></td></tr></table></figure><h4 id="K-os"><a href="#K-os" class="headerlink" title="K.os"></a>K.os</h4><ul><li>应该是可以理解为通过pvc进行申请后，StorageClass会根据pvc来动态创建pv<h3 id="configMap"><a href="#configMap" class="headerlink" title="configMap"></a>configMap</h3></li><li>于在集群中管理非机密数据配置，将配置信息从代码中分离出来，注入配置数据的方法，便于管理和更新。</li></ul><h4 id="K-os-1"><a href="#K-os-1" class="headerlink" title="K.os"></a>K.os</h4><ul><li>可以用键值得形式存储重要数据</li></ul><h3 id="secret"><a href="#secret" class="headerlink" title="secret"></a>secret</h3><p>可以参考： </p><h2 id="持久卷"><a href="#持久卷" class="headerlink" title="持久卷"></a>持久卷</h2><p>为Pod提供独立于Pod生命周期的持久存储。</p><h3 id="PV"><a href="#PV" class="headerlink" title="PV"></a>PV</h3><ul><li>一块存储资源。它是集群级别的资源，与Pod的生命周期分离。PV可以由管理员预先创建，也可以通过存储类动态创建。</li></ul><h4 id="静态"><a href="#静态" class="headerlink" title="静态"></a>静态</h4><ul><li>写完直接apply<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">10Gi</span></span><br></pre></td></tr></table></figure><h4 id="动态"><a href="#动态" class="headerlink" title="动态"></a>动态</h4></li><li>需要一个存储类StorageClass进行动态申领，就是想定义好StorageClass，再进行pvc进行获取</li></ul><h4 id="绑定"><a href="#绑定" class="headerlink" title="绑定"></a>绑定</h4><ul><li>Kubernetes会根据PVC的需求自动寻找和绑定合适的PV。</li></ul><h4 id="回收"><a href="#回收" class="headerlink" title="回收"></a>回收</h4><ul><li>当PVC被删除后，PV的回收策略决定了PV的处理方式。回收策略有三种：Retain、Recycle和Delete。</li></ul><ol><li>Retain：保留数据，管理员可以手动处理数据。</li><li>Recycle：清空数据后重新供PVC使用（已弃用）。</li><li>Delete：删除PV和存储数据。</li></ol><h4 id="K-os-2"><a href="#K-os-2" class="headerlink" title="K.os"></a>K.os</h4><ul><li>可以理解成物理卷一样，都是可以当作一块存储。但是后续的操作不一样，this.pv是能够通过StorageClass动态创建。</li></ul><h3 id="投射卷"><a href="#投射卷" class="headerlink" title="投射卷"></a>投射卷</h3><ul><li>将多种不同类型的数据源投射到 Pod 内的单个卷中。这些数据源包括 Secret、ConfigMap、Downward API 和 ServiceAccount Token 等。投射卷的一个主要优势是，它可以将多个来源的数据整合到一个挂载点，从而简化了数据管理和使用。</li></ul><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">projected-volume-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-projected-volume</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/etc/projected-volume</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-projected-volume</span></span><br><span class="line"><span class="comment"># 这里11111</span></span><br><span class="line">    <span class="attr">projected:</span></span><br><span class="line">      <span class="attr">sources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">configMap:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">my-config</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">secret:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">my-secret</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">downwardAPI:</span></span><br><span class="line">          <span class="attr">items:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">&quot;labels&quot;</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">metadata.labels</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">serviceAccountToken:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">&quot;token&quot;</span></span><br><span class="line">          <span class="attr">expirationSeconds:</span> <span class="number">3600</span></span><br><span class="line">          <span class="attr">audience:</span> <span class="string">&quot;api&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="存储类"><a href="#存储类" class="headerlink" title="存储类"></a><strong>存储类</strong></h3><p>用来定义PV的资源对象</p><h4 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h4><p>Provisioner：定义由谁负责提供存储资源。不同的 Provisioner 对应不同的存储系统，如 kubernetes.io/aws-ebs 对应 AWS 的 EBS 存储，kubernetes.io/gce-pd 对应 Google Cloud 的 Persistent Disk，等等。</p><p>Parameters：提供给存储系统的参数。例如，对于 AWS EBS，可以指定卷类型（如 gp2、io1 等）、IOPS 等参数。</p><p>ReclaimPolicy：定义 PV 被释放后如何处理。有两种策略：</p><p>Retain：保留存储资源供管理员手动回收。<br>Delete：自动删除存储资源。<br>AllowVolumeExpansion：指示是否允许动态扩展存储卷大小。</p><p>MountOptions：提供给挂载卷的选项，这些选项会应用于挂载存储卷时。</p><p>VolumeBindingMode：定义 PV 的绑定模式，主要有两种：</p><p>Immediate：PV 会立即绑定到 PVC。<br>WaitForFirstConsumer：PV 会等待第一个消费者（Pod）出现后再绑定，以便更好地优化存储资源分配。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span>  <span class="comment"># 指定API版本</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span>            <span class="comment"># 声明资源类型为StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fast</span>                  <span class="comment"># StorageClass的名称，用户定义的标识</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/aws-ebs</span>  <span class="comment"># 指定Provisioner类型，这里使用AWS EBS作为存储提供者</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">io1</span>                   <span class="comment"># 指定AWS EBS卷的类型，这里使用io1类型</span></span><br><span class="line">  <span class="attr">iopsPerGB:</span> <span class="string">&quot;10&quot;</span>             <span class="comment"># 指定每GB卷的IOPS（仅对io1类型有效）</span></span><br><span class="line">  <span class="attr">fsType:</span> <span class="string">ext4</span>                <span class="comment"># 指定文件系统类型，默认为ext4</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Retain</span>         <span class="comment"># 设置回收策略，Retain表示保留PV供管理员手动回收</span></span><br><span class="line"><span class="attr">allowVolumeExpansion:</span> <span class="literal">true</span>    <span class="comment"># 允许动态扩展存储卷大小</span></span><br><span class="line"><span class="attr">mountOptions:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">debug</span>                     <span class="comment"># 挂载卷时的选项，这里使用debug模式</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">WaitForFirstConsumer</span>  <span class="comment"># 设置卷绑定模式，WaitForFirstConsumer表示等待第一个消费者出现再绑定</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;卷&quot;&gt;&lt;a href=&quot;#卷&quot; class=&quot;headerlink&quot; title=&quot;卷&quot;&gt;&lt;/a&gt;卷&lt;/h2&gt;&lt;h3 id=&quot;PVC&quot;&gt;&lt;a href=&quot;#PVC&quot; class=&quot;headerlink&quot; title=&quot;PVC&quot;&gt;&lt;/a&gt;PVC&lt;/h3&gt;&lt;ul&gt;
&lt;</summary>
      
    
    
    
    <category term="kubernetes" scheme="https://kalyan-zitiu.github.io/categories/kubernetes/"/>
    
    
    <category term="kubernetes" scheme="https://kalyan-zitiu.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>基于containerd的kubernetes集群建设</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/26/%E5%9F%BA%E4%BA%8Econtainerd%E7%9A%84kubernetes%E9%9B%86%E7%BE%A4%E5%BB%BA%E8%AE%BE/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/26/%E5%9F%BA%E4%BA%8Econtainerd%E7%9A%84kubernetes%E9%9B%86%E7%BE%A4%E5%BB%BA%E8%AE%BE/</id>
    <published>2024-07-26T01:40:58.000Z</published>
    <updated>2024-07-30T06:48:06.012Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><h3 id="节点资源规划（仅学习）"><a href="#节点资源规划（仅学习）" class="headerlink" title="节点资源规划（仅学习）"></a>节点资源规划（仅学习）</h3><p>资源规划：一个master，两个work（非测试不建议这种模式，无高可用）<br>master： 16c,32g,200G,200G(空)<br>work : 16c,32g,200G,200G(空)</p><h3 id="选择安装工具"><a href="#选择安装工具" class="headerlink" title="选择安装工具"></a>选择安装工具</h3><ol><li>首先DNS更正223.5.5.5，223.6.6.6</li><li>选择后国内清华源的K8s软件库：</li></ol><ul><li><a href="https://mirrors.tuna.tsinghua.edu.cn/help/kubernetes/">https://mirrors.tuna.tsinghua.edu.cn/help/kubernetes/</a></li></ul><ol start="3"><li>选择containerd运行时</li><li>安装ipvs</li></ol><p>个人理解：环境主要在三节点上有kubelet，kubectl，主节点多一个初始化的kubeadm。然后主节点用kubeadm进行初始化主节点，然后进行containerd运行时进行组件的拉取和运行。组成一个集群。</p><h3 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h3><p>各种安装过程我们跳过哈,然后我们深度聊一聊一些环境的设置</p><h4 id="环境设置"><a href="#环境设置" class="headerlink" title="环境设置"></a>环境设置</h4><h5 id="内核参数调整"><a href="#内核参数调整" class="headerlink" title="内核参数调整"></a>内核参数调整</h5><h6 id="什么是内核参数呢，会影响什么"><a href="#什么是内核参数呢，会影响什么" class="headerlink" title="什么是内核参数呢，会影响什么"></a>什么是内核参数呢，会影响什么</h6><p>内核参数是配置Linux内核行为的设置。这些参数控制系统的各种功能，如内存管理、网络设置、文件系统行为等。内核参数通常通过/etc/sysctl.conf文件进行配置，并通过sysctl命令加载和应用。常用的内核参数请看<br><a href="https://blog.zitiu.top/2024/07/01/linux%E4%B8%8D%E5%90%8C%E5%8F%91%E8%A1%8C%E7%89%88%E7%9A%84%E5%8C%BA%E5%88%AB/">Linux从核心到边缘 | Kalyan的小书房 (zitiu.top)</a></p><h6 id="需要调整的内核参数"><a href="#需要调整的内核参数" class="headerlink" title="需要调整的内核参数"></a>需要调整的内核参数</h6><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vm.swappiness</span> <span class="string">=</span> <span class="number">0</span>  <span class="comment"># 减少swap分区使用</span></span><br><span class="line"><span class="string">net.ipv4.ip_forward</span> <span class="string">=</span> <span class="number">1</span> <span class="comment"># 允许linux内核将网络流量从一个网络接口转发到另一个网络接口</span></span><br><span class="line"><span class="string">net.bridge.bridge-nf-call-iptables=1</span> <span class="comment"># 启用 bridge-nf-call-iptables</span></span><br><span class="line"><span class="string">net.ipv4.ip_forward=1</span> <span class="comment"># 启用 IP 转发</span></span><br></pre></td></tr></table></figure><p>这里通常会有一个问题，当你sysctl -p采用的时候可能会报错</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sysctl: cannot <span class="built_in">stat</span> /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directory</span><br><span class="line">sysctl: cannot <span class="built_in">stat</span> /proc/sys/net/bridge/bridge-nf-call-ip6tables: No such file or directory</span><br></pre></td></tr></table></figure><p>这个时候你可以</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启用 bridge-nf-call-iptables</span></span><br><span class="line">sudo modprobe br_netfilter</span><br><span class="line"><span class="built_in">echo</span> 1 | sudo <span class="built_in">tee</span> /proc/sys/net/bridge/bridge-nf-call-iptables</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;net.bridge.bridge-nf-call-iptables=1&quot;</span> | sudo <span class="built_in">tee</span> -a /etc/sysctl.conf</span><br><span class="line">sudo sysctl -p</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用 IP 转发</span></span><br><span class="line"><span class="built_in">echo</span> 1 | sudo <span class="built_in">tee</span> /proc/sys/net/ipv4/ip_forward</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;net.ipv4.ip_forward=1&quot;</span> | sudo <span class="built_in">tee</span> -a /etc/sysctl.conf</span><br><span class="line">sudo sysctl -p</span><br></pre></td></tr></table></figure><p>最后进行微调</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建一个文件，将需要的内核模块写入其中，以便在系统启动时自动加载这些模块</span></span><br><span class="line"><span class="built_in">tee</span> /etc/modules-load.d/k8s.conf &lt;&lt;<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line"><span class="comment"># netfilter 模块，允许 iptables 检查桥接流量</span></span><br><span class="line">br_netfilter</span><br><span class="line"><span class="comment"># containerd 文件系统支持</span></span><br><span class="line">overlay</span><br><span class="line"><span class="comment"># IPVS (IP Virtual Server) 模块，用于负载均衡</span></span><br><span class="line">ip_vs</span><br><span class="line"><span class="comment"># 轮叫调度算法</span></span><br><span class="line">ip_vs_rr</span><br><span class="line"><span class="comment"># 加权轮叫调度算法</span></span><br><span class="line">ip_vs_wrr</span><br><span class="line"><span class="comment"># 源地址散列调度算法</span></span><br><span class="line">ip_vs_sh</span><br><span class="line"><span class="comment"># 连接跟踪模块，用于跟踪网络连接状态</span></span><br><span class="line">nf_conntrack</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建目录以存放模块加载脚本</span></span><br><span class="line"><span class="built_in">mkdir</span> -vp /etc/modules.d/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个脚本文件，立即加载所需的内核模块</span></span><br><span class="line"><span class="built_in">cat</span> &gt; /etc/modules.d/k8s.modules &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">#!/bin/bash</span></span><br><span class="line"><span class="string"># 允许 iptables 检查桥接流量</span></span><br><span class="line"><span class="string">modprobe -- br_netfilter</span></span><br><span class="line"><span class="string"># containerd 文件系统支持</span></span><br><span class="line"><span class="string">modprobe -- overlay</span></span><br><span class="line"><span class="string"># IPVS 模块，用于负载均衡</span></span><br><span class="line"><span class="string">modprobe -- ip_vs</span></span><br><span class="line"><span class="string"># 轮叫调度算法</span></span><br><span class="line"><span class="string">modprobe -- ip_vs_rr</span></span><br><span class="line"><span class="string"># 加权轮叫调度算法</span></span><br><span class="line"><span class="string">modprobe -- ip_vs_wrr</span></span><br><span class="line"><span class="string"># 源地址散列调度算法</span></span><br><span class="line"><span class="string">modprobe -- ip_vs_sh</span></span><br><span class="line"><span class="string"># 连接跟踪模块，用于跟踪网络连接状态</span></span><br><span class="line"><span class="string">modprobe -- nf_conntrack</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 给脚本文件赋予执行权限</span></span><br><span class="line"><span class="built_in">chmod</span> 755 /etc/modules.d/k8s.modules</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行脚本，立即加载所需的内核模块</span></span><br><span class="line">bash /etc/modules.d/k8s.modules</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证内核模块是否加载成功，查看加载的模块列表中是否包含 ip_vs 和 nf_conntrack 模块</span></span><br><span class="line">lsmod | grep -e ip_vs -e nf_conntrack</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 应用 sysctl 配置，确保所有内核参数设置立即生效</span></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重启系统，确保所有配置在系统重启后自动生效</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><h5 id="什么是swap分区-为什么要删除"><a href="#什么是swap分区-为什么要删除" class="headerlink" title="什么是swap分区,为什么要删除."></a>什么是swap分区,为什么要删除.</h5><ul><li>你可以把swap分区简单理解成是为了分担RAM的负担的这么一个作用,你可以想象一下你有一个书桌,你工作的时候,为了快速获取资料,你会在书桌上堆满书本,这个时候swap就像书架一样,在书架取书会有点慢,但是你起码有位置放书.</li></ul><ul><li><p>那么为什么我们要在kubernetes中要删除呢,继续刚刚的比喻,现在一个研究馆内,有很多书桌(节点),管理人员(k8s调度器)会根据每个人的书桌的容量进行任务的合理分配.如果启动了书架(swap),管理人员可能不知道,你书桌上的实际容量,要是书桌(RAM)把大量资源放到了书架(swap)上,管理人员(调度器)看你的书桌(RAM)空闲,把大量的资源工作丢给你,可能会导致书桌(RAM)的坍塌</p></li><li><p>一句话:k8s调度器无法知道swap分区里面的情况.</p></li></ul><h5 id="防火墙"><a href="#防火墙" class="headerlink" title="防火墙"></a>防火墙</h5><p>这个就不说了,主要是为了更好的后续node以及pod会有自己的网络体系,为了适配关掉最好.</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ufw <span class="built_in">disable</span> &amp;&amp; systemctl <span class="built_in">disable</span> ufw</span><br><span class="line">swapoff -a &amp;&amp; sed -i <span class="string">&#x27;s|^/swap.img|#/swap.ing|g&#x27;</span> /etc/fstab</span><br></pre></td></tr></table></figure><h5 id="containerd设置-配置runtime-endpoint"><a href="#containerd设置-配置runtime-endpoint" class="headerlink" title="containerd设置-配置runtime-endpoint"></a>containerd设置-配置runtime-endpoint</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># containerd - 运行时设置,这一步不能出错</span></span><br><span class="line">crictl config runtime-endpoint /run/containerd/containerd.sock</span><br></pre></td></tr></table></figure><p>要是出现无法连接的情况就检查三个地方</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 是否有/etc/containerd/config.toml 用于配置管理containerd容器运行时守护进程的行为。</span></span><br><span class="line"><span class="built_in">mkdir</span> -vp /etc/containerd/</span><br><span class="line">containerd config default &gt; /etc/containerd/config.toml</span><br><span class="line"><span class="comment"># 将配置文件中所有出现的 k8s.gcr.io 替换为 registry.cn-hangzhou.aliyuncs.com/google_containers</span></span><br><span class="line">sed -i <span class="string">&quot;s#k8s.gcr.io#registry.cn-hangzhou.aliyuncs.com/google_containers#g&quot;</span>  /etc/containerd/config.toml</span><br><span class="line"><span class="comment"># 这里有点问题，需要提前把SystemdCgroup = false删除掉，否则会有重复定义的错误。</span></span><br><span class="line">sed -i <span class="string">&#x27;/containerd.runtimes.runc.options/a\ \ \ \ \ \ \ \ \ \ \ \ SystemdCgroup = true&#x27;</span> /etc/containerd/config.toml</span><br><span class="line"><span class="comment"># 修改版</span></span><br><span class="line">CONFIG_FILE=<span class="string">&quot;/etc/containerd/config.toml&quot;</span>; grep -q <span class="string">&#x27;SystemdCgroup&#x27;</span> <span class="string">&quot;<span class="variable">$CONFIG_FILE</span>&quot;</span> &amp;&amp; sed -i <span class="string">&#x27;s/SystemdCgroup =.*/SystemdCgroup = true/&#x27;</span> <span class="string">&quot;<span class="variable">$CONFIG_FILE</span>&quot;</span> || sed -i <span class="string">&#x27;/containerd.runtimes.runc.options/a\ \ \ \ \ \ \ \ \ \ \ \ SystemdCgroup = true&#x27;</span> <span class="string">&quot;<span class="variable">$CONFIG_FILE</span>&quot;</span></span><br><span class="line"><span class="comment"># 将配置文件中所有出现的 https://registry-1.docker.io 替换为 https://xlx9erfu.mirror.aliyuncs.com。</span></span><br><span class="line">sed -i <span class="string">&quot;s#https://registry-1.docker.io#https://xlx9erfu.mirror.aliyuncs.com#g&quot;</span>  /etc/containerd/config.toml</span><br><span class="line"><span class="comment"># 是否有/etc/crictl.yaml</span></span><br><span class="line">runtime-endpoint: <span class="string">&quot;unix:///run/containerd/containerd.sock&quot;</span></span><br><span class="line">image-endpoint: <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="built_in">timeout</span>: 0</span><br><span class="line">debug: <span class="literal">false</span></span><br><span class="line">pull-image-on-create: <span class="literal">false</span></span><br><span class="line">disable-pull-on-run: <span class="literal">false</span></span><br><span class="line"><span class="comment"># 是否有/run/containerd/containerd.sock</span></span><br></pre></td></tr></table></figure><h3 id="初始化主节点"><a href="#初始化主节点" class="headerlink" title="初始化主节点"></a>初始化主节点</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生产配置模板，自己把imageRepository改成自己加速的镜像源。</span></span><br><span class="line">kubeadm config <span class="built_in">print</span> init-defaults &gt; kubeadm.yaml</span><br><span class="line"><span class="comment">#初始化</span></span><br><span class="line">kubeadm init --config=kubeadm.yaml --v=5</span><br><span class="line"><span class="comment"># 查看镜像列表</span></span><br><span class="line">kubeadm config images list</span><br><span class="line"><span class="comment"># 然后进行拉取</span></span><br><span class="line">crictl pull</span><br></pre></td></tr></table></figure><p>ps:一定要仔细配置kubeadm。</p><p>要是containerd有问题的话，修改过config.toml，记得restart一下然后记得</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubeadm reset -f --cri-socket unix:///run/containerd/containerd.sock</span><br></pre></td></tr></table></figure><p>ps:修改镜像源后记得修改一下containerd里面的pause的镜像源。</p><p>给个样板在这里：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- <span class="built_in">groups</span>:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 10.70.49.131 <span class="comment"># 必填</span></span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: unix:///run/containerd/containerd.sock <span class="comment">#最好加上unix://</span></span><br><span class="line">  imagePullPolicy: IfNotPresent <span class="comment"># 可以忽略镜像拉取，后续可以手动拉</span></span><br><span class="line">  name: masternode-1 <span class="comment"># 必填</span></span><br><span class="line">  taints: null</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns: <span class="comment"># dns有点ex，注意镜像源</span></span><br><span class="line">  <span class="built_in">type</span>: CoreDNS</span><br><span class="line">  imageRepository: k8s.m.daocloud.io/coredns</span><br><span class="line">  imageTag: v1.10.1</span><br><span class="line">etcd:</span><br><span class="line">  <span class="built_in">local</span>:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: k8s.m.daocloud.io</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: 1.28.0</span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: 10.96.0.0/12</span><br><span class="line">  podSubnet: 10.244.0.0/16</span><br><span class="line">scheduler: &#123;&#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">mode: ipvs <span class="comment"># 开启ipvs模式</span></span><br><span class="line">---</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">cgroupDriver: systemd</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="calico"><a href="#calico" class="headerlink" title="calico"></a>calico</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://docs.projectcalico.org/v3.18/manifests/calico.yaml</span><br></pre></td></tr></table></figure><p>然后自己配置一下</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240730105948262.png" alt="image-20240730105948262"></p><p>然后apply一下。等待跑起来</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240730143740906.png" alt="image-20240730143740906"></p><p>哪个拉不起来就去对应的controlby，或者直接deploy上修改image。然后正常来说的话就基本node全部ready</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240730143852876.png" alt="image-20240730143852876"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h2&gt;&lt;h3 id=&quot;节点资源规划（仅学习）&quot;&gt;&lt;a href=&quot;#节点资源规划（仅学习）&quot; class=&quot;headerlink&quot; ti</summary>
      
    
    
    
    <category term="kubernetes" scheme="https://kalyan-zitiu.github.io/categories/kubernetes/"/>
    
    
    <category term="kubernetes" scheme="https://kalyan-zitiu.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>排错杂记（pod error）</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/24/%E6%8E%92%E9%9A%9C%E6%97%A5%E5%BF%97%EF%BC%88updating%EF%BC%89/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/24/%E6%8E%92%E9%9A%9C%E6%97%A5%E5%BF%97%EF%BC%88updating%EF%BC%89/</id>
    <published>2024-07-24T02:44:28.000Z</published>
    <updated>2024-07-24T08:28:41.582Z</updated>
    
    <content type="html"><![CDATA[<h3 id="尝试排错"><a href="#尝试排错" class="headerlink" title="尝试排错"></a>尝试排错</h3><p>起因是拉起某个pod的时候持续不断的错误边拉边寄，显示的不是image问题。</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724104653156.png" alt="image-20240724104653156"></p><p>尝试describe一下，发现调度，拉取，创建，启动似乎都正常</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724104802500.png" alt="image-20240724104802500"></p><p>这个时候就得去看日志kubectl log一下，</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724104835975.png" alt="image-20240724104835975"></p><p>？？？timeout？？？kubectl 正常能get不至于访问不到api，api是包正常的。</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724104918625.png" alt="image-20240724104918625"></p><p>那就是网络问题，先看一下插件，插件也正常。</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724105000612.png" alt="image-20240724105000612"></p><p>再看DNS，似乎有点问题，丢了master3的conredns？？？</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724105033529.png" alt="image-20240724105033529"></p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724105351232.png" alt="image-20240724105351232"></p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724105355465.png" alt="image-20240724105355465"></p><p>但是查询后这个pod的是属于master1的pod所以不是dns的问题，缺一个的问题后面再解决。<br>按着尝试手动再吃连接api服务器,草pod fail了，所以用不了，先标记</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it kcollie-pre-hook-install-crds-bdb4g -n kcollie-system -- /bin/sh</span><br><span class="line">curl -k https://10.233.0.1:433</span><br></pre></td></tr></table></figure><p>再check一下kube-system的pod</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724110135451.png" alt="image-20240724110135451"></p><p>md草了，有屎啊，节点二怎么就timeout了，相继的节点一三也爆屎了。</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724111053894.png" alt="image-20240724111053894"></p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724111922571.png" alt="image-20240724111922571"></p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724112010432.png" alt="image-20240724112010432"></p><p>看一下节点情况，感觉可以rollout整个kube-system，完蛋，怎么查个pod状态，查到整个kube崩了</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724112656575.png" alt="image-20240724112656575"></p><p>直接rollout所有</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 重启所有 Deployments</span></span><br><span class="line"><span class="keyword">for</span> deployment <span class="keyword">in</span> $(kubectl get deployments -n kube-system -o jsonpath=<span class="string">&#x27;&#123;.items[*].metadata.name&#125;&#x27;</span>); <span class="keyword">do</span></span><br><span class="line">  kubectl rollout restart deployment <span class="variable">$deployment</span> -n kube-system</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启所有 StatefulSets</span></span><br><span class="line"><span class="keyword">for</span> statefulset <span class="keyword">in</span> $(kubectl get statefulsets -n kube-system -o jsonpath=<span class="string">&#x27;&#123;.items[*].metadata.name&#125;&#x27;</span>); <span class="keyword">do</span></span><br><span class="line">  kubectl rollout restart statefulset <span class="variable">$statefulset</span> -n kube-system</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启所有 DaemonSets</span></span><br><span class="line"><span class="keyword">for</span> daemonset <span class="keyword">in</span> $(kubectl get daemonsets -n kube-system -o jsonpath=<span class="string">&#x27;&#123;.items[*].metadata.name&#125;&#x27;</span>); <span class="keyword">do</span></span><br><span class="line">  kubectl rollout restart daemonset <span class="variable">$daemonset</span> -n kube-system</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>总算是起来了，然后有一个node还是not ready，估计是node3的某些pod还没好，但是报错还是</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724125055556.png" alt="image-20240724125055556"></p><p>不懂，node1的apiserver明明好好的，coredns也没问题。</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240724130355768.png" alt="image-20240724130355768"></p><p>又死了，草啊啊啊啊啊啊啊啊啊啊。节点不知道为什么十分的不稳定，似乎不断崩溃重启，直接停机加内存。</p><p>估计上面的Error是不怎么影响的。。。。。。。。重启然后就没事了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;尝试排错&quot;&gt;&lt;a href=&quot;#尝试排错&quot; class=&quot;headerlink&quot; title=&quot;尝试排错&quot;&gt;&lt;/a&gt;尝试排错&lt;/h3&gt;&lt;p&gt;起因是拉起某个pod的时候持续不断的错误边拉边寄，显示的不是image问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https:</summary>
      
    
    
    
    <category term="杂记" scheme="https://kalyan-zitiu.github.io/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
    <category term="杂记" scheme="https://kalyan-zitiu.github.io/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Kind基础</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/24/Kind/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/24/Kind/</id>
    <published>2024-07-24T01:58:31.000Z</published>
    <updated>2024-07-24T08:22:58.302Z</updated>
    
    <content type="html"><![CDATA[<h2 id="KIND（Kubernetes-IN-Docker）"><a href="#KIND（Kubernetes-IN-Docker）" class="headerlink" title="KIND（Kubernetes IN Docker）"></a>KIND（Kubernetes IN Docker）</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>KIND，全称“Kubernetes IN Docker”，是一个开源工具，用于在本地开发和测试 Kubernetes 集群。KIND 允许在 Docker 容器中运行 Kubernetes 集群，从而便于开发者快速创建和销毁 Kubernetes 集群，提升开发效率。</p><h3 id="安装和配置"><a href="#安装和配置" class="headerlink" title="安装和配置"></a>安装和配置</h3><h4 id="前置条件"><a href="#前置条件" class="headerlink" title="前置条件"></a>前置条件</h4><p>在使用 KIND 之前，你需要确保以下软件已经正确安装：<br>Docker<br>kubectl<br>确保 Docker 已经启动，并且你的用户在 docker 组中，以便能够运行 Docker 命令而无需 sudo。</p><h4 id="安装-KIND"><a href="#安装-KIND" class="headerlink" title="安装 KIND"></a>安装 KIND</h4><p>在 Linux 环境中，可以通过以下命令获取和安装 KIND：</p><p>curl -Lo ./kind <a href="https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64">https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64</a><br>chmod +x ./kind<br>sudo mv ./kind /usr/local/bin/kind</p><h4 id="检查安装"><a href="#检查安装" class="headerlink" title="检查安装"></a>检查安装</h4><p>验证 KIND 是否安装成功：</p><p>kind –version<br>你应该看到类似 kind v0.11.1 的输出。</p><h3 id="创建-Kubernetes-集群"><a href="#创建-Kubernetes-集群" class="headerlink" title="创建 Kubernetes 集群"></a>创建 Kubernetes 集群</h3><h4 id="简单创建一个集群"><a href="#简单创建一个集群" class="headerlink" title="简单创建一个集群"></a>简单创建一个集群</h4><p>使用以下命令创建一个默认的 Kubernetes 集群：</p><p>kind create cluster<br>成功创建后，你会看到与集群相关的信息输出。</p><h4 id="自定义配置创建集群"><a href="#自定义配置创建集群" class="headerlink" title="自定义配置创建集群"></a>自定义配置创建集群</h4><p>为了更具定制化，可以使用 YAML 文件：</p><p>创建 kind-config.yaml 文件：</p><p>kind: Cluster<br>apiVersion: kind.x-k8s.io/v1alpha4<br>nodes:</p><ul><li>role: control-plane</li><li>role: worker</li><li>role: worker<br>使用以下命令创建集群：</li></ul><p>kind create cluster –config kind-config.yaml</p><h4 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h4><p>验证集群状态：</p><p>kubectl cluster-info –context kind-kind</p><h3 id="实战操作"><a href="#实战操作" class="headerlink" title="实战操作"></a>实战操作</h3><h4 id="部署应用到-KIND-集群"><a href="#部署应用到-KIND-集群" class="headerlink" title="部署应用到 KIND 集群"></a>部署应用到 KIND 集群</h4><p>创建一个名为 nginx-deployment.yaml 的文件：</p><p>apiVersion: apps/v1<br>kind: Deployment<br>metadata:<br>  name: nginx-deployment<br>spec:<br>  replicas: 3<br>  selector:<br>    matchLabels:<br>      app: nginx<br>  template:<br>    metadata:<br>      labels:<br>        app: nginx<br>    spec:<br>      containers:<br>      - name: nginx<br>        image: nginx:1.14.2<br>        ports:<br>        - containerPort: 80<br>使用 kubectl 部署：</p><p>kubectl apply -f nginx-deployment.yaml</p><h4 id="验证部署"><a href="#验证部署" class="headerlink" title="验证部署"></a>验证部署</h4><p>查看部署的状态：</p><p>kubectl get deployments<br>查看 Pods 状态：</p><p>kubectl get pods</p><h4 id="暴露服务"><a href="#暴露服务" class="headerlink" title="暴露服务"></a>暴露服务</h4><p>创建一个名为 nginx-service.yaml 的文件：</p><p>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: nginx-service<br>spec:<br>  selector:<br>    app: nginx<br>  ports:</p><ul><li>protocol: TCP<br>port: 80<br>targetPort: 80<br>type: LoadBalancer<br>使用 kubectl 暴露服务：</li></ul><p>kubectl apply -f nginx-service.yaml</p><h3 id="KIND的应用场景和作用"><a href="#KIND的应用场景和作用" class="headerlink" title="KIND的应用场景和作用"></a>KIND的应用场景和作用</h3><h4 id="开发和测试环境"><a href="#开发和测试环境" class="headerlink" title="开发和测试环境"></a>开发和测试环境</h4><p>在本地开发和测试 Kubernetes 应用，KIND 的特性让开发者可以快速创建和删除集群，大大提高了开发效率。</p><h4 id="CI-CD管道"><a href="#CI-CD管道" class="headerlink" title="CI/CD管道"></a>CI/CD管道</h4><p>在 CI/CD 管道中，KIND 可以在每次代码变更时快速创建一个新的 Kubernetes 集群用于测试，确保代码的稳定性和一致性。</p><h4 id="学习和培训"><a href="#学习和培训" class="headerlink" title="学习和培训"></a>学习和培训</h4><p>KIND 非常适合用于学习和培训，可以在本地快速搭建 Kubernetes 环境，使学习者掌握 Kubernetes 基本操作和概念。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>KIND 是基于 Docker 容器的，因此某些 Kubernetes 高级功能可能不完全支持。<br>偶尔你可能需要手动清理 Docker 容器和网络设置，特别是在多次创建和删除集群后。<br>不建议在生产环境中使用 KIND，它更适用于开发和测试用途。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>KIND 是一个非常方便的工具，可以帮助我们在本地快速搭建和管理 Kubernetes 集群。无论是开发测试、CI/CD 还是学习培训，KIND 都能发挥其巨大的作用。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;KIND（Kubernetes-IN-Docker）&quot;&gt;&lt;a href=&quot;#KIND（Kubernetes-IN-Docker）&quot; class=&quot;headerlink&quot; title=&quot;KIND（Kubernetes IN Docker）&quot;&gt;&lt;/a&gt;KIND（Kub</summary>
      
    
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/categories/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus基础</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/23/Prometheus%E5%9F%BA%E7%A1%80/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/23/Prometheus%E5%9F%BA%E7%A1%80/</id>
    <published>2024-07-23T08:10:02.000Z</published>
    <updated>2024-07-23T08:10:28.035Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h2><p>一个开源的监控和告警系统</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><h4 id="多维数据模型"><a href="#多维数据模型" class="headerlink" title="多维数据模型"></a>多维数据模型</h4><ul><li>使用时间序列数据，每个序列有一个度量指标（metricname）和一组键值对（labels）标识，这样可以灵活对同一类进行细分。<h5 id="度量指标"><a href="#度量指标" class="headerlink" title="度量指标"></a>度量指标</h5></li><li>counter：计数器，用于记录累计值，例如请求次数。</li><li>gauge：测量值，可增可减，例如当前内存使用量。</li><li>histogram：直方图，用于记录值分布，例如请求延迟。</li><li>summary：摘要，用于统计分位数和总和，例如响应时间的分位数。</li></ul><h5 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h5><ul><li>一组键值对，用于对时间序列进行细分和区分。例如，监控一个 HTTP 请求的计数器可以通过标签区分不同的请求路径和状态码</li></ul><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">http_requests_total&#123;method=<span class="string">&quot;POST&quot;</span>, handler=<span class="string">&quot;/api/v1&quot;</span>, <span class="built_in">status</span>=<span class="string">&quot;200&quot;</span>&#125;</span><br><span class="line">http_requests_total&#123;method=<span class="string">&quot;GET&quot;</span>, handler=<span class="string">&quot;/api/v1&quot;</span>, <span class="built_in">status</span>=<span class="string">&quot;500&quot;</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>假设我们有一个 Web 服务，它记录了每个请求的数量和响应时间。我们可以定义以下指标：</p><ol><li>记录请求数量的计数器：<ul><li>Metric Name: <code>http_requests_total</code></li><li>Labels: <code>method</code>, <code>handler</code>, <code>status</code></li></ul></li><li>记录响应时间的直方图：<ul><li>Metric Name: <code>http_request_duration_seconds</code></li><li>Labels: <code>method</code>, <code>handler</code></li></ul></li></ol><p>每次有新的请求进来，计数器和直方图都会更新。例如：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http_requests_total&#123;method=<span class="string">&quot;POST&quot;</span>, handler=<span class="string">&quot;/api/v1&quot;</span>, status=<span class="string">&quot;200&quot;</span>&#125; 1234</span><br><span class="line">http_requests_total&#123;method=<span class="string">&quot;GET&quot;</span>, handler=<span class="string">&quot;/api/v1&quot;</span>, status=<span class="string">&quot;500&quot;</span>&#125; 56</span><br><span class="line">http_request_duration_seconds_bucket&#123;method=<span class="string">&quot;POST&quot;</span>, handler=<span class="string">&quot;/api/v1&quot;</span>, le=<span class="string">&quot;0.1&quot;</span>&#125; 5</span><br><span class="line">http_request_duration_seconds_bucket&#123;method=<span class="string">&quot;POST&quot;</span>, handler=<span class="string">&quot;/api/v1&quot;</span>, le=<span class="string">&quot;0.5&quot;</span>&#125; 50</span><br></pre></td></tr></table></figure><h4 id="支持PromQL"><a href="#支持PromQL" class="headerlink" title="支持PromQL"></a>支持PromQL</h4><p>查询所有 POST 请求的数量：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">promql</span><br><span class="line">复制代码</span><br><span class="line">sum(http_requests_total&#123;method=&quot;POST&quot;&#125;)</span><br></pre></td></tr></table></figure><p>查询 <code>/api/v1</code> 接口的所有请求数量：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">promql</span><br><span class="line">复制代码</span><br><span class="line">sum(http_requests_total&#123;handler=&quot;/api/v1&quot;&#125;)</span><br></pre></td></tr></table></figure><p>查询状态码为 200 的请求数量：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">promql</span><br><span class="line">复制代码</span><br><span class="line">sum(http_requests_total&#123;status=&quot;200&quot;&#125;)</span><br></pre></td></tr></table></figure><h5 id="优化使用标签"><a href="#优化使用标签" class="headerlink" title="优化使用标签"></a>优化使用标签</h5><ul><li><strong>标签数目不要过多</strong>：过多的标签会导致时间序列爆炸，影响性能。</li><li><strong>标签值尽量稳定</strong>：标签值变化太频繁会增加存储和查询负担。</li><li><strong>合理设计标签</strong>：确保标签的选择能够满足查询需求，同时不过度细化。</li></ul><h4 id="时间序列数据库"><a href="#时间序列数据库" class="headerlink" title="时间序列数据库"></a>时间序列数据库</h4><h5 id="TSDB-Prometheus自带时序数据库"><a href="#TSDB-Prometheus自带时序数据库" class="headerlink" title="TSDB Prometheus自带时序数据库"></a>TSDB Prometheus自带时序数据库</h5><h6 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h6><p>高效写入：Prometheus 的 TSDB 能够每秒写入数百万个样本，适合高频数据采集。<br>高效查询：针对时间序列数据优化的查询性能。<br>数据压缩：使用差分编码和 Gorilla 压缩算法减少存储空间。<br>局部存储：数据默认存储在本地磁盘上，可以通过远程存储扩展。</p><h6 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h6><p>样本 (Sample)：包含一个时间戳和一个值。<br>时间序列 (Time Series)：由一个度量名和一组标签唯一标识的一组样本。<br>块 (Block)：TSDB 中的数据以块的形式存储，每个块通常覆盖 2 小时的数据。<br>WAL (Write-Ahead Log)：在写入到块之前，数据先写入 WAL，以确保数据持久化。</p><h6 id="数据存储和管理"><a href="#数据存储和管理" class="headerlink" title="数据存储和管理"></a>数据存储和管理</h6><ol><li>数据存储路径：默认存储路径为 /var/lib/prometheus，可以在 Prometheus 配置文件中通过 storage.tsdb.path 参数修改。</li><li>数据保留策略：默认保留 15 天的数据，可以通过 –storage.tsdb.retention.time 参数设置。</li><li>数据压缩和删除：Prometheus 会自动压缩和删除过期数据。<h4 id="独立抓取模型："><a href="#独立抓取模型：" class="headerlink" title="独立抓取模型："></a>独立抓取模型：</h4></li></ol><h5 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h5><ol><li><strong>Scrape</strong>：Prometheus 从目标处获取监控数据的过程。</li><li><strong>Target</strong>：被监控的对象，可以是服务器、应用程序、数据库等。</li><li><strong>Job</strong>：一组相似目标的集合。</li><li><strong>Exporter</strong>：用于将目标的数据暴露给 Prometheus 的组件，通常是 HTTP 端点</li></ol><h5 id="配置文件’prometheus-yml’"><a href="#配置文件’prometheus-yml’" class="headerlink" title="配置文件’prometheus.yml’"></a>配置文件’prometheus.yml’</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  scrape_interval: 15s     <span class="comment"># 每15秒抓取一次数据</span></span><br><span class="line">  evaluation_interval: 15s <span class="comment"># 每15秒评估一次规则</span></span><br></pre></td></tr></table></figure><h6 id="抓取配置"><a href="#抓取配置" class="headerlink" title="抓取配置"></a>抓取配置</h6><p>抓取配置定义了 Prometheus 如何发现和抓取目标数据。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scrape_configs:</span><br><span class="line">  - job_name: <span class="string">&#x27;prometheus&#x27;</span></span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [<span class="string">&#x27;localhost:9090&#x27;</span>]</span><br></pre></td></tr></table></figure><h6 id="动态服务发现"><a href="#动态服务发现" class="headerlink" title="动态服务发现"></a>动态服务发现</h6><p>Prometheus 支持多种服务发现机制，允许动态发现目标。例如，可以使用 Kubernetes、Consul、Etcd 等进行服务发现。</p><p>####### Exporter<br>Exporter 是将监控数据暴露给 Prometheus 的组件，不同的应用和系统有不同的 Exporter。例如：</p><ul><li>Node Exporter：用于监控操作系统的资源使用情况。</li><li>Blackbox Exporter：用于进行探测和检查（如 HTTP、HTTPS、TCP）。</li><li>MySQL Exporter：用于监控 MySQL 数据库。</li></ul><h4 id="多种数据支持："><a href="#多种数据支持：" class="headerlink" title="多种数据支持："></a>多种数据支持：</h4><p>支持包括通过导出器（exporters）收集第三方系统的数据，支持服务发现（Service Discovery），如 Kubernetes、Consul、Etcd 等</p><h4 id="告警："><a href="#告警：" class="headerlink" title="告警："></a>告警：</h4><p>内置了 Alertmanager，用于处理告警通知和管理告警规则。</p><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><ol><li>Prometheus Server：<br>存储：使用基于时间序列数据库（TSDB）的本地存储来存储监控数据。<br>抓取（Scrape）：定期从目标端点（如应用程序、数据库等）拉取指标数据。<br>PromQL 查询引擎：允许用户通过 PromQL 查询存储的数据。</li><li>数据导出器（Exporters）：<br>节点导出器（Node Exporter）：收集系统级别的指标，如 CPU、内存、磁盘使用等。<br>应用程序导出器：如 MySQL Exporter、Redis Exporter，专门用于从特定应用中收集指标。</li><li>服务发现（Service Discovery）：<br>支持多种服务发现机制，如 Kubernetes、Consul、DNS 等，自动发现并监控动态变化的服务和主机。</li><li>Alertmanager：<br>告警规则：定义告警规则，当满足条件时触发告警。<br>告警通知：管理告警的路由和发送，支持多种通知方式，如电子邮件、Slack、PagerDuty 等。<br>告警抑制和分组：可以配置告警抑制规则和告警分组，避免告警风暴。</li><li>Pushgateway：<br>用于接收临时性任务（如批处理任务）的指标数据，这些任务无法被 Prometheus 定期拉取。</li></ol><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ol><li>配置和服务发现：通过配置文件或服务发现机制，Prometheus 确定需要监控的目标。</li><li>抓取数据：Prometheus 定期从目标端点拉取指标数据。</li><li>存储数据：将拉取到的指标数据存储在本地的时间序列数据库中。</li><li>查询和可视化：通过 PromQL 查询数据，结合 Grafana 等可视化工具展示监控结果。</li><li>告警处理：根据定义的告警规则，Prometheus 触发告警并通过 Alertmanager 发送通知。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Prometheus&quot;&gt;&lt;a href=&quot;#Prometheus&quot; class=&quot;headerlink&quot; title=&quot;Prometheus&quot;&gt;&lt;/a&gt;Prometheus&lt;/h2&gt;&lt;p&gt;一个开源的监控和告警系统&lt;/p&gt;
&lt;h3 id=&quot;特点&quot;&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="kubernetes" scheme="https://kalyan-zitiu.github.io/categories/kubernetes/"/>
    
    
    <category term="Prometheus" scheme="https://kalyan-zitiu.github.io/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>简单ansible操作</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/22/%E7%AE%80%E5%8D%95ansible%E6%93%8D%E4%BD%9C/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/22/%E7%AE%80%E5%8D%95ansible%E6%93%8D%E4%BD%9C/</id>
    <published>2024-07-22T06:59:35.000Z</published>
    <updated>2024-07-22T07:00:01.256Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a>Ansible</h2><p>用于配置管理、应用程序部署、任务自动化</p><h3 id="ansible主机清单"><a href="#ansible主机清单" class="headerlink" title="ansible主机清单"></a>ansible主机清单</h3><h4 id="定义组"><a href="#定义组" class="headerlink" title="定义组"></a>定义组</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[webservers] <span class="comment"># 定义组</span></span><br><span class="line">xxx.xxx.com</span><br><span class="line">xxx.xxx.com</span><br><span class="line"></span><br><span class="line">[dbserver] <span class="comment"># 定义组</span></span><br><span class="line">xxx.xxx.com</span><br><span class="line">xxx.xxx.com</span><br><span class="line"></span><br><span class="line">[dce5_nodes]</span><br><span class="line">10.70.49.17[2:4]</span><br><span class="line"></span><br><span class="line">[all:vars] <span class="comment"># 定义全局变量适用于全部主机</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Ansible SSH 用户名，用于连接到目标主机</span></span><br><span class="line">ansible_ssh_user: guest2admin</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ansible SSH 密码，用于连接到目标主机</span></span><br><span class="line">ansible_ssh_pass: @<span class="built_in">users</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Ansible 使用的 Python 解释器路径</span></span><br><span class="line">ansible_python_interpreter: /usr/bin/python</span><br><span class="line"></span><br><span class="line"><span class="comment"># SSH 连接的通用参数，这里指定了加密算法为 AES-256-CBC</span></span><br><span class="line">ansible_ssh_common_args: -c aes256-cbc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定 Ansible 连接到主机的方式，这里使用 SSH</span></span><br><span class="line">ansible_connection: ssh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提权操作时使用的密码（例如切换到 root 用户时的密码）</span></span><br><span class="line">ansible_become_password: root@root@su</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提权方法，这里使用 su 命令切换用户</span></span><br><span class="line">ansible_become_method: su</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提权执行命令，这里指定了使用 sudo su - 命令来切换到超级用户</span></span><br><span class="line">ansible_become_exe: sudo su -</span><br><span class="line"></span><br><span class="line"><span class="comment"># 还可以组别变量</span></span><br><span class="line">[webserver:vars]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="o打"><a href="#o打" class="headerlink" title="o打"></a>o打</h3><ol><li><p><strong>Ping 模块</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m ping</span><br></pre></td></tr></table></figure><p>通过 Ping 模块测试所有主机是否可达。</p></li><li><p><strong>Shell 模块</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m shell -a <span class="string">&#x27;uptime&#x27;</span></span><br></pre></td></tr></table></figure><p>在所有主机上执行 <code>uptime</code> 命令。</p></li><li><p><strong>Command 模块</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m <span class="built_in">command</span> -a <span class="string">&#x27;ls /tmp&#x27;</span></span><br></pre></td></tr></table></figure><p>使用 <code>command</code> 模块列出 <code>/tmp</code> 目录下的文件。</p></li><li><p><strong>Copy 模块</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m copy -a <span class="string">&#x27;src=/path/to/source dest=/path/to/destination&#x27;</span></span><br></pre></td></tr></table></figure><p>将本地文件复制到远程主机。</p></li><li><p><strong>File 模块</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m file -a <span class="string">&#x27;path=/tmp/testfile state=touch&#x27;</span></span><br></pre></td></tr></table></figure><p>在远程主机上创建一个空文件。</p></li><li><p><strong>Service 模块</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m service -a <span class="string">&#x27;name=httpd state=started&#x27;</span></span><br></pre></td></tr></table></figure><p>启动所有主机上的 httpd 服务。</p></li><li><p><strong>User 模块</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m user -a <span class="string">&#x27;name=johndoe state=present&#x27;</span></span><br></pre></td></tr></table></figure><p>创建一个名为 <code>johndoe</code> 的用户。</p></li></ol><h3 id="常用选项"><a href="#常用选项" class="headerlink" title="常用选项"></a>常用选项</h3><ul><li><code>-i &lt;inventory&gt;</code>：指定主机清单文件。例如 <code>-i hosts</code>。</li><li><code>--list-hosts</code>：列出将运行任务的主机。</li><li><code>-l &lt;subset&gt;</code>：指定要执行任务的主机子集。例如 <code>-l webservers</code>。</li><li><code>-u &lt;user&gt;</code>：指定远程主机用户。例如 <code>-u root</code>。</li><li><code>-k</code>：提示输入 SSH 密码。</li><li><code>--ask-become-pass</code>：提示输入 sudo 密码。</li><li><code>-e &lt;extra_vars&gt;</code>：传递额外变量。例如 <code>-e &quot;var1=value1 var2=value2&quot;</code>。</li></ul><h3 id="示例详解"><a href="#示例详解" class="headerlink" title="示例详解"></a>示例详解</h3><ol><li><p><strong>列出主机</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all --list-hosts</span><br></pre></td></tr></table></figure><p>列出所有在清单中的主机。</p></li><li><p><strong>指定用户和密码执行命令</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m shell -a <span class="string">&#x27;df -h&#x27;</span> -u root -k</span><br></pre></td></tr></table></figure><p>使用 root 用户执行 <code>df -h</code> 命令，并提示输入密码。</p></li><li><p><strong>传递额外变量</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m shell -a <span class="string">&#x27;echo &#123;&#123; var_name &#125;&#125;&#x27;</span> -e <span class="string">&#x27;var_name=HelloWorld&#x27;</span></span><br></pre></td></tr></table></figure><p>传递变量 <code>var_name</code>，并在命令中使用。</p></li></ol><h3 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h3><ol><li><p><strong>使用标签</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m shell -a <span class="string">&#x27;systemctl restart httpd&#x27;</span> --tags <span class="string">&quot;restart&quot;</span></span><br></pre></td></tr></table></figure><p>使用标签来组织和执行特定的任务。</p></li><li><p><strong>检查主机连通性</strong></p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ansible all -m ping -i inventory/hosts</span><br></pre></td></tr></table></figure><p>使用指定的主机清单文件检查连通性。</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Ansible&quot;&gt;&lt;a href=&quot;#Ansible&quot; class=&quot;headerlink&quot; title=&quot;Ansible&quot;&gt;&lt;/a&gt;Ansible&lt;/h2&gt;&lt;p&gt;用于配置管理、应用程序部署、任务自动化&lt;/p&gt;
&lt;h3 id=&quot;ansible主机清单&quot;&gt;&lt;a hr</summary>
      
    
    
    
    <category term="ansible" scheme="https://kalyan-zitiu.github.io/categories/ansible/"/>
    
    
    <category term="ansible" scheme="https://kalyan-zitiu.github.io/tags/ansible/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes服务网格</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/22/Kubernetes%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/22/Kubernetes%E6%9C%8D%E5%8A%A1%E7%BD%91%E6%A0%BC/</id>
    <published>2024-07-22T03:31:12.000Z</published>
    <updated>2024-07-22T03:35:22.878Z</updated>
    
    <content type="html"><![CDATA[<h2 id="kubernetes服务网格"><a href="#kubernetes服务网格" class="headerlink" title="kubernetes服务网格"></a>kubernetes服务网格</h2><p>是一种架构，为了解决服务和服务之间的通信。</p><h3 id="服务网格接口（打算理解）"><a href="#服务网格接口（打算理解）" class="headerlink" title="服务网格接口（打算理解）"></a>服务网格接口（打算理解）</h3><h4 id="SMI"><a href="#SMI" class="headerlink" title="SMI"></a>SMI</h4><p>  用于定义服务网格标准化接口的规范，旨在提供一个通用的接口，让不同的服务网格实现可以互操作。SMI的主要目的是简化服务网格的使用和集成，使用户可以使用统一的API管理不同的服务网格实现，如Istio、Linkerd、Consul Connect等。</p><h4 id="CRD"><a href="#CRD" class="headerlink" title="CRD"></a>CRD</h4><p>  是Kubernetes中的一种机制，用于扩展Kubernetes API，使用户可以定义自己的资源类型。通过CRD，用户可以创建自定义资源（CR），这些资源可以与Kubernetes内置资源（如Pod、Service）一样进行管理和操作。</p><h3 id="数据平面代理"><a href="#数据平面代理" class="headerlink" title="数据平面代理"></a>数据平面代理</h3><p>负责处理和管理服务间流量的代理组件。</p><p>核心职责:<br>流量转发：代理组件负责接收、转发和负载均衡服务之间的流量。这包括 HTTP、gRPC、TCP 等多种协议。<br>服务发现：代理可以自动发现 Kubernetes 中的服务，根据服务的配置进行相应的流量路由。<br>流量管理：包括流量控制、重试策略、断路器、故障注入等功能，以保证服务间通信的可靠性和稳定性。<br>安全：提供 mTLS（双向 TLS）加密来确保服务间通信的安全性，支持认证和授权策略。<br>监控和可观测性：代理会收集并上报各种流量指标和日志，帮助管理员监控和诊断服务间的通信问题。</p><h4 id="数据平面架构"><a href="#数据平面架构" class="headerlink" title="数据平面架构"></a>数据平面架构</h4><h5 id="代理附件"><a href="#代理附件" class="headerlink" title="代理附件"></a>代理附件</h5><p>一般部署在工作负载的pod上，后续会拦截进出服务的所有通信，但是在一些升级上，代理附件不能保证在不重建Pod的条件下进行升级</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240722112524609.png" alt="image-20240722112524609"></p><h5 id="代理节点"><a href="#代理节点" class="headerlink" title="代理节点"></a>代理节点</h5><p>由代理节点来处理运行服务的所有流量。但是会存在很大的网络瓶颈。</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240722112926402.png" alt="image-20240722112926402"></p><h4 id="Envoy"><a href="#Envoy" class="headerlink" title="Envoy"></a>Envoy</h4><p>  一个高性能的开源边缘和服务代理，主要用于微服务架构中的通信管理</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240722102428515.png" alt="image-20240722102428515"></p><h5 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h5><h6 id="API网关："><a href="#API网关：" class="headerlink" title="API网关："></a>API网关：</h6><p>Envoy可以作为API网关，处理外部请求并将其路由到内部服务，同时提供认证、限流、缓存等功能。</p><h6 id="边车代理："><a href="#边车代理：" class="headerlink" title="边车代理："></a>边车代理：</h6><ul><li>是一种设计模式，在这种模式下，一个代理程序（如Envoy）被部署在每个服务实例的旁边，这样每个服务实例都有一个独立的代理来处理进出流量。</li><li>在服务网格架构中，Envoy通常以边车代理的形式部署在每个服务实例旁，拦截和处理所有入站和出站流量。</li><li>边车注入是将边车代理自动注入到服务实例的Pod中，以便在微服务架构中实现服务网格功能的过程。分为手动与自动，自动注入似乎能够用istio来进行自动注入。</li><li>Sidecar 模式：Envoy 通常以 sidecar 容器的形式部署在每个微服务 Pod 内，与应用容器共享网络命名空间。所有进出微服务的流量都会通过 Envoy 代理。</li></ul><h6 id="中介层代理："><a href="#中介层代理：" class="headerlink" title="中介层代理："></a>中介层代理：</h6><p>Envoy可以部署在不同的服务层之间，作为中介层代理，处理跨服务的流量和策略管理。</p><h5 id="模块化架构"><a href="#模块化架构" class="headerlink" title="模块化架构"></a>模块化架构</h5><p>Listener：<br>作用：Listener是Envoy用于监听网络端口的组件，负责接受客户端的连接请求。每个Listener都绑定到一个特定的IP地址和端口，并根据配置将流量传递给相应的处理模块。<br>配置：Listener的配置包括监听的地址和端口、使用的协议（如HTTP、TCP）、以及关联的过滤器链。</p><p>Filter：<br>作用：Filter是Envoy用于处理请求和响应的中间处理模块。Filter可以用于修改请求、添加日志、执行身份验证、路由选择等。Envoy的Filter分为多种类型，包括网络过滤器、HTTP过滤器和TCP过滤器。<br>类型：<br>网络过滤器：处理TCP连接层面的流量，如TLS终止、连接限速等。<br>HTTP过滤器：处理HTTP请求和响应，如修改头部信息、执行认证和授权、负载均衡等。<br>TCP过滤器：处理TCP层流量，如TCP代理、流量镜像等。</p><p>Cluster：<br>作用：Cluster是Envoy用于表示一组上游服务实例的组件。Cluster负责服务发现、负载均衡、健康检查等。每个Cluster包含多个主机（即上游服务实例），并定义了如何将流量分配到这些主机上。<br>配置：Cluster的配置包括服务发现类型（静态、DNS、EDS等）、负载均衡策略（如轮询、随机、加权轮询等）、健康检查配置等。</p><p>Route：<br>作用：Route组件定义了Envoy如何将请求路由到不同的Cluster。Route规则基于请求的属性（如路径、头部信息、方法等）来决定具体的路由目标。<br>配置：Route的配置包括匹配规则、路由目标Cluster、重试策略、超时设置等。</p><p>Admin：<br>作用：Admin组件提供了管理和监控Envoy的接口。通过Admin接口，用户可以查看Envoy的运行状态、统计信息、配置详情，并进行管理操作。<br>配置：Admin接口通常通过HTTP API暴露，可以在Envoy配置中指定Admin的监听地址和端口。</p><h5 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h5><p>配置管理<br>Envoy的配置管理可以通过静态文件配置，也可以通过动态配置API（xDS）实现。xDS（Envoy Dynamic Configuration API）包括以下几个部分：<br>ADS（Aggregated Discovery Service）：聚合配置服务，统一管理其他xDS服务。<br>CDS（Cluster Discovery Service）：动态管理Cluster的配置。<br>EDS（Endpoint Discovery Service）：动态管理Cluster中上游服务实例的配置。<br>LDS（Listener Discovery Service）：动态管理Listener的配置。<br>RDS（Route Discovery Service）：动态管理路由配置。<br>SDS（Secret Discovery Service）：动态管理密钥和证书。</p><h3 id="控制平面"><a href="#控制平面" class="headerlink" title="控制平面"></a>控制平面</h3><p>负责管理和协调数据平面代理</p><p>配置管理：提供统一的配置接口，管理服务网格中所有代理的配置，包括路由规则、负载均衡策略、故障恢复策略等。<br>服务发现：集成服务发现机制，实时感知集群中服务的变化，并通知数据平面代理更新其配置。<br>安全管理：实现服务间的认证和授权，管理 TLS 证书的分发和轮换，确保服务间通信的安全性。<br>流量管理：提供流量路由、灰度发布、A/B 测试等高级流量控制功能，帮助开发和运维人员灵活管理服务间的流量。<br>可观测性：收集和聚合数据平面代理的监控指标、日志和分布式追踪数据，提供全局的可观测性视图，帮助排查和诊断问题。</p><h4 id="istio"><a href="#istio" class="headerlink" title="istio"></a>istio</h4><p>istiod为基于envoy的服务网络提供控制平面，他包括三个核心组件，Galley，Pilot，Citidel</p><p>Pilot：一个Envoy的配置服务器，实现 xDS API，并将配置流向与应用程序一起运行的Envoy代理。</p><p>Citadel：负责网格内的证书管理，建立服务器身份和相互TLS。</p><p>Galley：与外部系统互动，Kubernetes等。</p><h4 id="webhook"><a href="#webhook" class="headerlink" title="webhook"></a>webhook</h4><p>用于在 Kubernetes 集群中实现动态配置和策略控制的关键组件。 Istio 中的主要用途包括服务网格控制、资源变更管理和策略执行等。</p><ul><li>自动注入 Sidecar 容器:Istio 使用一个变异（Mutating）Webhook 自动将 Envoy 代理（Sidecar）注入到新创建的 Kubernetes Pod 中。这个过程确保每个服务都能被 Istio 管理和监控。当你为集群启用了自动注入，Webhook 会拦截 Pod 创建请求，在 Pod 完成调度之前往其定义中添加 Envoy 容器以及必要的配置信息。</li><li>配置验证（Validating Webhook）:验证（Validating）Webhook 用于在新的 Istio 配置资源（如 VirtualService、DestinationRule 等）创建或更新时执行验证过程，确保这些配置符合要求，避免因错误配置导致服务故障。这个 Webhook 会在配置提交到 etcd 之前进行执行，起到一个“守门人”的作用，阻止不符合标准的配置生效。</li><li>动态配置和策略控制:Webhook 还可以用于执行动态配置和策略决策。例如，通过 Webhook，可以向运行时注入配置参数或更新策略以应对瞬时需求或安全要求。</li></ul><h4 id="通过iptable达到工作负载通过Envoy发送流量。"><a href="#通过iptable达到工作负载通过Envoy发送流量。" class="headerlink" title="通过iptable达到工作负载通过Envoy发送流量。"></a>通过iptable达到工作负载通过Envoy发送流量。</h4><p>Istio的iptables规则是通过init-containner来进行安装，拦截pod网络流量路由到Envoy。</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240722111557580.png" alt="image-20240722111557580"></p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">initContainers:</span></span><br><span class="line"><span class="string">”argS:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">istio-iptables</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">--envoy-port</span> <span class="comment">#捕获出站的所有流量，并且发送到Envoy这个端口</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&quot;15001&quot;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">--inbound-capture-port</span> <span class="comment">#捕获入站的所有流量，并且发送Envoy这个端口1</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&quot;15006&quot;</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">--proxy-uid</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">&quot;1337”</span></span><br><span class="line"><span class="string">- --istio-inbound-interception-mode</span></span><br><span class="line"><span class="string">- REDIRECT</span></span><br><span class="line"><span class="string">--istio-service-cidr </span></span><br><span class="line"><span class="string">- &#x27;*&#x27;</span></span><br><span class="line"><span class="string">--istio-inbound-ports </span></span><br><span class="line"><span class="string">- &#x27;*&#x27;</span></span><br><span class="line"><span class="string">- --istio-local-exclude-ports</span></span><br><span class="line"><span class="string">- 15090,15021,15020</span></span><br><span class="line"><span class="string">image: docker.io/istio/proxyv2:1.6.7</span></span><br><span class="line"><span class="string">imagePullPolicy: Always</span></span><br><span class="line"><span class="string">name: istio-init</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;kubernetes服务网格&quot;&gt;&lt;a href=&quot;#kubernetes服务网格&quot; class=&quot;headerlink&quot; title=&quot;kubernetes服务网格&quot;&gt;&lt;/a&gt;kubernetes服务网格&lt;/h2&gt;&lt;p&gt;是一种架构，为了解决服务和服务之间的通信。&lt;</summary>
      
    
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/categories/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes ingress基础</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/19/Kubernetes_ingress/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/19/Kubernetes_ingress/</id>
    <published>2024-07-19T01:21:03.000Z</published>
    <updated>2024-07-19T08:02:55.408Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ingress"><a href="#ingress" class="headerlink" title="ingress"></a>ingress</h2><p>  我的理解简单就是处理外部流量，和按规则把流量指向指定服务，以及提供SSL终止。什么是SSL终止，可以简单的理解为一个外包，现在在互联网上很多的流量都使用了TLS/SSL协议继续加密，但是这也会增加服务器的负担，因此SSL终止可以理解成<code>外包</code>一个机器处理这个问题。一般这个外包工作会给到负载均衡器和反向代理。</p><h3 id="为什么需要ingress的存在，Service不是已经提供了流量路由的功能了吗？"><a href="#为什么需要ingress的存在，Service不是已经提供了流量路由的功能了吗？" class="headerlink" title="为什么需要ingress的存在，Service不是已经提供了流量路由的功能了吗？"></a>为什么需要ingress的存在，Service不是已经提供了流量路由的功能了吗？</h3><ul><li>好像就是因为service不够用:dog:所以才有了ingress的存在，而且似乎ingress在处理HTTP和HTTPS流量的能力上十分出色。</li><li>除此之外ingress跳脱到应用层进行负载和流量路由的功能，大大减少统一访问策略和路由规则:boom:</li><li>而且ingress似乎为每一个集群提供了单一入口，流量能够精准投送。:fish:</li></ul><h3 id="ingress-配置冲突"><a href="#ingress-配置冲突" class="headerlink" title="ingress 配置冲突"></a>ingress 配置冲突</h3><p>不同团队或租户尝试使用相同的域名来暴露他们的应用程序时，可能会发生的问题。简单来说，就是两个团队都想用同一个域名，比如<code>app.bearcanoe.com</code>，来让外界访问他们的应用程序。这会导致冲突，因为Ingress控制器（管理这些网络流量的组件）不明确如何处理这种情况</p><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ol><li>准入控制器：在配置被应用到集群之前，验证并确保域名的唯一性。可以使用开放策略代理（OPA）来实现这个功能。</li><li>Contour Ingress 控制器：使用HTTPProxy自定义资源，创建一个根HTTPProxy资源，分配给特定团队。这种方法将域名管理集中化，避免冲突。</li></ol><h3 id="Ingress控制器"><a href="#Ingress控制器" class="headerlink" title="Ingress控制器"></a>Ingress控制器</h3><p>是用来实现Ingress资源定义的路由规则和流量管理的组件，以Pod的形式存在运行，负责解析Ingress资源，配置底层反向代理或负载均衡以处理HTTP和HTTPS流量 。</p><ol><li>解析 Ingress 资源：Ingress 控制器会监视 :eye: Kubernetes API，解析和处理定义在 Ingress 资源中的路由规则和配置。</li><li>配置反向代理/负载均衡器：根据解析到的 Ingress 规则，Ingress 控制器会动态配置底层的反向代理（如 NGINX、HAProxy）或云 :cloud: 提供商的负载均衡器（如 AWS ELB、GCP Load Balancer）。</li><li>管理外部访问：Ingress 控制器 :control_knobs: 负责将外部请求路由到集群内相应的服务，管理 HTTP/HTTPS 流量的转发、负载均衡以及 SSL/TLS 终止等功能。</li><li>支持高级特性：许多 Ingress 控制器支持高级功能，如基于 Cookie 的会话保持、限速、访问控制和基于 IP 的访问限制等。</li></ol><h3 id="流量模式"><a href="#流量模式" class="headerlink" title="流量模式"></a>流量模式</h3><h4 id="HTTP代理"><a href="#HTTP代理" class="headerlink" title="HTTP代理"></a>HTTP代理</h4><p>:question:什么是HTTP代理呢，想象一下你需要借一本书，但是这本书在一个封闭的空间内，你不能够直接自己拿到，这个时候你就需要一个中间人来帮你去借。这个时候这个中间人就可以理解成代理人。就是当客户进行一个HTTP请求，这个请求会通过代理服务器转发到目标服务器。反向代理也是这么理解，目标服务器的资源通过代理服务器传输出去。</p><p>:boy:ingress处理HTTP流量很简单，就是通过host头进行路由转发</p><h4 id="HTTPS代理"><a href="#HTTPS代理" class="headerlink" title="HTTPS代理"></a>HTTPS代理</h4><p>:question:HTTPS流量处理的有些特别，ingress在获取流量的时候进行SSL终止，然后建立新的HTTP请求进行转发。</p><p>但是特殊情况为了安全起见。ingress也会进行SSL终止之后再进行TLS加密与后端pod建立连接。</p><h4 id="OCI-3-4层代理"><a href="#OCI-3-4层代理" class="headerlink" title="OCI 3/4层代理"></a>OCI 3/4层代理</h4><p>:calendar:不懂往后点再研究…….</p><h3 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h3><h4 id="control-knobs-nginx-ingress-controller"><a href="#control-knobs-nginx-ingress-controller" class="headerlink" title=":control_knobs:nginx ingress controller"></a>:control_knobs:nginx ingress controller</h4><p>常用于HTTP和反向代理</p><ul><li>支持SSL/TLS终止</li><li>基于主机名和路径的路由</li><li>支持URL重写和重定向</li></ul><h4 id="control-knobs-Istio-ingress-Gateway"><a href="#control-knobs-Istio-ingress-Gateway" class="headerlink" title=":control_knobs:Istio ingress Gateway"></a>:control_knobs:Istio ingress Gateway</h4><p>Istio Ingress Gateway 是 Istio 服务网格中的一个组件，专门用于管理进入服务网格的外部 HTTP 和 HTTPS 流量。与传统的 Kubernetes Ingress 不同，Istio Ingress Gateway 提供了更多的高级流量管理和安全功能，如细粒度的流量控制、策略管理和监控。</p><h5 id="Istio-Ingress-Gateway-组件"><a href="#Istio-Ingress-Gateway-组件" class="headerlink" title="Istio Ingress Gateway 组件"></a>Istio Ingress Gateway 组件</h5><ol><li>:door: Gateway：定义哪些外部流量可以进入服务网格，以及如何路由这些流量。</li><li>VirtualService：定义流量的具体路由规则，可以包含多种匹配条件和路由行为。</li></ol><h4 id="control-knobs-HAProxy-Ingress"><a href="#control-knobs-HAProxy-Ingress" class="headerlink" title=":control_knobs: HAProxy Ingress"></a>:control_knobs: HAProxy Ingress</h4><p>高性能和高级路由功能，路由灵活，低延迟，负载均衡算法</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;ingress&quot;&gt;&lt;a href=&quot;#ingress&quot; class=&quot;headerlink&quot; title=&quot;ingress&quot;&gt;&lt;/a&gt;ingress&lt;/h2&gt;&lt;p&gt;  我的理解简单就是处理外部流量，和按规则把流量指向指定服务，以及提供SSL终止。什么是SSL终止，</summary>
      
    
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/categories/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes服务基础</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/17/Kubernetes%E6%9C%8D%E5%8A%A1/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/17/Kubernetes%E6%9C%8D%E5%8A%A1/</id>
    <published>2024-07-17T05:26:24.000Z</published>
    <updated>2024-07-17T07:34:53.561Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes服务基础"><a href="#Kubernetes服务基础" class="headerlink" title="Kubernetes服务基础"></a>Kubernetes服务基础</h1><h2 id="o打"><a href="#o打" class="headerlink" title="o打"></a>o打</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看</span></span><br><span class="line">kubectl get svc</span><br><span class="line">kubectl get svc &lt;svc-name&gt;</span><br><span class="line">kubectl describe svc &lt;svc-name&gt;</span><br><span class="line"><span class="comment"># 创建</span></span><br><span class="line">kubectl expose deployment &lt;d-name&gt; --port&lt;port&gt; --target-port=&lt;target-port&gt;</span><br><span class="line"><span class="comment"># 调试</span></span><br><span class="line">kubectl get endpoints &lt;svc-name&gt;：查看服务端点</span><br><span class="line">kubectl port-forward svc/&lt;svc-name&gt;&lt;local-port&gt;:&lt;svc-port&gt;:本地端口转发服务端口</span><br></pre></td></tr></table></figure><h2 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h2><h3 id="服务的类型"><a href="#服务的类型" class="headerlink" title="服务的类型"></a>服务的类型</h3><ul><li>ClusterIP: 分配一个集群内部的ip地址，使得服务只能集群内部访问</li><li>NodePort: 在每个节点上分配一个端口，是的可以外部访问服务</li><li>LoadBalancer: 使用负载均衡来暴露服务，让服务加入后端池</li><li>ExternalName: 通过返回的CNAME记录来映射另一个外部的DNS名称</li></ul><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240717132825010.png" alt="image-20240717132825010"></p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240717145241179.png" alt="image-20240717145241179"></p><h4 id="ClusterIP"><a href="#ClusterIP" class="headerlink" title="ClusterIP"></a>ClusterIP</h4><p>用于定义一组Pod的逻辑集合，并且可以通过一个稳定的IP地址和端口进行访问。<code>ClusterIP</code>服务类型会在集群内部分配一个虚拟IP地址，这个IP地址只能在集群内部访问，不能从外部直接访问。</p><h5 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h5><ol><li><strong>定义Service</strong>: 当你创建一个<code>ClusterIP</code>类型的Service时，Kubernetes会为这个Service分配一个虚拟IP地址（Cluster IP）。</li><li><strong>选择器（Selector）</strong>: Service通过标签选择器（Label Selector）来选择一组Pod，这些Pod将成为这个Service的后端。</li><li><strong>Endpoints</strong>: Kubernetes会自动创建一个Endpoints对象，记录所有符合选择器条件的Pod的IP地址和端口。</li><li><strong>内部负载均衡</strong>: 当集群内的其他Pod或服务通过Cluster IP访问这个Service时，Kubernetes会自动将请求负载均衡到后端的Pod上。</li></ol><h5 id="yaml参考"><a href="#yaml参考" class="headerlink" title="yaml参考"></a>yaml参考</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes</span><br><span class="line">  namespace: default</span><br><span class="line">  uid: 855d96b0-c9e8-4ef2-afe5-bdb86e21adc3</span><br><span class="line">  resourceVersion: <span class="string">&#x27;194&#x27;</span></span><br><span class="line">  creationTimestamp: <span class="string">&#x27;2024-07-12T07:36:07Z&#x27;</span></span><br><span class="line">  labels:</span><br><span class="line">    component: apiserver</span><br><span class="line">    provider: kubernetes</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - name: https</span><br><span class="line">      protocol: TCP</span><br><span class="line">      port: 443</span><br><span class="line">      targetPort: 6443</span><br><span class="line">  clusterIP: 10.233.0.1</span><br><span class="line">  clusterIPs:</span><br><span class="line">    - 10.233.0.1</span><br><span class="line">  <span class="built_in">type</span>: ClusterIP</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  ipFamilies:</span><br><span class="line">    - IPv4</span><br><span class="line">  ipFamilyPolicy: SingleStack</span><br><span class="line">  internalTrafficPolicy: Cluster</span><br><span class="line">status:</span><br><span class="line">  loadBalancer: &#123;&#125;</span><br></pre></td></tr></table></figure><h4 id="NodePort"><a href="#NodePort" class="headerlink" title="NodePort"></a>NodePort</h4><h5 id="工作原理-1"><a href="#工作原理-1" class="headerlink" title="工作原理"></a>工作原理</h5><ol><li><strong>定义Service</strong>: 当你创建一个<code>NodePort</code>类型的Service时，Kubernetes会在每个节点上分配一个端口（范围通常是30000-32767）。</li><li><strong>选择器（Selector）</strong>: Service通过标签选择器（Label Selector）来选择一组Pod，这些Pod将成为这个Service的后端。</li><li><strong>Endpoints</strong>: Kubernetes会自动创建一个Endpoints对象，记录所有符合选择器条件的Pod的IP地址和端口。</li><li><strong>节点端口（NodePort）</strong>: Kubernetes会在每个节点上开放一个指定的端口，并将这个端口的流量转发到Service的Cluster IP，然后再负载均衡到后端的Pod上。</li></ol><h4 id="yaml参考-1"><a href="#yaml参考-1" class="headerlink" title="yaml参考"></a>yaml参考</h4><h4 id="LoadBalancer"><a href="#LoadBalancer" class="headerlink" title="LoadBalancer"></a>LoadBalancer</h4><p>ps：这里的LoadBalancer和云上的不同，是为了解决nodeport不清晰问题。</p><h5 id="外部流量策略"><a href="#外部流量策略" class="headerlink" title="外部流量策略"></a>外部流量策略</h5><ol><li>cluster</li></ol><ul><li>把流量分配给所有集群中所有节点的可用实例上</li><li>能够做到全局分配和高利用，但是可能会造成比较高的延迟</li><li>场景：适合需要整体稳定可用的</li></ul><ol start="2"><li>local</li></ol><ul><li>优先把流量分给同一节点或同一区域的可用实例上</li><li>能够低延迟访问服务，本地优先</li><li>场景：适合游戏或者视频流媒体</li></ul><h5 id="yaml参考-2"><a href="#yaml参考-2" class="headerlink" title="yaml参考"></a>yaml参考</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: loadbalancer-01</span><br><span class="line">  namespace: default</span><br><span class="line">  uid: c4093644-e423-4737-94e1-8fd92606933d</span><br><span class="line">  resourceVersion: <span class="string">&#x27;3774606&#x27;</span></span><br><span class="line">  creationTimestamp: <span class="string">&#x27;2024-07-16T03:04:31Z&#x27;</span></span><br><span class="line">  annotations:</span><br><span class="line">    kpanda.io/alias-name: loadbalancer</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - name: tcp-loadbalaner</span><br><span class="line">      protocol: TCP</span><br><span class="line">      port: 8081</span><br><span class="line">      targetPort: 8081</span><br><span class="line">      nodePort: 30683</span><br><span class="line">  selector:</span><br><span class="line">    app: baize-notebook-ssh</span><br><span class="line">  clusterIP: 10.233.59.228</span><br><span class="line">  clusterIPs:</span><br><span class="line">    - 10.233.59.228</span><br><span class="line">  <span class="built_in">type</span>: LoadBalancer</span><br><span class="line">  sessionAffinity: None</span><br><span class="line">  externalTrafficPolicy: Cluster</span><br><span class="line">  ipFamilies:</span><br><span class="line">    - IPv4</span><br><span class="line">  ipFamilyPolicy: SingleStack</span><br><span class="line">  allocateLoadBalancerNodePorts: <span class="literal">true</span></span><br><span class="line">  internalTrafficPolicy: Cluster</span><br><span class="line">status:</span><br><span class="line">  loadBalancer: &#123;&#125;</span><br></pre></td></tr></table></figure><h4 id="ExternalName"><a href="#ExternalName" class="headerlink" title="ExternalName"></a>ExternalName</h4><h5 id="工作原理-2"><a href="#工作原理-2" class="headerlink" title="工作原理"></a>工作原理</h5><ol><li><strong>定义Service</strong>: 当你创建一个<code>ExternalName</code>类型的Service时，你需要指定一个外部的DNS名称。</li><li><strong>DNS解析</strong>: Kubernetes的DNS服务会为这个Service创建一个CNAME记录，将Service名称解析为指定的外部DNS名称。</li><li><strong>访问外部服务</strong>: 集群内的Pod可以通过Service名称访问外部的服务，Kubernetes的DNS服务会将这个名称解析为外部的DNS名称</li></ol><h5 id="yaml参考-3"><a href="#yaml参考-3" class="headerlink" title="yaml参考"></a>yaml参考</h5><p>不许参考，懒得cv了都基本一样就其他字段和type不同。</p>]]></content>
    
    
    <summary type="html">了解服务以及服务网格的作用</summary>
    
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/categories/Kubernetes/"/>
    
    
    <category term="Kubernetes" scheme="https://kalyan-zitiu.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>解析Linux文件</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/10/%E8%A7%A3%E6%9E%90Linux%E6%96%87%E4%BB%B6/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/10/%E8%A7%A3%E6%9E%90Linux%E6%96%87%E4%BB%B6/</id>
    <published>2024-07-10T03:47:16.000Z</published>
    <updated>2024-07-10T05:44:03.848Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Linux文件管理"><a href="#Linux文件管理" class="headerlink" title="Linux文件管理"></a>Linux文件管理</h3><h4 id="1-lsof-List-Open-Files"><a href="#1-lsof-List-Open-Files" class="headerlink" title="1. lsof (List Open Files)"></a>1. lsof (List Open Files)</h4><p><code>lsof</code>命令用于列出当前系统中已打开的文件。它可以显示哪个进程正在使用哪个文件，并提供有关这些文件的详细信息。这个命令在排查文件占用、删除不成功或挂载卸载问题时非常有用。</p><h5 id="基本语法："><a href="#基本语法：" class="headerlink" title="基本语法："></a>基本语法：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsof [选项] [文件]</span><br></pre></td></tr></table></figure><h5 id="常用选项："><a href="#常用选项：" class="headerlink" title="常用选项："></a>常用选项：</h5><ul><li><code>-u</code>：显示指定用户打开的文件。</li><li><code>-p</code>：显示指定进程ID打开的文件。</li><li><code>+D</code>：递归显示指定目录下的所有打开文件。</li><li><code>-i</code>：显示与网络相关的文件（例如端口使用情况）。</li></ul><h5 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h5><p>列出所有打开的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsof</span><br></pre></td></tr></table></figure><p>查看用户<code>user</code>打开的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsof -u user</span><br></pre></td></tr></table></figure><p>显示进程ID为1234的进程打开的文件：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsof -p 1234</span><br></pre></td></tr></table></figure><h4 id="2-cp-Copy-Files"><a href="#2-cp-Copy-Files" class="headerlink" title="2. cp (Copy Files)"></a>2. cp (Copy Files)</h4><p><code>cp</code>命令用于复制文件和目录。</p><h5 id="基本语法：-1"><a href="#基本语法：-1" class="headerlink" title="基本语法："></a>基本语法：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> [选项] 源文件 目标文件</span><br></pre></td></tr></table></figure><h5 id="常用选项：-1"><a href="#常用选项：-1" class="headerlink" title="常用选项："></a>常用选项：</h5><ul><li><code>-r</code>：递归复制目录及其内容。</li><li><code>-i</code>：覆盖文件前提示确认。</li><li><code>-u</code>：只在源文件比目标文件新或目标文件不存在时复制。</li><li><code>-p</code>：保留源文件的属性。</li></ul><h5 id="示例：-1"><a href="#示例：-1" class="headerlink" title="示例："></a>示例：</h5><p>复制文件<code>file1</code>到<code>file2</code>：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> file1 file2</span><br></pre></td></tr></table></figure><p>递归复制目录<code>dir1</code>到<code>dir2</code>：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cp</span> -r dir1 dir2</span><br></pre></td></tr></table></figure><h4 id="3-mv-Move-Rename-Files"><a href="#3-mv-Move-Rename-Files" class="headerlink" title="3. mv (Move/Rename Files)"></a>3. mv (Move/Rename Files)</h4><p><code>mv</code>命令用于移动或重命名文件和目录。</p><h5 id="基本语法：-2"><a href="#基本语法：-2" class="headerlink" title="基本语法："></a>基本语法：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> [选项] 源文件 目标文件</span><br></pre></td></tr></table></figure><h5 id="常用选项：-2"><a href="#常用选项：-2" class="headerlink" title="常用选项："></a>常用选项：</h5><ul><li><code>-i</code>：覆盖文件前提示确认。</li><li><code>-u</code>：只在源文件比目标文件新或目标文件不存在时移动。</li><li><code>-v</code>：显示详细的操作信息。</li></ul><h5 id="示例：-2"><a href="#示例：-2" class="headerlink" title="示例："></a>示例：</h5><p>重命名文件<code>file1</code>为<code>file2</code>：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> file1 file2</span><br></pre></td></tr></table></figure><p>移动文件<code>file1</code>到目录<code>dir1</code>：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> file1 dir1/</span><br></pre></td></tr></table></figure><h4 id="4-ln-Link-Files"><a href="#4-ln-Link-Files" class="headerlink" title="4. ln (Link Files)"></a>4. ln (Link Files)</h4><p><code>ln</code>命令用于创建硬链接或符号链接（软链接）。</p><h5 id="基本语法：-3"><a href="#基本语法：-3" class="headerlink" title="基本语法："></a>基本语法：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> [选项] 目标文件 链接文件</span><br></pre></td></tr></table></figure><h5 id="常用选项：-3"><a href="#常用选项：-3" class="headerlink" title="常用选项："></a>常用选项：</h5><ul><li><code>-s</code>：创建符号链接。</li><li><code>-f</code>：覆盖已有的链接文件。</li></ul><h5 id="示例：-3"><a href="#示例：-3" class="headerlink" title="示例："></a>示例：</h5><p>创建文件<code>file1</code>的硬链接<code>link1</code>：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> file1 link1</span><br></pre></td></tr></table></figure><p>创建文件<code>file1</code>的符号链接<code>link1</code>：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s file1 link1</span><br></pre></td></tr></table></figure><p>在Linux系统中，建立文件链接（Link）是非常有用的，它提供了多种文件管理和使用的灵活性。文件链接主要分为两种类型：硬链接（Hard Link）和符号链接（Symbolic Link，也称为软链接）。以下是建立链接的原因和它们的用途：</p><h5 id="硬链接（Hard-Link）"><a href="#硬链接（Hard-Link）" class="headerlink" title="硬链接（Hard Link）"></a>硬链接（Hard Link）</h5><p>硬链接是对文件的直接引用。每个硬链接都指向文件的相同物理数据块，因此它们是完全等价的。</p><h6 id="建立硬链接的原因："><a href="#建立硬链接的原因：" class="headerlink" title="建立硬链接的原因："></a>建立硬链接的原因：</h6><ol><li><strong>冗余与备份</strong>：硬链接允许在不同位置访问同一文件内容，可以在不同目录中保持文件的多个访问点，从而提高冗余度，避免文件意外删除。</li><li><strong>节省空间</strong>：硬链接不会占用额外的存储空间，因为它们只是指向同一个物理数据块。</li><li><strong>一致性</strong>：硬链接确保文件的多个实例始终保持同步。对其中一个硬链接的修改会影响所有其他硬链接，因为它们指向相同的数据块。</li></ol><h6 id="示例：-4"><a href="#示例：-4" class="headerlink" title="示例："></a>示例：</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> file1 link1</span><br></pre></td></tr></table></figure><h5 id="符号链接（Symbolic-Link-Soft-Link）"><a href="#符号链接（Symbolic-Link-Soft-Link）" class="headerlink" title="符号链接（Symbolic Link / Soft Link）"></a>符号链接（Symbolic Link / Soft Link）</h5><p>符号链接是指向另一个文件路径的引用。它们类似于快捷方式，包含了目标文件或目录的路径。</p><h6 id="建立符号链接的原因："><a href="#建立符号链接的原因：" class="headerlink" title="建立符号链接的原因："></a>建立符号链接的原因：</h6><ol><li><strong>灵活性</strong>：符号链接可以跨文件系统边界创建，而硬链接只能在同一文件系统内使用。它们可以指向目录或文件。</li><li><strong>便捷访问</strong>：通过符号链接，用户可以创建对常用文件或目录的快捷访问点，简化路径的输入和操作。</li><li><strong>组织结构</strong>：符号链接可以帮助组织文件系统，使某些文件或目录在多个位置都能方便地访问，而不需要复制实际数据。</li><li><strong>共享资源</strong>：在多用户环境中，符号链接可以用于共享公共资源，例如库文件、配置文件等，而不必在每个用户目录中复制一份。</li></ol><h6 id="示例：-5"><a href="#示例：-5" class="headerlink" title="示例："></a>示例：</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ln</span> -s /path/to/original /path/to/symlink</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Linux文件管理&quot;&gt;&lt;a href=&quot;#Linux文件管理&quot; class=&quot;headerlink&quot; title=&quot;Linux文件管理&quot;&gt;&lt;/a&gt;Linux文件管理&lt;/h3&gt;&lt;h4 id=&quot;1-lsof-List-Open-Files&quot;&gt;&lt;a href=&quot;#1-l</summary>
      
    
    
    
    <category term="Linux" scheme="https://kalyan-zitiu.github.io/categories/Linux/"/>
    
    
    <category term="file" scheme="https://kalyan-zitiu.github.io/tags/file/"/>
    
  </entry>
  
  <entry>
    <title>解析Linux网络</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/10/%E8%A7%A3%E6%9E%90Linux%E7%BD%91%E7%BB%9C/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/10/%E8%A7%A3%E6%9E%90Linux%E7%BD%91%E7%BB%9C/</id>
    <published>2024-07-10T01:39:02.000Z</published>
    <updated>2024-07-10T03:39:24.543Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-tcpdump"><a href="#1-tcpdump" class="headerlink" title="1. tcpdump"></a>1. <code>tcpdump</code></h3><p><code>tcpdump</code> 是一个网络抓包工具，可以捕获并分析网络流量。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -i eth0</span><br></pre></td></tr></table></figure><p>捕获接口 <code>eth0</code> 上的所有数据包。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -i eth0 host 192.168.1.1</span><br></pre></td></tr></table></figure><p>捕获与特定主机 <code>192.168.1.1</code> 相关的数据包。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -i eth0 port 80</span><br></pre></td></tr></table></figure><p>捕获接口 <code>eth0</code> 上所有通过端口 <code>80</code> 的数据包。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -i eth0 -w capture.pcap</span><br></pre></td></tr></table></figure><p>将捕获的数据包保存到文件 <code>capture.pcap</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -r capture.pcap</span><br></pre></td></tr></table></figure><p>读取并分析 <code>capture.pcap</code> 文件中的数据包。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tcpdump -i eth0 <span class="string">&#x27;tcp[tcpflags] &amp; (tcp-syn|tcp-ack) != 0&#x27;</span></span><br></pre></td></tr></table></figure><p>捕获所有带有 SYN 或 ACK 标志的 TCP 包。</p><h3 id="2-lsof"><a href="#2-lsof" class="headerlink" title="2. lsof"></a>2. <code>lsof</code></h3><p><code>lsof</code> 显示系统中打开的文件，常用于查看打开的网络连接。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsof -i</span><br></pre></td></tr></table></figure><p>显示所有打开的网络连接。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsof -i :80</span><br></pre></td></tr></table></figure><p>显示所有使用端口 <code>80</code> 的网络连接。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsof -p &lt;PID&gt;</span><br></pre></td></tr></table></figure><p>显示特定进程 <code>&lt;PID&gt;</code> 打开的文件。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsof -u &lt;username&gt;</span><br></pre></td></tr></table></figure><p>显示特定用户打开的文件。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsof /path/to/file</span><br></pre></td></tr></table></figure><p>显示哪个进程打开了指定文件。</p><h3 id="3-net-tools"><a href="#3-net-tools" class="headerlink" title="3. net-tools"></a>3. <code>net-tools</code></h3><p><code>net-tools</code> 包含 <code>ifconfig</code>、<code>netstat</code> 等工具。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ifconfig eth0</span><br></pre></td></tr></table></figure><p>显示接口 <code>eth0</code> 的配置信息。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -an</span><br></pre></td></tr></table></figure><p>显示所有活动的网络连接及其状态。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ifconfig eth0 192.168.1.100 netmask 255.255.255.0</span><br></pre></td></tr></table></figure><p>配置接口 <code>eth0</code> 的 IP 地址和子网掩码。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -r</span><br></pre></td></tr></table></figure><p>显示路由表信息。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -i</span><br></pre></td></tr></table></figure><p>显示网络接口统计信息。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -plnt</span><br></pre></td></tr></table></figure><p>显示所有监听的 TCP 端口及其关联的进程。</p><h3 id="4-iproute2"><a href="#4-iproute2" class="headerlink" title="4. iproute2"></a>4. <code>iproute2</code></h3><p><code>iproute2</code> 是 <code>net-tools</code> 的替代品，提供 <code>ip</code> 命令。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip <span class="built_in">link</span> show</span><br></pre></td></tr></table></figure><p>显示所有网络接口。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip addr show</span><br></pre></td></tr></table></figure><p>显示所有接口的 IP 地址信息。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip addr add 192.168.1.100/24 dev eth0</span><br></pre></td></tr></table></figure><p>为接口 <code>eth0</code> 添加 IP 地址。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> eth0 up</span><br></pre></td></tr></table></figure><p>启用接口 <code>eth0</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip route add default via 192.168.1.1</span><br></pre></td></tr></table></figure><p>设置默认网关。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> eth0 down</span><br></pre></td></tr></table></figure><p>禁用接口 <code>eth0</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip rule add from 192.168.1.0/24 table 1</span><br></pre></td></tr></table></figure><p>添加路由规则，使来自 <code>192.168.1.0/24</code> 的流量使用路由表 <code>1</code>。</p><h3 id="5-NetworkManager"><a href="#5-NetworkManager" class="headerlink" title="5. NetworkManager"></a>5. <code>NetworkManager</code></h3><p><code>NetworkManager</code> 是管理网络配置的工具。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nmtui</span><br></pre></td></tr></table></figure><p>交互命令窗口</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nmcli device status</span><br></pre></td></tr></table></figure><p>查看当前设备的连接状态。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nmcli con show</span><br></pre></td></tr></table></figure><p>列出所有已保存的网络连接。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nmcli device wifi list</span><br></pre></td></tr></table></figure><p>列出可用的 Wi-Fi 网络。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nmcli device wifi connect SSID password PASSWORD</span><br></pre></td></tr></table></figure><p>连接到指定的 Wi-Fi 网络。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nmcli con add <span class="built_in">type</span> ethernet ifname eth0 con-name my-eth0</span><br></pre></td></tr></table></figure><p>添加一个名为 <code>my-eth0</code> 的以太网连接。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nmcli con modify my-eth0 ipv4.addresses 192.168.1.100/24 ipv4.gateway 192.168.1.1</span><br></pre></td></tr></table></figure><p>修改连接 <code>my-eth0</code> 的 IP 地址和网关。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nmcli con up my-eth0</span><br></pre></td></tr></table></figure><p>启用连接 <code>my-eth0</code>。</p><h3 id="6-firewalld"><a href="#6-firewalld" class="headerlink" title="6. firewalld"></a>6. <code>firewalld</code></h3><p><code>firewalld</code> 提供动态的防火墙管理工具。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start firewalld</span><br></pre></td></tr></table></figure><p>启动 <code>firewalld</code> 服务。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --get-active-zones</span><br></pre></td></tr></table></figure><p>查看当前活动的区域。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --list-all</span><br></pre></td></tr></table></figure><p>列出当前区域的所有规则。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --add-port=80/tcp --permanent</span><br></pre></td></tr></table></figure><p>永久打开端口 <code>80</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure><p>重新加载防火墙配置。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --zone=public --add-service=http --permanent</span><br></pre></td></tr></table></figure><p>将 <code>http</code> 服务添加到 <code>public</code> 区域。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --remove-port=80/tcp --permanent</span><br></pre></td></tr></table></figure><p>永久关闭端口 <code>80</code>。</p><h3 id="7-iptables"><a href="#7-iptables" class="headerlink" title="7. iptables"></a>7. <code>iptables</code></h3><p><code>iptables</code> 是 Linux 内核中的包过滤工具。</p><h4 id="四表五链"><a href="#四表五链" class="headerlink" title="四表五链"></a>四表五链</h4><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/1343683-20190523094912972-1910501182.png" alt="img"></p><p>iptables 是 Linux 系统中用于配置网络地址转换（NAT）、包过滤和包修改规则的工具。iptables 使用四个表和五个链来处理数据包。以下是对四个表和五个链的详细解释：</p><h5 id="四个表（Tables）"><a href="#四个表（Tables）" class="headerlink" title="四个表（Tables）"></a>四个表（Tables）</h5><ol><li><p><strong>filter 表</strong>：</p><ul><li><strong>用途</strong>：这是默认的表，用于网络包过滤。</li><li><strong>链</strong>：包含 INPUT、FORWARD 和 OUTPUT 链。</li><li><strong>示例规则</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 允许所有进入本地网络接口的流量</span></span><br><span class="line">iptables -A INPUT -i lo -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 允许所有从本地网络接口发出的流量</span></span><br><span class="line">iptables -A OUTPUT -o lo -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拒绝所有从外部到达本机的流量</span></span><br><span class="line">iptables -A INPUT -i eth0 -j DROP</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>nat 表</strong>：</p><ul><li><strong>用途</strong>：用于网络地址转换（NAT），比如源 NAT（SNAT）和目标 NAT（DNAT）。</li><li><strong>链</strong>：包含 PREROUTING、OUTPUT 和 POSTROUTING 链。</li><li><strong>示例规则</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将外部访问的80端口重定向到内部服务器的8080端口</span></span><br><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将发往外部的流量的源IP地址更改为指定的IP地址</span></span><br><span class="line">iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to-source 1.2.3.4</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>mangle 表</strong>：</p><ul><li><strong>用途</strong>：用于修改 IP 包头信息，如 TOS、TTL 等。</li><li><strong>链</strong>：包含 PREROUTING、OUTPUT、INPUT、FORWARD 和 POSTROUTING 链。</li><li><strong>示例规则</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改流经本机的包的TTL值</span></span><br><span class="line">iptables -t mangle -A PREROUTING -i eth0 -j TTL --ttl-set 128</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>raw 表</strong>：</p><ul><li><strong>用途</strong>：用于在连接跟踪（conntrack）机制之前对数据包进行处理。</li><li><strong>链</strong>：包含 PREROUTING 和 OUTPUT 链。</li><li><strong>示例规则</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 标记流经本机的包，以不进行连接跟踪</span></span><br><span class="line">iptables -t raw -A PREROUTING -p tcp --dport 80 -j NOTRACK</span><br></pre></td></tr></table></figure></li></ul></li></ol><h5 id="五个链（Chains）"><a href="#五个链（Chains）" class="headerlink" title="五个链（Chains）"></a>五个链（Chains）</h5><ol><li><p><strong>INPUT 链</strong>：</p><ul><li><strong>用途</strong>：处理入站流量，即目标为本机的数据包。</li><li><strong>示例规则</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 拒绝所有到达本机的入站流量</span></span><br><span class="line">iptables -A INPUT -j DROP</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>FORWARD 链</strong>：</p><ul><li><strong>用途</strong>：处理转发流量，即通过本机路由的数据包。</li><li><strong>示例规则</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 允许所有通过本机的转发流量</span></span><br><span class="line">iptables -A FORWARD -j ACCEPT</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>OUTPUT 链</strong>：</p><ul><li><strong>用途</strong>：处理出站流量，即从本机发出的数据包。</li><li><strong>示例规则</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 允许所有从本机发出的出站流量</span></span><br><span class="line">iptables -A OUTPUT -j ACCEPT</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>PREROUTING 链</strong>：</p><ul><li><strong>用途</strong>：在路由决策之前处理入站流量，用于 nat 和 mangle 表。</li><li><strong>示例规则</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在路由之前修改入站包的目的IP地址</span></span><br><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 8080 -j DNAT --to-destination 192.168.1.100:80</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>POSTROUTING 链</strong>：</p><ul><li><strong>用途</strong>：在路由决策之后处理出站流量，用于 nat 和 mangle 表。</li><li><strong>示例规则</strong>：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在路由之后修改出站包的源IP地址</span></span><br><span class="line">iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to-source 1.2.3.4</span><br></pre></td></tr></table></figure></li></ul></li></ol><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptables -L</span><br></pre></td></tr></table></figure><p>列出所有当前规则。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptables -A INPUT -p tcp --dport 80 -j ACCEPT</span><br></pre></td></tr></table></figure><p>允许所有进入的 TCP 连接通过端口 <code>80</code>。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptables -D INPUT -p tcp --dport 80 -j ACCEPT</span><br></pre></td></tr></table></figure><p>删除规则，阻止端口 <code>80</code> 的连接。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptables -A INPUT -s 192.168.1.1 -j DROP</span><br></pre></td></tr></table></figure><p>丢弃来自 <code>192.168.1.1</code> 的所有连接。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptables -A OUTPUT -p icmp -j ACCEPT</span><br></pre></td></tr></table></figure><p>允许所有 ICMP 出站流量。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptables-save &gt; /etc/iptables/rules.v4</span><br></pre></td></tr></table></figure><p>保存当前规则到文件。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptables-restore &lt; /etc/iptables/rules.v4</span><br></pre></td></tr></table></figure><p>从文件恢复规则。</p><h3 id="8-nftables"><a href="#8-nftables" class="headerlink" title="8. nftables"></a>8. <code>nftables</code></h3><p>NFTables 是一个用于包过滤、网络地址转换 (NAT) 和流量控制的框架。它替代了 iptables、ip6tables、arptables 和 ebtables。NFTables 的配置文件通常使用简单的脚本语言来定义规则。以下是 NFTables 的表、链和规则的基本结构和语法。</p><h4 id="一、基础结构"><a href="#一、基础结构" class="headerlink" title="一、基础结构"></a>一、基础结构</h4><ol><li><p><strong>表（table）</strong></p><ul><li>表是规则集的容器。每张表可以包含多个链。</li></ul></li><li><p><strong>链（chain）</strong></p><ul><li>链是规则的有序列表。链可以是内置的（如 <code>input</code>、<code>output</code>、<code>forward</code>）或用户定义的。</li></ul></li><li><p><strong>规则（rule）</strong></p><ul><li>规则定义了特定条件下应执行的动作。</li></ul></li></ol><h4 id="二、表、链和规则的语法"><a href="#二、表、链和规则的语法" class="headerlink" title="二、表、链和规则的语法"></a>二、表、链和规则的语法</h4><ol><li><p><strong>创建表</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft add table &lt;family&gt; &lt;table_name&gt;</span><br></pre></td></tr></table></figure><ul><li><code>&lt;family&gt;</code>: 地址族，常见的有 <code>ip</code>（IPv4）、<code>ip6</code>（IPv6）、<code>inet</code>（支持 IPv4 和 IPv6）、<code>arp</code>（ARP）、<code>bridge</code>（网桥）。</li><li><code>&lt;table_name&gt;</code>: 表的名称。</li></ul></li><li><p><strong>删除表</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft delete table &lt;family&gt; &lt;table_name&gt;</span><br></pre></td></tr></table></figure></li><li><p><strong>列出现有表</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft list tables</span><br></pre></td></tr></table></figure></li><li><p><strong>创建链</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft add chain &lt;family&gt; &lt;table_name&gt; &lt;chain_name&gt; &#123; type &lt;type&gt; hook &lt;hook&gt; priority &lt;priority&gt;; &#125;</span><br></pre></td></tr></table></figure><ul><li><code>&lt;type&gt;</code>: 链的类型，可以是 <code>filter</code>、<code>nat</code> 等。</li><li><code>&lt;hook&gt;</code>: 钩子点，可以是 <code>input</code>、<code>output</code>、<code>forward</code>、<code>prerouting</code>、<code>postrouting</code> 等。</li><li><code>&lt;priority&gt;</code>: 优先级。</li></ul><p> 例如：</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft add chain ip mytable mychain &#123; type filter hook input priority 0\; &#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>删除链</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft delete chain &lt;family&gt; &lt;table_name&gt; &lt;chain_name&gt;</span><br></pre></td></tr></table></figure></li><li><p><strong>添加规则</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft add rule &lt;family&gt; &lt;table_name&gt; &lt;chain_name&gt; &lt;expression&gt; &lt;action&gt;</span><br></pre></td></tr></table></figure><ul><li><code>&lt;expression&gt;</code>: 匹配条件，例如 <code>ip saddr 192.168.1.1</code>。</li><li><code>&lt;action&gt;</code>: 动作，例如 <code>accept</code>、<code>drop</code>、<code>reject</code>、<code>log</code> 等。</li></ul><p> 例如：</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft add rule ip mytable mychain ip saddr 192.168.1.1 drop</span><br></pre></td></tr></table></figure></li><li><p><strong>删除规则</strong><br> 可以通过规则句柄删除：</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft delete rule &lt;family&gt; &lt;table_name&gt; &lt;chain_name&gt; handle &lt;handle_number&gt;</span><br></pre></td></tr></table></figure><p> 首先列出链中的规则以找到句柄：</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft list chain &lt;family&gt; &lt;table_name&gt; &lt;chain_name&gt;</span><br></pre></td></tr></table></figure></li><li><p><strong>列出规则</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft list ruleset</span><br></pre></td></tr></table></figure></li></ol><h4 id="三、示例"><a href="#三、示例" class="headerlink" title="三、示例"></a>三、示例</h4><p>假设我们要创建一个简单的防火墙配置，允许入站 SSH 连接并拒绝所有其他入站流量。</p><ol><li><p><strong>创建表</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft add table ip filter</span><br></pre></td></tr></table></figure></li><li><p><strong>创建链</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft add chain ip filter input &#123; type filter hook input priority 0\; &#125;</span><br><span class="line">nft add chain ip filter forward &#123; type filter hook forward priority 0\; &#125;</span><br><span class="line">nft add chain ip filter output &#123; type filter hook output priority 0\; &#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>添加规则</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft add rule ip filter input ip protocol tcp tcp dport 22 accept</span><br><span class="line">nft add rule ip filter input drop</span><br></pre></td></tr></table></figure></li><li><p><strong>查看配置</strong></p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nft list ruleset</span><br></pre></td></tr></table></figure></li></ol><p>这样，我们就配置了一个简单的防火墙，允许入站 SSH 连接并拒绝所有其他入站流量。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nft list ruleset</span><br></pre></td></tr></table></figure><p>列出当前规则集。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nft add rule ip filter input tcp dport 80 accept</span><br></pre></td></tr></table></figure><p>添加规则，允许通过端口 <code>80</code> 的 TCP 连接。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nft delete rule ip filter input tcp dport 80 accept</span><br></pre></td></tr></table></figure><p>删除规则，阻止端口 <code>80</code> 的连接。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nft add rule ip filter input ip saddr 192.168.1.1 drop</span><br></pre></td></tr></table></figure><p>丢弃来自 <code>192.168.1.1</code> 的所有连接。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nft add table ip mytable</span><br></pre></td></tr></table></figure><p>添加一个名为 <code>mytable</code> 的表。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nft add chain ip mytable mychain &#123; <span class="built_in">type</span> filter hook input priority 0 \; &#125;</span><br></pre></td></tr></table></figure><p>在 <code>mytable</code> 表中添加一个名为 <code>mychain</code> 的链。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nft add rule ip mytable mychain counter</span><br></pre></td></tr></table></figure><p>在 <code>mychain</code> 链中添加一个计数规则。</p><h3 id="9-curl"><a href="#9-curl" class="headerlink" title="9. curl"></a>9. <code>curl</code></h3><p><code>curl</code> 是用于传输数据的命令行工具。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -O http://example.com/file</span><br></pre></td></tr></table></figure><p>下载文件 <code>file</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -I http://example.com</span><br></pre></td></tr></table></figure><p>获取 HTTP 响应头信息。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -X POST -d <span class="string">&quot;param1=value1&amp;param2=value2&quot;</span> http://example.com/api</span><br></pre></td></tr></table></figure><p>发送 POST 请求。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -u username:password http://example.com</span><br></pre></td></tr></table></figure><p>使用基本身份验证下载文件。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -k https://example.com</span><br></pre></td></tr></table></figure><p>忽略 SSL 证书错误。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -L http://example.com</span><br></pre></td></tr></table></figure><p>跟随重定向。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -C - -O http://example.com/file</span><br></pre></td></tr></table></figure><p>断点续传下载文件。</p><h3 id="10-wget"><a href="#10-wget" class="headerlink" title="10. wget"></a>10. <code>wget</code></h3><p><code>wget</code> 是另一个下载文件的命令行工具。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget http://example.com/file</span><br></pre></td></tr></table></figure><p>下载文件 <code>file</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget -q http://example.com/file</span><br></pre></td></tr></table></figure><p>静默模式下载文件，不输出任何信息。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget --mirror -p --convert-links -P ./local http://example.com</span><br></pre></td></tr></table></figure><p>递归下载整个网站，并将文件保存到 <code>./local</code> 目录中</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget -c http://example.com/file</span><br></pre></td></tr></table></figure><p>断点续传下载文件。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget --limit-rate=100k http://example.com/file</span><br></pre></td></tr></table></figure><p>限制下载速度为 <code>100kB/s</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget --user=username --password=password http://example.com/file</span><br></pre></td></tr></table></figure><p>使用基本身份验证下载文件。</p><h3 id="11-iptop"><a href="#11-iptop" class="headerlink" title="11. iptop"></a>11. <code>iptop</code></h3><p><code>iptop</code> 是一个实时显示网络流量的工具。</p><p><strong>基本用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptop</span><br></pre></td></tr></table></figure><p>启动 <code>iptop</code>，显示实时网络流量。</p><p><strong>高级用法：</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptop -i eth0</span><br></pre></td></tr></table></figure><p>显示特定接口 <code>eth0</code> 的网络流量。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptop -f src net 192.168.1.0/24</span><br></pre></td></tr></table></figure><p>显示来自特定子网 <code>192.168.1.0/24</code> 的流量。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">iptop -f dst port 80</span><br></pre></td></tr></table></figure><p>显示发送到端口 <code>80</code> 的流量。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;1-tcpdump&quot;&gt;&lt;a href=&quot;#1-tcpdump&quot; class=&quot;headerlink&quot; title=&quot;1. tcpdump&quot;&gt;&lt;/a&gt;1. &lt;code&gt;tcpdump&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;&lt;code&gt;tcpdump&lt;/code&gt; 是一个网络抓</summary>
      
    
    
    
    <category term="Linux" scheme="https://kalyan-zitiu.github.io/categories/Linux/"/>
    
    
    <category term="net" scheme="https://kalyan-zitiu.github.io/tags/net/"/>
    
  </entry>
  
  <entry>
    <title>解析Linux磁盘</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/08/%E8%A7%A3%E6%9E%90Linux%E7%A3%81%E7%9B%98/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/08/%E8%A7%A3%E6%9E%90Linux%E7%A3%81%E7%9B%98/</id>
    <published>2024-07-08T08:49:36.000Z</published>
    <updated>2024-07-09T07:35:51.868Z</updated>
    
    <content type="html"><![CDATA[<h3 id="磁盘方面"><a href="#磁盘方面" class="headerlink" title="磁盘方面"></a>磁盘方面</h3><h4 id="磁盘分区"><a href="#磁盘分区" class="headerlink" title="磁盘分区"></a>磁盘分区</h4><h5 id="分区概念"><a href="#分区概念" class="headerlink" title="分区概念"></a>分区概念</h5><p>在linux系统中，磁盘分区是一种物理硬盘分割成多个逻辑部分的方法，每个分区可以独立地进行管理和使用通常会分为</p><ul><li>主分区：每个磁盘最多可以有四个主分区。需要更多地分区可以使用扩展分区。</li><li>扩展分区： 扩展分区本身不能直接用于存储数据，但可以包含多个逻辑分区。</li><li>逻辑分区： 位于扩展分区内地分区，可以超过四个限制。</li></ul><h5 id="分区职责"><a href="#分区职责" class="headerlink" title="分区职责"></a>分区职责</h5><ul><li>主分区：用于安装操作系统，存储数据，以及引导系统</li><li>扩展分区：是用于包含逻辑分区的一个容器，解决主分区的限制，创建多个逻辑分区</li><li>逻辑分区：可以用来存储操作系统，应用程序和数据。</li></ul><h5 id="常见目录"><a href="#常见目录" class="headerlink" title="常见目录"></a>常见目录</h5><table><thead><tr><th>目录</th><th>描述</th></tr></thead><tbody><tr><td><code>/</code></td><td>根目录，包含系统中所有文件和目录的起点。</td></tr><tr><td><code>/bin</code></td><td>基本命令的二进制文件，如 <code>ls</code>、<code>cp</code>、<code>mv</code> 等。</td></tr><tr><td><code>/boot</code></td><td>存放启动加载器相关的文件和内核文件。</td></tr><tr><td><code>/dev</code></td><td>设备文件目录，包含所有设备的接口文件（如硬盘、终端）。</td></tr><tr><td><code>/etc</code></td><td>配置文件目录，包含系统和应用程序的所有配置文件。</td></tr><tr><td><code>/home</code></td><td>用户家目录，每个用户都有一个单独的子目录，用于存放个人文件和配置。</td></tr><tr><td><code>/lib</code></td><td>系统库文件目录，包含基本系统库和内核模块。</td></tr><tr><td><code>/media</code></td><td>自动挂载的可移动媒体设备（如CD-ROM、USB驱动器）。</td></tr><tr><td><code>/mnt</code></td><td>临时挂载文件系统的挂载点。</td></tr><tr><td><code>/opt</code></td><td>可选软件包目录，用于安装附加的第三方应用程序。</td></tr><tr><td><code>/proc</code></td><td>虚拟文件系统，提供系统和进程信息。</td></tr><tr><td><code>/root</code></td><td>超级用户（root）家目录。</td></tr><tr><td><code>/run</code></td><td>运行时数据，存放系统启动后产生的临时文件（如进程ID文件）。</td></tr><tr><td><code>/sbin</code></td><td>系统管理员命令的二进制文件，如 <code>fdisk</code>、<code>ifconfig</code> 等。</td></tr><tr><td><code>/srv</code></td><td>服务数据目录，存放特定服务的数据（如Web服务器文件）。</td></tr><tr><td><code>/sys</code></td><td>虚拟文件系统，提供内核设备和驱动程序信息。</td></tr><tr><td><code>/tmp</code></td><td>临时文件目录，存放临时文件，系统重启后可能会清空。</td></tr><tr><td><code>/usr</code></td><td>用户程序目录，包含二进制文件、库文件、文档等（如 <code>/usr/bin</code>、<code>/usr/lib</code>）。</td></tr><tr><td><code>/var</code></td><td>可变数据文件目录，存放日志文件、邮件、临时文件等（如 <code>/var/log</code>、<code>/var/mail</code>）。</td></tr></tbody></table><h4 id="MBR-Master-Boot-Record"><a href="#MBR-Master-Boot-Record" class="headerlink" title="MBR (Master Boot Record)"></a>MBR (Master Boot Record)</h4><ul><li>MBR是一种传统的磁盘分区表格式，它位于磁盘的第一个扇区。</li><li>MBR分区表最多支持4个主分区，如果需要更多分区，必须将其中一个主分区转换为扩展分区，再在扩展分区内创建逻辑分区。</li><li>由于使用32位地址，MBR最多支持2TB的磁盘。</li></ul><h5 id="逻辑结构"><a href="#逻辑结构" class="headerlink" title="逻辑结构"></a>逻辑结构</h5><ol><li><p><strong>主引导记录 (Master Boot Record)</strong></p><ul><li>位于磁盘的第一个扇区（LBA 0）。</li><li>大小为512字节。</li></ul></li><li><p><strong>主引导代码 (Boot Code)</strong></p><ul><li>前446字节存储主引导代码，用于启动操作系统。</li></ul></li><li><p><strong>分区表 (Partition Table)</strong></p><ul><li>紧随其后64字节（每个分区条目16字节，共4个条目）。</li><li>描述最多四个主分区或一个扩展分区的起始位置和大小。</li></ul></li><li><p><strong>签名 (Signature)</strong></p><ul><li>最后2字节为磁盘签名（0x55AA），标志主引导记录的结束。</li></ul></li><li><p><strong>扩展分区</strong></p><ul><li>如果需要超过四个分区，可以创建一个扩展分区（Extended Partition）。</li><li>扩展分区包含一个扩展引导记录 (EBR)，每个逻辑分区包含一个EBR。</li></ul></li></ol><h4 id="GPT-GUID-Partition-Table"><a href="#GPT-GUID-Partition-Table" class="headerlink" title="GPT (GUID Partition Table)"></a>GPT (GUID Partition Table)</h4><ul><li>GPT是一种现代的磁盘分区表格式，取代了传统的MBR。</li><li>GPT使用64位地址，可以支持超过8ZB的磁盘容量。</li><li>GPT最多可以支持128个主分区，没有扩展分区的限制。</li><li>GPT分区表有冗余备份和CRC校验，提高了数据的安全性和可靠性。</li></ul><h5 id="逻辑结构-1"><a href="#逻辑结构-1" class="headerlink" title="逻辑结构"></a>逻辑结构</h5><ol><li><p><strong>保护性MBR (Protective MBR)</strong></p><ul><li>位于磁盘的第一个扇区（LBA 0），防止旧版工具误读GPT磁盘。</li></ul></li><li><p><strong>主GPT头 (Primary GPT Header)</strong></p><ul><li>位于LBA 1，描述GPT分区表的总体信息。</li><li>包含GPT版本、头部大小、CRC32校验和等。</li></ul></li><li><p><strong>主分区表 (Primary Partition Table)</strong></p><ul><li>紧随其后，从LBA 2开始，一般占用32个扇区。</li><li>每个分区条目128字节，通常最多支持128个分区条目。</li></ul></li><li><p><strong>分区条目 (Partition Entries)</strong></p><ul><li>每个条目描述一个分区的GUID、类型GUID、起始LBA、结束LBA、属性标志等。</li></ul></li><li><p><strong>用户分区</strong></p><ul><li>从主分区表结束位置开始，存储实际的数据和文件系统。</li></ul></li><li><p><strong>备份分区表 (Backup Partition Table)</strong></p><ul><li>位于磁盘末尾，用于恢复主GPT头和分区表。</li></ul></li><li><p><strong>备份GPT头 (Backup GPT Header)</strong></p><ul><li>位于磁盘倒数第二个扇区，记录备份分区表的信息。</li></ul></li></ol><h4 id="Legacy-BIOS-引导"><a href="#Legacy-BIOS-引导" class="headerlink" title="Legacy / BIOS 引导"></a>Legacy / BIOS 引导</h4><p>Legacy/BIOS（Basic Input/Output System）引导是一种传统的计算机启动模式。它是PC兼容系统的早期固件接口，负责初始化硬件并引导操作系统。以下是详细的说明：</p><h5 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h5><ol><li><p><strong>电源自检（POST）</strong>:</p><ul><li>计算机启动时，BIOS首先进行电源自检（Power-On Self-Test），检查和初始化系统硬件，如内存、CPU、硬盘和外设。</li><li>如果POST过程中检测到错误，BIOS会通过蜂鸣声或屏幕错误信息提示用户。</li></ul></li><li><p><strong>查找引导设备</strong>:</p><ul><li>POST完成后，BIOS会根据预设的引导顺序查找可启动设备（如硬盘、光盘、U盘等）。</li><li>引导顺序通常可以在BIOS设置界面中配置。</li></ul></li><li><p><strong>加载引导扇区</strong>:</p><ul><li>一旦找到一个可引导的设备，BIOS会读取该设备的主引导记录（MBR，Master Boot Record），这通常是设备的第一个扇区（512字节）。</li><li>MBR包含了启动加载程序的初始部分以及分区表信息。</li></ul></li><li><p><strong>执行引导加载程序</strong>:</p><ul><li>BIOS将控制权交给MBR中的引导加载程序。这个程序进一步加载操作系统或更多的引导代码（例如，GRUB、LILO等引导加载程序）。</li></ul></li><li><p><strong>启动操作系统</strong>:</p><ul><li>引导加载程序最终加载操作系统内核，并将控制权交给它，操作系统开始初始化并进入用户模式。</li></ul></li></ol><h5 id="特点和限制"><a href="#特点和限制" class="headerlink" title="特点和限制"></a>特点和限制</h5><ul><li><strong>地址空间限制</strong>: BIOS模式只能使用传统的32位地址模式，无法利用超过4GB的内存空间。</li><li><strong>MBR分区限制</strong>: MBR分区表限制最大支持4个主分区，每个分区最大只能是2TB。</li><li><strong>兼容性</strong>: 由于其长期存在，BIOS模式具有广泛的硬件和软件兼容性。</li></ul><h5 id="设置和配置"><a href="#设置和配置" class="headerlink" title="设置和配置"></a>设置和配置</h5><ul><li><strong>进入BIOS设置</strong>: 通常通过在启动时按下特定的键（如F2、Del、Esc）进入BIOS设置界面。</li><li><strong>配置引导顺序</strong>: 在BIOS设置界面中，用户可以配置引导设备的优先级。</li><li><strong>启用/禁用设备</strong>: 可以在BIOS中启用或禁用某些硬件设备，以优化系统性能或解决兼容性问题。</li></ul><h4 id="UEFI"><a href="#UEFI" class="headerlink" title="UEFI"></a>UEFI</h4><p>UEFI（统一可扩展固件接口）是一种现代固件接口，用于替代传统的BIOS。它提供更强大的功能和更灵活的引导方式。以下是详细的UEFI启动流程和相关设置的教学：</p><h5 id="UEFI-启动流程"><a href="#UEFI-启动流程" class="headerlink" title="UEFI 启动流程"></a>UEFI 启动流程</h5><ol><li><p><strong>电源开启和硬件初始化</strong>:</p><ul><li>计算机启动时，UEFI固件首先进行硬件初始化和电源自检（POST，Power-On Self-Test）。</li><li>检查CPU、内存、存储设备和外设，确保它们工作正常。</li></ul></li><li><p><strong>进入UEFI固件界面</strong>:</p><ul><li>在启动过程中，用户可以按特定的键（如F2、Del、Esc）进入UEFI固件设置界面。</li></ul></li><li><p><strong>查找EFI系统分区（ESP）</strong>:</p><ul><li>UEFI固件会查找包含EFI系统分区（ESP）的存储设备。ESP是一个特殊的分区，用于存储EFI引导加载程序和相关文件。</li><li>ESP通常格式化为FAT32文件系统，并且标记为“EFI System Partition”。</li></ul></li><li><p><strong>加载EFI引导加载程序</strong>:</p><ul><li>在ESP中，UEFI固件查找引导加载程序文件，通常位于 <code>\EFI\Boot\bootx64.efi</code>（对于64位系统）。</li><li>用户可以在UEFI设置中指定特定的引导加载程序路径或更改引导顺序。</li></ul></li><li><p><strong>执行引导加载程序</strong>:</p><ul><li>UEFI将控制权交给引导加载程序。这个程序进一步加载操作系统的引导程序或内核。</li><li>常见的引导加载程序包括Windows Boot Manager、GRUB、Clover等。</li></ul></li><li><p><strong>启动操作系统</strong>:</p><ul><li>引导加载程序加载操作系统内核并将控制权交给它，操作系统开始初始化并进入用户模式。</li></ul></li></ol><h5 id="设置和配置UEFI"><a href="#设置和配置UEFI" class="headerlink" title="设置和配置UEFI"></a>设置和配置UEFI</h5><ol><li><p><strong>进入UEFI设置界面</strong>:</p><ul><li>重启计算机，在启动过程中按下特定的键（如F2、Del、Esc）进入UEFI设置界面。</li><li>不同品牌的主板可能有不同的按键，具体请参考主板或计算机手册。</li></ul></li><li><p><strong>配置引导顺序</strong>:</p><ul><li>在UEFI设置界面中，找到“Boot”或“启动”选项卡。</li><li>配置引导设备的优先级，将希望首先引导的设备设置为第一优先级。</li><li>如果需要从特定的EFI引导文件启动，可以手动指定路径。</li></ul></li><li><p><strong>启用/禁用设备</strong>:</p><ul><li>在“Advanced”或“高级”选项卡中，可以启用或禁用某些硬件设备。</li><li>例如，启用/禁用USB端口、网卡、SATA接口等。</li></ul></li><li><p><strong>安全启动（Secure Boot）</strong>:</p><ul><li>安全启动是一项UEFI功能，用于防止加载未签名或未经授权的操作系统引导程序。</li><li>在“Security”或“安全”选项卡中，可以启用或禁用安全启动。</li><li>如果需要安装非官方签名的操作系统，可能需要暂时禁用安全启动。</li></ul></li><li><p><strong>保存和退出</strong>:</p><ul><li>完成设置后，选择“Save &amp; Exit”或“保存并退出”选项。</li><li>保存设置后，系统将重新启动并应用新的设置。</li></ul></li></ol><h4 id="sar"><a href="#sar" class="headerlink" title="sar"></a>sar</h4><p><code>sar</code>（System Activity Reporter）是一个强大的工具，用于在Linux系统上收集、报告和保存系统活动信息。它可以提供有关系统性能的详细数据，包括CPU、内存、网络、磁盘I/O等多个方面。<code>sar</code>命令通常与<code>sysstat</code>软件包一起使用。下面是如何使用<code>sar</code>命令来监控磁盘活动的步骤：</p><h5 id="安装sysstat包"><a href="#安装sysstat包" class="headerlink" title="安装sysstat包"></a>安装sysstat包</h5><p>在大多数Linux发行版中，可以通过包管理器安装<code>sysstat</code>包：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对于基于Debian的系统（如Ubuntu）</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install sysstat</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于基于RHEL的系统（如CentOS）</span></span><br><span class="line">sudo yum install sysstat</span><br></pre></td></tr></table></figure><h5 id="启用和配置sysstat"><a href="#启用和配置sysstat" class="headerlink" title="启用和配置sysstat"></a>启用和配置sysstat</h5><p>安装完成后，确保<code>sysstat</code>服务已启用并正在运行：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启用sysstat服务</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> sysstat</span><br><span class="line">sudo systemctl start sysstat</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置sysstat以启用数据收集</span></span><br><span class="line">sudo nano /etc/default/sysstat</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将ENABLED=&quot;false&quot;修改为ENABLED=&quot;true&quot;</span></span><br><span class="line">ENABLED=<span class="string">&quot;true&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存并退出编辑器</span></span><br></pre></td></tr></table></figure><h5 id="使用sar监控磁盘I-O"><a href="#使用sar监控磁盘I-O" class="headerlink" title="使用sar监控磁盘I/O"></a>使用sar监控磁盘I/O</h5><p><code>sar</code>可以通过<code>-d</code>选项来监控磁盘I/O活动：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 实时监控磁盘I/O，每1秒报告一次，共报告10次</span></span><br><span class="line">sar -d 1 10</span><br></pre></td></tr></table></figure><h5 id="常用选项"><a href="#常用选项" class="headerlink" title="常用选项"></a>常用选项</h5><ul><li><code>-d</code>：报告磁盘I/O统计信息。</li><li><code>-p</code>：将设备名称从设备编号翻译为设备名称。</li><li><code>-r</code>：报告内存和交换空间使用情况。</li><li><code>-n</code>：报告网络统计信息（如<code>-n DEV</code>报告网络接口统计信息）。</li><li><code>-u</code>：报告CPU使用情况。</li></ul><h5 id="查看历史数据"><a href="#查看历史数据" class="headerlink" title="查看历史数据"></a>查看历史数据</h5><p><code>sar</code>命令可以查看过去的系统性能数据，这些数据通常保存在<code>/var/log/sa/</code>目录中：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看特定日期的磁盘I/O活动（例如2024年7月5日）</span></span><br><span class="line">sar -d -f /var/log/sa/sa05</span><br></pre></td></tr></table></figure><h5 id="示例输出解读"><a href="#示例输出解读" class="headerlink" title="示例输出解读"></a>示例输出解读</h5><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240709151241420.png" alt="image-20240709151241420"></p><p>以下是<code>sar -d</code>命令的示例输出及其含义：</p><ul><li><code>tps</code>：每秒传输数（读+写）。</li><li><code>rd_sec/s</code>：每秒读取的扇区数。</li><li><code>wr_sec/s</code>：每秒写入的扇区数。</li><li><code>avgrq-sz</code>：平均请求大小（扇区）。</li><li><code>avgqu-sz</code>：平均请求队列长度。</li><li><code>await</code>：每个I/O操作的平均等待时间（毫秒）。</li><li><code>svctm</code>：每个I/O操作的平均服务时间（毫秒）。</li><li><code>%util</code>：设备的I/O使用百分比。</li></ul><p>使用<code>sar</code>工具可以帮助系统管理员深入了解系统性能瓶颈并进行相应的优化。</p><h4 id="RAID"><a href="#RAID" class="headerlink" title="RAID"></a>RAID</h4><p>RAID（Redundant Array of Independent Disks，即独立磁盘冗余阵列）是一种将多个物理硬盘驱动器组合成一个逻辑单元的存储技术。其主要目的是提高数据存储的性能、容量和可靠性。RAID技术通过不同的配置（称为RAID级别）来实现这些目标。以下是几种常见的RAID级别：</p><ol><li><p><strong>RAID 0</strong>：</p><ul><li><strong>条带化（Striping）</strong>：数据在多个磁盘上分割并并行写入。</li><li><strong>优点</strong>：提高读写速度。</li><li><strong>缺点</strong>：没有冗余，任何一个磁盘故障都会导致数据丢失。</li></ul></li><li><p><strong>RAID 1</strong>：</p><ul><li><strong>镜像（Mirroring）</strong>：每个数据块都在两个或多个磁盘上复制。</li><li><strong>优点</strong>：提供高冗余，数据安全性高。</li><li><strong>缺点</strong>：磁盘利用率低（50%），只使用了一半的存储容量。</li></ul></li><li><p><strong>RAID 5</strong>：</p><ul><li><strong>分布式奇偶校验（Distributed Parity）</strong>：数据和奇偶校验信息分布在所有磁盘上。</li><li><strong>优点</strong>：平衡了性能、容量和数据安全性，至少需要3个磁盘。</li><li><strong>缺点</strong>：写操作较慢，因为需要计算和写入奇偶校验数据。</li></ul></li><li><p><strong>RAID 6</strong>：</p><ul><li><strong>双奇偶校验（Double Parity）</strong>：类似RAID 5，但有两组奇偶校验数据，容忍两块磁盘同时故障。</li><li><strong>优点</strong>：更高的数据安全性。</li><li><strong>缺点</strong>：写操作更慢，磁盘利用率较低。</li></ul></li><li><p><strong>RAID 10（或1+0）</strong>：</p><ul><li><strong>条带化和镜像结合</strong>：先进行镜像，再进行条带化。</li><li><strong>优点</strong>：结合了RAID 0和RAID 1的优点，高性能和高冗余。</li><li><strong>缺点</strong>：需要较多的磁盘，成本较高。</li></ul></li><li><p><strong>RAID 50（或5+0）</strong>：</p><ul><li><strong>条带化和分布式奇偶校验结合</strong>：将RAID 5阵列条带化。</li><li><strong>优点</strong>：提高了性能和冗余，适合大规模存储需求。</li><li><strong>缺点</strong>：复杂度增加，需要更多磁盘。</li></ul></li></ol><h4 id="fdisk"><a href="#fdisk" class="headerlink" title="fdisk"></a>fdisk</h4><p>fdisk 是用于操作磁盘分区的工具，适用于 MBR 分区表。</p><table><thead><tr><th>命令</th><th>描述</th><th>使用说明</th></tr></thead><tbody><tr><td>m</td><td>显示帮助菜单</td><td>显示所有可用命令的列表和简要说明。</td></tr><tr><td>p</td><td>显示当前分区表</td><td>列出指定磁盘上的所有分区信息。</td></tr><tr><td>n</td><td>添加一个新分区</td><td>根据提示选择主分区或逻辑分区，并设置分区的开始和结束位置。</td></tr><tr><td>d</td><td>删除一个分区</td><td>选择要删除的分区编号。</td></tr><tr><td>l</td><td>列出已知分区类型</td><td>显示支持的所有分区类型代码和说明。</td></tr><tr><td>t</td><td>更改一个分区的系统ID</td><td>选择分区后，输入新的类型代码。</td></tr><tr><td>a</td><td>切换启动标志</td><td>设置或取消某个分区的启动标志（使其可引导）。</td></tr><tr><td>w</td><td>写入分区表并退出</td><td>将对分区所做的更改写入磁盘，并退出fdisk。</td></tr><tr><td>q</td><td>不保存更改并退出</td><td>退出fdisk而不保存对分区表的任何更改。</td></tr></tbody></table><h5 id="创建新分区"><a href="#创建新分区" class="headerlink" title="创建新分区"></a>创建新分区</h5><ol><li>输入<code>n</code>创建新分区。</li><li>选择分区类型（主分区<code>p</code>或逻辑分区<code>e</code>）。</li><li>指定分区号（例如<code>1</code>）。</li><li>指定分区的起始扇区和结束扇区。</li><li>输入<code>w</code>保存并退出。</li></ol><h5 id="删除分区"><a href="#删除分区" class="headerlink" title="删除分区"></a>删除分区</h5><ol><li>输入<code>p</code>查看当前分区表。</li><li>输入<code>d</code>删除分区。</li><li>输入要删除的分区编号（例如<code>1</code>）。</li><li>输入<code>w</code>保存并退出。</li></ol><h5 id="更改分区类型"><a href="#更改分区类型" class="headerlink" title="更改分区类型"></a>更改分区类型</h5><ol><li>输入<code>t</code>更改分区类型。</li><li>输入分区编号（例如<code>1</code>）。</li><li>输入新的类型代码（例如<code>83</code>用于Linux分区）。</li><li>输入<code>w</code>保存并退出。</li></ol><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240709125834777.png" alt="image-20240709125834777"></p><h4 id="parted"><a href="#parted" class="headerlink" title="parted"></a>parted</h4><p>fdisk 是用于操作磁盘分区的工具，适用于 GPT分区表。</p><table><thead><tr><th>命令</th><th>描述</th><th>使用说明</th></tr></thead><tbody><tr><td>mklabel</td><td>创建新的磁盘标签（分区表）</td><td>格式：<code>mklabel &lt;label&gt;</code>，其中<code>label</code>可以是<code>gpt</code>、<code>msdos</code>等。</td></tr><tr><td>mkpart</td><td>创建新分区</td><td>格式：<code>mkpart &lt;part-type&gt; &lt;fs-type&gt; &lt;start&gt; &lt;end&gt;</code>，例如<code>mkpart primary ext4 1MiB 500MiB</code>。</td></tr><tr><td>rm</td><td>删除分区</td><td>格式：<code>rm &lt;number&gt;</code>，其中<code>number</code>是分区编号。</td></tr><tr><td>print</td><td>显示分区表</td><td>列出指定磁盘上的所有分区信息。</td></tr><tr><td>name</td><td>给分区命名</td><td>格式：<code>name &lt;number&gt; &lt;name&gt;</code>，给指定编号的分区命名。</td></tr><tr><td>set</td><td>设置分区标志</td><td>格式：`set <number> <flag> &lt;on</td></tr><tr><td>resizepart</td><td>调整分区大小</td><td>格式：<code>resizepart &lt;number&gt; &lt;end&gt;</code>，将分区调整到新的结束位置。</td></tr><tr><td>move</td><td>移动分区</td><td>格式：<code>move &lt;number&gt; &lt;start&gt; &lt;end&gt;</code>，移动分区到新的位置。</td></tr><tr><td>mkfs</td><td>创建文件系统</td><td>格式：<code>mkfs &lt;number&gt; &lt;fs-type&gt;</code>，例如<code>mkfs 1 ext4</code>。</td></tr><tr><td>align-check</td><td>检查分区对齐</td><td>格式：<code>align-check &lt;opt&gt; &lt;number&gt;</code>，例如<code>align-check optimal 1</code>。</td></tr><tr><td>rescue</td><td>尝试恢复丢失的分区</td><td>格式：<code>rescue &lt;start&gt; &lt;end&gt;</code>，尝试在指定范围内恢复分区。</td></tr><tr><td>quit</td><td>退出parted</td><td>退出parted交互模式。</td></tr><tr><td>unit</td><td>设置显示单位</td><td>格式：<code>unit &lt;unit&gt;</code>，其中<code>unit</code>可以是<code>s</code>(扇区)、<code>MB</code>、<code>GB</code>等。</td></tr></tbody></table><h5 id="启动parted"><a href="#启动parted" class="headerlink" title="启动parted"></a>启动parted</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo parted /dev/sdb</span><br></pre></td></tr></table></figure><h5 id="创建新的分区表（GPT）"><a href="#创建新的分区表（GPT）" class="headerlink" title="创建新的分区表（GPT）"></a>创建新的分区表（GPT）</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) mklabel gpt</span><br></pre></td></tr></table></figure><h5 id="创建新分区-1"><a href="#创建新分区-1" class="headerlink" title="创建新分区"></a>创建新分区</h5><p>创建一个从1MiB开始，500MiB结束的主分区，文件系统类型为ext4：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) mkpart primary ext4 1MiB 500MiB</span><br></pre></td></tr></table></figure><h5 id="删除分区-1"><a href="#删除分区-1" class="headerlink" title="删除分区"></a>删除分区</h5><p>删除刚才创建的第一个分区：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) <span class="built_in">rm</span> 1</span><br></pre></td></tr></table></figure><h5 id="调整分区大小"><a href="#调整分区大小" class="headerlink" title="调整分区大小"></a>调整分区大小</h5><p>假设重新创建了一个分区，现在调整其大小到1000MiB：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) mkpart primary ext4 1MiB 500MiB</span><br><span class="line">(parted) resizepart 1 1000MiB</span><br></pre></td></tr></table></figure><h5 id="设置分区标志"><a href="#设置分区标志" class="headerlink" title="设置分区标志"></a>设置分区标志</h5><p>设置第一个分区的启动标志：</p><p>可设置的标识有：</p><p><code>boot</code>：引导分区</p><p><code>esp</code>：EFI系统分区（通常用于UEFI引导）</p><p><code>lvm</code>：逻辑卷管理</p><p><code>raid</code>：RAID分区</p><p><code>swap</code>：交换分区</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) <span class="built_in">set</span> &lt;分区编号&gt; &lt;标识&gt; on</span><br></pre></td></tr></table></figure><h5 id="显示分区表"><a href="#显示分区表" class="headerlink" title="显示分区表"></a>显示分区表</h5><p>显示当前的分区表：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) <span class="built_in">print</span></span><br></pre></td></tr></table></figure><h5 id="给分区命名"><a href="#给分区命名" class="headerlink" title="给分区命名"></a>给分区命名</h5><p>给第一个分区命名：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) name 1 my_partition</span><br></pre></td></tr></table></figure><h5 id="创建文件系统"><a href="#创建文件系统" class="headerlink" title="创建文件系统"></a>创建文件系统</h5><p>在第一个分区上创建ext4文件系统：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) mkfs 1 ext4</span><br></pre></td></tr></table></figure><h6 id="文件类型"><a href="#文件类型" class="headerlink" title="文件类型"></a>文件类型</h6><ol><li><p><strong>ext4</strong>：</p><ul><li>目前最广泛使用的Linux文件系统，ext4具有良好的性能、稳定性和兼容性，支持大文件和大容量存储，适用于大多数应用场景。</li></ul></li><li><p><strong>XFS</strong>：</p><ul><li>XFS是一个高性能的日志文件系统，擅长处理大文件和高并发环境，常用于需要高性能和可扩展性的服务器和存储系统。</li></ul></li><li><p><strong>Btrfs</strong>：</p><ul><li>Btrfs（B-tree FS）支持快照、压缩、多设备存储池、在线文件系统检查和修复等高级功能，适用于需要高级数据管理和灵活性的环境。</li></ul></li><li><p>**ZFS on Linux (ZoL)**：</p><ul><li>ZFS具有高度的数据完整性、快照和复制等高级特性，适用于高存储要求的环境，如服务器和大型存储系统。</li></ul></li></ol><h5 id="检查分区对齐"><a href="#检查分区对齐" class="headerlink" title="检查分区对齐"></a>检查分区对齐</h5><p>检查第一个分区的对齐情况：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) align-check optimal 1</span><br></pre></td></tr></table></figure><h5 id="尝试恢复丢失的分区"><a href="#尝试恢复丢失的分区" class="headerlink" title="尝试恢复丢失的分区"></a>尝试恢复丢失的分区</h5><p>假设分区丢失，尝试在指定范围内恢复分区：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) rescue 1MiB 1000MiB</span><br></pre></td></tr></table></figure><h5 id="退出parted"><a href="#退出parted" class="headerlink" title="退出parted"></a>退出parted</h5><p>退出parted：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(parted) quit</span><br></pre></td></tr></table></figure><h5 id="验证操作"><a href="#验证操作" class="headerlink" title="验证操作"></a>验证操作</h5><p>为了验证这些操作，可以使用<code>lsblk</code>或<code>fdisk -l</code>来查看分区表：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo lsblk</span><br><span class="line">sudo fdisk -l /dev/sdb</span><br></pre></td></tr></table></figure><p>系统中没有parted工具，可以通过以下命令安装：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install parted  <span class="comment"># Debian/Ubuntu</span></span><br><span class="line">sudo yum install parted      <span class="comment"># CentOS/RHEL</span></span><br><span class="line">sudo dnf install parted      <span class="comment"># Fedora</span></span><br></pre></td></tr></table></figure><h4 id="LVM"><a href="#LVM" class="headerlink" title="LVM"></a>LVM</h4><p>LVM 是一种逻辑卷管理器，允许对硬盘和其他存储设备进行灵活的分区管理。</p><p>ps: 逻辑卷是由LVM创建和管理的虚拟存储单元，可以跨越多个物理磁盘或分区。逻辑卷是建立在物理卷之上，物理卷可以是整个磁盘分区或RAID设备。</p><h5 id="为什么要用到LVM"><a href="#为什么要用到LVM" class="headerlink" title="为什么要用到LVM"></a>为什么要用到LVM</h5><p>有工具就是因为有需求，传统的分区因为固定分区大小，需要停机调整分区，影响服务可用。所以需要用到LVM，在线扩展逻辑卷的大小无需停机，只需要添加新的物理硬盘到卷组（VG）中，然后扩展逻辑卷（LV）大小。除此之外，还能够快速创建备份，不需要传统的长时间锁定数据库，还能够整合多个磁盘设备成为一个存储池，能够在数据迁移阶段，避免长时间停机。</p><h5 id="怎么查看逻辑卷"><a href="#怎么查看逻辑卷" class="headerlink" title="怎么查看逻辑卷"></a>怎么查看逻辑卷</h5><h6 id="了解大概的可用块设备"><a href="#了解大概的可用块设备" class="headerlink" title="了解大概的可用块设备"></a>了解大概的可用块设备</h6><p>这张图片显示了<code>lsblk</code>命令的输出，列出了系统中的所有块设备及其挂载点。以下是对这张图片的详细描述：</p><ol><li><p><strong>loop设备</strong>：</p><ul><li><strong>loop0</strong>: 111.9M, 类型为loop，挂载在<code>/snap/lxd/24322</code></li><li><strong>loop1</strong>: 87M, 类型为loop，挂载在<code>/snap/lxd/28373</code></li><li><strong>loop2</strong>: 53.3M, 类型为loop，挂载在<code>/snap/snapd/19457</code></li><li><strong>loop3</strong>: 38.8M, 类型为loop，挂载在<code>/snap/core20/1974</code></li><li><strong>loop4</strong>: 63.9M, 类型为loop，挂载在<code>/snap/core20/2318</code></li><li><strong>loop5</strong>: 63.9M, 类型为loop，挂载在<code>/snap/core20/2456</code></li></ul></li><li><p><strong>物理磁盘</strong>：</p><ul><li><p>sda</p><p>: 25G, 类型为disk</p><ul><li><strong>sda1</strong>: 1M, 类型为part，没有挂载点（这可能是BIOS引导分区或其他用途的特殊分区）</li><li><strong>sda2</strong>: 2G, 类型为part，挂载在<code>/boot</code></li><li><strong>sda3</strong>: 23G, 类型为part，没有挂载点（这可能是LVM物理卷）</li></ul></li></ul></li><li><p><strong>逻辑卷管理器（LVM）</strong>：</p><ul><li><strong>ubuntu–vg-ubuntu–lv</strong>: 12.5G, 类型为lvm，挂载在<code>/</code></li></ul></li><li><p><strong>光驱设备</strong>：</p><ul><li><strong>sr0</strong>: 2G, 类型为rom，没有挂载点</li></ul></li><li></li></ol><ul><li><p><strong>loop设备</strong>：这些是虚拟设备，通常用于挂载磁盘映像文件。</p></li><li><p>sda</p><p>：这是系统中的一个物理磁盘，包含三个分区（sda1, sda2, sda3）。</p><ul><li><strong>sda1</strong>：非常小，只有1M，通常用于系统引导或其他特殊用途。</li><li><strong>sda2</strong>：挂载在<code>/boot</code>，通常用于存放启动加载程序和内核。</li><li><strong>sda3</strong>：较大，为23G，可能用于LVM管理。</li></ul></li><li><p><strong>LVM逻辑卷</strong>：<code>ubuntu--vg-ubuntu--lv</code>是一个逻辑卷，挂载在根目录<code>/</code>。这表示LVM在管理这个分区的存储。</p></li><li><p><strong>光驱设备（sr0）</strong>：显示为2G，未挂载。</p></li></ul><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240709110545123.png" alt="image-20240709110545123"></p><h6 id="扩展逻辑卷大概步骤"><a href="#扩展逻辑卷大概步骤" class="headerlink" title="扩展逻辑卷大概步骤"></a>扩展逻辑卷大概步骤</h6><ol><li>添加新物理硬盘</li><li>将新的物理硬盘初始化为物理卷(PV)</li><li>将PV添加到现在的卷组VG</li><li>扩展逻辑卷LV的大小</li></ol><ul><li><strong>示例</strong>: 创建一个逻辑卷</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建物理卷</span></span><br><span class="line">pvcreate /dev/sdb</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建卷组</span></span><br><span class="line">vgcreate myvg /dev/sdb</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建逻辑卷</span></span><br><span class="line">lvcreate -L 10G -n mylv myvg</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">格式化逻辑卷</span></span><br><span class="line">mkfs.ext4 /dev/myvg/mylv</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建挂载点</span></span><br><span class="line">mkdir /mnt/kalyantest</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">挂载载目录上（ps：一个逻辑卷只能挂载一个目录）</span></span><br><span class="line">mount /mnt/kalyantest</span><br></pre></td></tr></table></figure><h6 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h6><p>创建lvm分区以及扩容</p><ol><li>首先增加物理盘<br><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240709114035255.png" alt="image-20240709114035255"></li><li>然后查询存储块</li></ol><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240709114244596.png" alt="image-20240709114244596"></p><ol start="3"><li>为物理盘建立分区</li></ol><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240709114615916.png" alt="image-20240709114615916"></p><ol start="4"><li>创建PV，VG，LV</li></ol><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240709115109564.png" alt="image-20240709115109564"></p><ol start="5"><li>格式化lv<pre><code>![image-20240709115309348](https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240709115309348.png)</code></pre></li><li>创建挂载目录（也可挂载在你想挂载的地方），并进行挂载(ps:记得修改etc/fstab文件，不然重启会丢失mount点)</li></ol><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240709115612877.png" alt="image-20240709115612877"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;磁盘方面&quot;&gt;&lt;a href=&quot;#磁盘方面&quot; class=&quot;headerlink&quot; title=&quot;磁盘方面&quot;&gt;&lt;/a&gt;磁盘方面&lt;/h3&gt;&lt;h4 id=&quot;磁盘分区&quot;&gt;&lt;a href=&quot;#磁盘分区&quot; class=&quot;headerlink&quot; title=&quot;磁盘分区&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="linux" scheme="https://kalyan-zitiu.github.io/categories/linux/"/>
    
    
    <category term="linux" scheme="https://kalyan-zitiu.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Blog脚本编写</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/07/%E5%8D%9A%E5%AE%A2%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/07/%E5%8D%9A%E5%AE%A2%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99/</id>
    <published>2024-07-07T03:03:50.000Z</published>
    <updated>2024-07-07T03:34:02.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>最近来深圳上班了，这座城市给我的感觉就是有的伸不开身子的感觉，到处都很拥挤，人挤，楼挤，路挤，生活节奏也很挤。来深圳第三天了，但是感觉还是挺好的，公司的前辈们挺有趣的，而且感觉在这里努力下去会有收获的感觉。回到正题，因为运维实习的原因，在正式上岗工作之前都会有一段培训，所以写博客的机会就变多了，因为我的博客框架原因，我每次写博客都需要处理一下页头的一些参数，而且需要用git进行仓库上传，这些重复的工作有点繁琐，所以打算写两个脚本来处理一下。</p><h2 id="页头处理"><a href="#页头处理" class="headerlink" title="页头处理"></a>页头处理</h2><p> 我的页头格式是这样的</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240707111114634.png" alt="image-20240707111114634"></p><h3 id="模块确定"><a href="#模块确定" class="headerlink" title="模块确定"></a>模块确定</h3><p>基本涉及到一些题目，时间，分类，标签，图片，作者之类的，有时候还会涉及到是否加密等。所以第一时间需要考虑的是，这个脚本需要能够获取时间，其次要能够快捷输入题目，标签以及分类和用的图片序号，所以需要GUI，然后还需要能够处理文件系统。故基本能够确定三个模块</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime  <span class="comment"># 导入datetime模块，用于处理日期和时间</span></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path  <span class="comment"># 从pathlib导入Path，用于处理文件系统路径</span></span><br><span class="line"><span class="keyword">import</span> tkinter <span class="keyword">as</span> tk  <span class="comment"># 导入tkinter，用于创建GUI应用程序</span></span><br></pre></td></tr></table></figure><h3 id="函数编写"><a href="#函数编写" class="headerlink" title="函数编写"></a>函数编写</h3><p>然后就可以开始写专门用来生成头部的函数，根据一些页头的结构和格式，进行编写</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_markdown_header</span>(<span class="params">title, categories, tags, wallpaper_index</span>):</span><br><span class="line">    now = datetime.datetime.now()  <span class="comment"># 获取当前日期和时间</span></span><br><span class="line">    date_str = now.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)  <span class="comment"># 将日期和时间格式化为字符串</span></span><br><span class="line">    author = <span class="string">&quot;Kalyan&quot;</span>  <span class="comment"># 作者名称</span></span><br><span class="line">    <span class="comment"># 创建一个格式化为Markdown的类别项字符串</span></span><br><span class="line">    categories_str = <span class="string">&quot;\n&quot;</span>.join(<span class="string">f&quot;- <span class="subst">&#123;cat.strip()&#125;</span>&quot;</span> <span class="keyword">for</span> cat <span class="keyword">in</span> categories.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">    <span class="comment"># 创建一个格式化为Markdown的标签项字符串</span></span><br><span class="line">    tags_str = <span class="string">&quot;\n&quot;</span>.join(<span class="string">f&quot;- <span class="subst">&#123;tag.strip()&#125;</span>&quot;</span> <span class="keyword">for</span> tag <span class="keyword">in</span> tags.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">    <span class="comment"># 使用提供的信息构建完整的Markdown头部</span></span><br><span class="line">    markdown_header = <span class="string">f&quot;&quot;&quot;---</span></span><br><span class="line"><span class="string">title: <span class="subst">&#123;title&#125;</span></span></span><br><span class="line"><span class="string">date: <span class="subst">&#123;date_str&#125;</span></span></span><br><span class="line"><span class="string">categories:</span></span><br><span class="line"><span class="string"><span class="subst">&#123;categories_str&#125;</span></span></span><br><span class="line"><span class="string">tags:</span></span><br><span class="line"><span class="string"><span class="subst">&#123;tags_str&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">description: </span></span><br><span class="line"><span class="string">top_img: /img/WallPaper (<span class="subst">&#123;wallpaper_index&#125;</span>).jpg</span></span><br><span class="line"><span class="string">cover: /img/WallPaper (<span class="subst">&#123;wallpaper_index&#125;</span>).jpg</span></span><br><span class="line"><span class="string">copyright_author: <span class="subst">&#123;author&#125;</span></span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> markdown_header  <span class="comment"># 返回构建的Markdown头部</span></span><br></pre></td></tr></table></figure><h3 id="GUI事件处理"><a href="#GUI事件处理" class="headerlink" title="GUI事件处理"></a>GUI事件处理</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 处理GUI中提交按钮点击的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">on_submit</span>():</span><br><span class="line">    title = title_entry.get()  <span class="comment"># 从文本输入小部件获取标题</span></span><br><span class="line">    categories = categories_entry.get()  <span class="comment"># 从文本输入小部件获取类别</span></span><br><span class="line">    tags = tags_entry.get()  <span class="comment"># 从文本输入小部件获取标签</span></span><br><span class="line">    wallpaper_index = wallpaper_entry.get()  <span class="comment"># 从文本输入小部件获取壁纸序号</span></span><br><span class="line">    header = generate_markdown_header(title, categories, tags, wallpaper_index)  <span class="comment"># 生成Markdown头部</span></span><br><span class="line">    desktop = Path.home() / <span class="string">&#x27;Desktop&#x27;</span>  <span class="comment"># 获取桌面路径</span></span><br><span class="line">    file_name = title.replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;_&quot;</span>).replace(<span class="string">&quot;/&quot;</span>, <span class="string">&quot;_&quot;</span>).replace(<span class="string">&quot;\\&quot;</span>, <span class="string">&quot;_&quot;</span>) + <span class="string">&quot;.md&quot;</span>  <span class="comment"># 创建文件名</span></span><br><span class="line">    full_path = desktop / file_name  <span class="comment"># 完整的文件路径</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(full_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:  <span class="comment"># 打开文件进行写入</span></span><br><span class="line">        f.write(header)  <span class="comment"># 写入Markdown头部</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;文件已保存在桌面: <span class="subst">&#123;full_path&#125;</span>&quot;</span>)  <span class="comment"># 打印文件保存位置</span></span><br><span class="line"></span><br><span class="line">    root.destroy()  <span class="comment"># 关闭GUI</span></span><br></pre></td></tr></table></figure><h3 id="窗口UI调整"><a href="#窗口UI调整" class="headerlink" title="窗口UI调整"></a>窗口UI调整</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">root = tk.Tk()</span><br><span class="line">root.title(<span class="string">&quot;文章信息输入&quot;</span>)  <span class="comment"># 设置窗口标题</span></span><br><span class="line">root.geometry(<span class="string">&quot;400x200&quot;</span>)  <span class="comment"># 设置窗口大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建并放置各种标签和输入框</span></span><br><span class="line">tk.Label(root, text=<span class="string">&quot;文章标题:&quot;</span>).pack()</span><br><span class="line">title_entry = tk.Entry(root, width=<span class="number">50</span>)</span><br><span class="line">title_entry.pack()</span><br><span class="line"></span><br><span class="line">tk.Label(root, text=<span class="string">&quot;分类（用逗号分隔）-&quot;</span>).pack()</span><br><span class="line">categories_entry = tk.Entry(root, width=<span class="number">50</span>)</span><br><span class="line">categories_entry.pack()</span><br><span class="line"></span><br><span class="line">tk.Label(root, text=<span class="string">&quot;标签（用逗号分隔）:&quot;</span>).pack()</span><br><span class="line">tags_entry = tk.Entry(root, width=<span class="number">50</span>)</span><br><span class="line">tags_entry.pack()</span><br><span class="line"></span><br><span class="line">tk.Label(root, text=<span class="string">&quot;壁纸序号:&quot;</span>).pack()</span><br><span class="line">wallpaper_entry = tk.Entry(root, width=<span class="number">50</span>)</span><br><span class="line">wallpaper_entry.pack()</span><br><span class="line"></span><br><span class="line">submit_button = tk.Button(root, text=<span class="string">&quot;提交&quot;</span>, command=on_submit)  <span class="comment"># 创建提交按钮</span></span><br><span class="line">submit_button.pack()</span><br><span class="line"></span><br><span class="line">root.mainloop()  <span class="comment"># 启动GUI事件循环</span></span><br></pre></td></tr></table></figure><p>以上搞定，然后就是打包创建可执行文件就好了。感觉还不错。</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240707112220421.png" alt="image-20240707112220421"></p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240707112235909.png" alt="image-20240707112235909"></p><h2 id="上传处理"><a href="#上传处理" class="headerlink" title="上传处理"></a>上传处理</h2><p>这次并用不上写python脚本，只需要用批处理就好了。</p><p><img src="https://gcore.jsdelivr.net/gh/Kalyan-zitiu/TyporaIMG/img/image-20240707112640400.png" alt="image-20240707112640400"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;最近来深圳上班了，这座城市给我的感觉就是有的伸不开身子的感觉，到处都很拥挤，人挤，楼挤，路挤，生活节奏也很挤。来深圳第三天了，但是感觉还是挺</summary>
      
    
    
    
    <category term="python" scheme="https://kalyan-zitiu.github.io/categories/python/"/>
    
    
    <category term="脚本" scheme="https://kalyan-zitiu.github.io/tags/%E8%84%9A%E6%9C%AC/"/>
    
  </entry>
  
  <entry>
    <title>VMware vSphere</title>
    <link href="https://kalyan-zitiu.github.io/2024/07/07/VMware%20vSphere/"/>
    <id>https://kalyan-zitiu.github.io/2024/07/07/VMware%20vSphere/</id>
    <published>2024-07-07T03:01:04.000Z</published>
    <updated>2024-07-08T02:36:43.736Z</updated>
    
    <content type="html"><![CDATA[<h2 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h2><p>是vmware官方开发的一套虚拟化平台</p><h2 id="能够干什么"><a href="#能够干什么" class="headerlink" title="能够干什么"></a>能够干什么</h2><ol><li>虚拟化：将物理服务器的资源分配给多个VM，提高硬件资源利用率，减少硬件成本。</li><li>集中管理：统一管理监控整个虚拟化环境，包括虚拟机，主机，网络和存储</li><li>高可用提供：能够自动重启故障的物理服务器，保持业务连续。</li><li>资源优化：提供分布式资源调度DRS功能，动态调整VM资源，性能和负载</li><li>安全：能够网络隔离，访问控制，数据加密</li><li>数据保护：提供快照和备份，支持快速恢复</li><li>自动化和编排，通过脚本和工具实现虚拟机的快速部署。</li></ol><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><h3 id="ESXi"><a href="#ESXi" class="headerlink" title="ESXi"></a>ESXi</h3><p>是VMware vSphere虚拟化平台的核心组件。它是一种小型的、专用的操作系统，直接安装在物理服务器上，用于运行和管理虚拟机（VM）。可以说有ESXi的OS的物理服务器就是宿主机Host。</p><h3 id="vSwitch"><a href="#vSwitch" class="headerlink" title="vSwitch"></a>vSwitch</h3><p>运行在VMware ESXi主机上的软件交换机，用于管理虚拟网络。它类似于物理交换机，但功能更灵活，能够在虚拟化环境中提供网络连接和管理。</p><h4 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h4><ol><li><p>网络连接：提供VM之间的网络连接，以及虚拟机与外部物理网络的连接。</p></li><li><p>流量隔离和管理：通过VLAN（虚拟局域网）标签，vSwitch可以隔离和管理不同虚拟机的网络流量，提高网络安全性和性能。</p></li><li><p>网络适配器绑定：vSwitch支持将多个物理网络适配器（NIC）绑定在一起，提供冗余和负载均衡，提高网络的可用性和带宽。</p></li></ol><p>ps: NIC即网络接口卡，是计算机硬件组件，用于计算机与网络的连接。它通常以插卡形式存在，插入计算机主板的扩展槽中，也有集成在主板上的形式。</p><ol start="4"><li><p>流量整形：vSwitch能够对进出网络流量进行整形（Traffic Shaping），控制流量速率，确保网络性能的稳定性。</p></li><li><p>安全特性：vSwitch具备安全特性，如防止MAC地址欺骗和IP地址欺骗，提升虚拟网络的安全性。 </p></li></ol><h4 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h4><h5 id="标准虚拟交换机（vSS）"><a href="#标准虚拟交换机（vSS）" class="headerlink" title="标准虚拟交换机（vSS）"></a>标准虚拟交换机（vSS）</h5><ul><li>独立管理：每台ESXi主机上的vSS独立管理，不同主机上的vSS配置相互独立</li><li>本地主机管理：配置和管理通过ESXi主机的Host Client或vSphere Clinet进行。</li><li>手动配置：手动为每个ESXi主机上分别配置，配置工作量大。</li><li>适用小型环境：适合规模较小或独立的环境，网络配置相对简单<br>ps：缺乏跨主机的集中管理和高级网络功能。</li></ul><h5 id="分布式虚拟交换机（vDS）"><a href="#分布式虚拟交换机（vDS）" class="headerlink" title="分布式虚拟交换机（vDS）"></a>分布式虚拟交换机（vDS）</h5><ul><li>集中管理：能够跨多个ESXi主机统一配置管理</li><li>视图统一：提供网络配置视图，简化大规模环境中的网络管理。</li><li>集中配置：可以在vCenter Server中一次性配置和管理所有相关ESXi主机上的网络设备</li><li>适用于大环境：适合规模大，复杂的，网络配置需求高的。</li></ul><p>ps：拥有比较高级的功能，入Private VLAN，网络IO控制（NetIOC），分布式端口镜像（Port Mirroring）/简化迁移能够网络配置一起迁移，无需重新配置。</p><h5 id="VLAN-和Private-VALN"><a href="#VLAN-和Private-VALN" class="headerlink" title="VLAN 和Private VALN"></a>VLAN 和Private VALN</h5><ol><li>VLAN: </li></ol><ul><li>主要通过交换机端口配置，将交换机端口分到不同的VLAN中。每个VLAN都有唯一的VLAN ID</li><li>设备之间通信得在同一VLAN进行，不同VLAN之间通信需要通过三层设备（如路由器，三层交换机）</li></ul><ol start="2"><li>Private VLAN</li></ol><ul><li>进一步细分VLAN内部的子VLAN，从而提供更精细的流量隔离和控制。</li><li>避免VLAN ID的浪费，适合大规模网络环境。</li></ul><h6 id="Private实现"><a href="#Private实现" class="headerlink" title="Private实现"></a>Private实现</h6><ol><li>Private VLAN将一个VLAN划分为主VLAN（Primary VLAN）和子VLAN（Secondary VLAN）。子VLAN又分为两种类型：Isolated VLAN和Community VLAN。</li></ol><ul><li>Primary VLAN：主VLAN，包含所有的Secondary VLAN。</li><li>Isolated VLAN：隔离VLAN，主机只能与Promiscuous端口通信，不能与其他任何端口通信。</li><li>Community VLAN：社区VLAN，主机可以与同一个Community VLAN内的其他主机和Promiscuous端口通信，但不能与其他Community VLAN或Isolated VLAN内的主机通信。</li><li>Promiscuous端口：可以与所有子VLAN内的端口通信，通常用于连接网关或路由器等设备。</li></ul><h5 id="vDS和vSS的区别"><a href="#vDS和vSS的区别" class="headerlink" title="vDS和vSS的区别"></a>vDS和vSS的区别</h5><p>管理上，vSS独立管理（每个ESXi独立配置），vDS集中管理（跨多个ESXi主机统一配置）<br>功能上，vSS网络配置简单，vDS提供高级网络功能。</p><h3 id="Datastore"><a href="#Datastore" class="headerlink" title="Datastore"></a>Datastore</h3><ul><li>Datastore是一个逻辑存储单元，由ESXi主机创建和管理。</li><li>它可以基于不同类型的物理存储，如本地硬盘、NFS共享、iSCSI目标和SAN存储。</li><li>Datastore用于存储虚拟机的虚拟磁盘文件（.vmdk）、配置文件（.vmx）、ISO映像文件以及其他虚拟机相关的数据。</li></ul><h4 id="数据存储类型及其特点"><a href="#数据存储类型及其特点" class="headerlink" title="数据存储类型及其特点"></a>数据存储类型及其特点</h4><ol><li>本地</li></ol><ul><li>直接连接单个ESXi主机的存储设备，SATA，SAS，SSD硬盘</li></ul><ol start="2"><li>SAN（Storage Area Network）</li></ol><ul><li>高性能，低延迟的存储网络，通常使用光纤通道或iSCSI协议连接</li><li>提供集中管理和共享存储</li></ul><ol start="3"><li>NAS（Network Attached Storage）</li></ol><ul><li>通过标准网络协议（IFS或SMB）访问存储设备</li><li>适用于文件级存储需求</li></ul><ol start="4"><li>vSAN（Virtual SAN）</li></ol><ul><li>VM的分布式存储解决方案，集群中所有ESXi主机的本地存储集合成一个逻辑数据存储。</li><li>提供高性能，可扩展共享存储，支持高可用性。</li></ul><h5 id="类型-1"><a href="#类型-1" class="headerlink" title="类型"></a>类型</h5><ul><li>VMFS： 块存储，如SAN和本地存储。</li><li>NFS：网络附加存储如NAS。</li><li>vSAN:分布式存储解决方案。</li></ul><h3 id="Resource-Pool"><a href="#Resource-Pool" class="headerlink" title="Resource Pool"></a>Resource Pool</h3><p>用于管理和分配计算资源（如CPU和内存）。</p><h4 id="资源池的关键特性"><a href="#资源池的关键特性" class="headerlink" title="资源池的关键特性"></a>资源池的关键特性</h4><ol><li><strong>资源分配</strong>：<ul><li><strong>预留（Reservation）</strong>：确保虚拟机或资源池可以使用的最小资源量。预留的资源保证在所有者需要时始终可用。</li><li><strong>限制（Limit）</strong>：资源池或虚拟机可以使用的最大资源量。限制防止单个实体使用过多资源，影响其他实体的性能。</li><li><strong>份额（Shares）</strong>：定义资源争用时的相对优先级。份额是一个权重，用于确定在资源紧张时各个虚拟机或资源池的优先级。</li></ul></li><li><strong>灵活的资源管理</strong>：<ul><li>动态调整资源：管理员可以在不影响虚拟机运行的情况下动态调整资源池的配置。</li><li>自动化资源分配：配合VMware的DRS（分布式资源调度），可以自动平衡资源池之间的负载。</li></ul></li><li><strong>资源池的层次结构</strong>：<ul><li><strong>根资源池（Root Resource Pool）</strong>：默认存在于每个主机或集群中，是最顶层的资源池。</li><li><strong>子资源池（Child Resource Pool）</strong>：创建在根资源池或其他资源池下，形成树状结构。</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;是什么&quot;&gt;&lt;a href=&quot;#是什么&quot; class=&quot;headerlink&quot; title=&quot;是什么&quot;&gt;&lt;/a&gt;是什么&lt;/h2&gt;&lt;p&gt;是vmware官方开发的一套虚拟化平台&lt;/p&gt;
&lt;h2 id=&quot;能够干什么&quot;&gt;&lt;a href=&quot;#能够干什么&quot; class=&quot;hea</summary>
      
    
    
    
    <category term="VMware" scheme="https://kalyan-zitiu.github.io/categories/VMware/"/>
    
    
    <category term="虚拟化" scheme="https://kalyan-zitiu.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"/>
    
  </entry>
  
</feed>
